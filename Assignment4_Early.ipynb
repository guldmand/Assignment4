{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd007b53",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621bcb29",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2e084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install vit-keras tensorflow-addons wandb --quiet opencv-python python-dotenv nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7580d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 18:30:16.761106: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764869416.793648    5890 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764869416.804628    5890 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-04 18:30:16.944583: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, time, math, json, random, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    "from wandb.integration.keras import WandbCallback\n",
    "from wandb.integration.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282c822",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb2c18dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd08bf",
   "metadata": {},
   "source": [
    "### Reproduceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f3e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813d07bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Will use standard TensorFlow LSTM implementation to avoid cuDNN errors\n"
     ]
    }
   ],
   "source": [
    "# Fix cuDNN compatibility issue for LSTM/GRU layers\n",
    "# Force use of standard LSTM implementation (not cuDNN optimized version)\n",
    "print(\"âœ… Will use standard TensorFlow LSTM implementation to avoid cuDNN errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd23f4f",
   "metadata": {},
   "source": [
    "### Notebook configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12831ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook-config\n",
    "BATCH    = 64\n",
    "EPOCHS   = 300\n",
    "LR       = 1e-4\n",
    "VAL_SPLIT= 0.2\n",
    "\n",
    "# RNN parameters\n",
    "max_tokens = 1000 \n",
    "output_sequence_length = 100\n",
    "pad_to_max_tokens = True\n",
    "\n",
    "# TITLE + CHUNKS configuration for sequence-based RNN\n",
    "MAX_BODY_CHUNKS = 5      # Max sentence chunks from review body\n",
    "MAX_CHUNKS_TOTAL = 6     # title + 5 body chunks = 6 total\n",
    "EMBED_DIM = 1024         # BGE-M3 embedding dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec89436c",
   "metadata": {},
   "source": [
    "### Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b598ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get W&B variables from .env\n",
    "api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "project = os.getenv(\"WANDB_PROJECT\")\n",
    "entity = os.getenv(\"WANDB_ENTITY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158551a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guldmand/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/guldmand/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguldmand\u001b[0m (\u001b[33mguldmand-university-of-southern-denmark\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguldmand\u001b[0m (\u001b[33mguldmand-university-of-southern-denmark\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… W&B login successful â€” runs are now initialized inside train_one_model()\n"
     ]
    }
   ],
   "source": [
    "# get W&B variables from .env\n",
    "api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "project = os.getenv(\"WANDB_PROJECT\")\n",
    "entity = os.getenv(\"WANDB_ENTITY\")\n",
    "\n",
    "WANDB_PROJECT = project\n",
    "WANDB_ENTITY = entity\n",
    "wandb.login(key=api_key, verify=True)\n",
    "\n",
    "os.makedirs(\"progress\", exist_ok=True)\n",
    "\n",
    "print(\"âœ… W&B login successful â€” runs are now initialized inside train_one_model()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5df7b6",
   "metadata": {},
   "source": [
    "## 1) Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e42c3",
   "metadata": {},
   "source": [
    "### 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c37425bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RNN text data\n",
    "X_train = np.load(\"../../data/X_train.npy\", allow_pickle=True)\n",
    "y_train = np.load(\"../../data/y_train.npy\", allow_pickle=True)\n",
    "X_test = np.load(\"../../data/X_test.npy\", allow_pickle=True)\n",
    "\n",
    "# Create pandas DataFrames for easier handling\n",
    "df_Xtrain = pd.DataFrame(X_train,columns=['reviewerID','reviewText','summary'])\n",
    "df_ytrain = pd.DataFrame(y_train,columns=['overall'])\n",
    "df_train = pd.concat([df_ytrain, df_Xtrain], axis=1)\n",
    "df_Xtest = pd.DataFrame(X_test,columns=['reviewerID','reviewText','summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e46519c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8029e89a",
   "metadata": {},
   "source": [
    "### 1.1.1 Text Preprocessing\n",
    "\n",
    "Minimal preprocessing to remove noise while preserving semantics.\n",
    "BGE-M3 is trained on raw text with contractions, punctuation, and mixed case - we keep it that way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Minimal text cleaning for BGE-M3 embeddings.\n",
    "    \n",
    "    We ONLY remove:\n",
    "    - URLs (noise)\n",
    "    - HTML tags (noise)\n",
    "    - Extra whitespace (normalization)\n",
    "    \n",
    "    We KEEP:\n",
    "    - Contractions (I'm, don't, can't) - BGE-M3 is trained on these\n",
    "    - Punctuation (!, ?, ...) - carries sentiment signal\n",
    "    - Stopwords (not, very, but) - crucial for sentiment\n",
    "    - Mixed case - BGE-M3 is case-sensitive\n",
    "    - Numbers and special chars - may have meaning\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Normalize whitespace (replace multiple spaces with single space)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"âœ… Text cleaning function ready (clean_text)\")\n",
    "print(\"   - Removes: URLs, HTML, extra whitespace\")\n",
    "print(\"   - Keeps: contractions, punctuation, stopwords, case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce280ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to all text data\n",
    "print(\"Applying text preprocessing...\")\n",
    "print(f\"Before cleaning - Train reviews: {len(df_Xtrain)}, Test reviews: {len(df_Xtest)}\")\n",
    "\n",
    "# Clean training data\n",
    "df_Xtrain['reviewText'] = df_Xtrain['reviewText'].apply(clean_text)\n",
    "df_Xtrain['summary'] = df_Xtrain['summary'].apply(clean_text)\n",
    "\n",
    "# Clean test data\n",
    "df_Xtest['reviewText'] = df_Xtest['reviewText'].apply(clean_text)\n",
    "df_Xtest['summary'] = df_Xtest['summary'].apply(clean_text)\n",
    "\n",
    "# Check for empty reviews after cleaning\n",
    "empty_train = (df_Xtrain['reviewText'].str.len() == 0).sum()\n",
    "empty_test = (df_Xtest['reviewText'].str.len() == 0).sum()\n",
    "\n",
    "print(f\"\\nâœ… Preprocessing complete!\")\n",
    "print(f\"   Empty reviews after cleaning:\")\n",
    "print(f\"      Train: {empty_train}/{len(df_Xtrain)} ({100*empty_train/len(df_Xtrain):.2f}%)\")\n",
    "print(f\"      Test:  {empty_test}/{len(df_Xtest)} ({100*empty_test/len(df_Xtest):.2f}%)\")\n",
    "print(f\"\\n   Sample cleaned review (first 200 chars):\")\n",
    "print(f\"   {df_Xtrain['reviewText'].iloc[0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a564ef9c",
   "metadata": {},
   "source": [
    "### 1.2 Stratified split (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3654abc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: (24680, 3) (24680, 1)\n",
      "Val   split: (6170, 3) (6170, 1)\n"
     ]
    }
   ],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    df_Xtrain, df_ytrain,\n",
    "    test_size=VAL_SPLIT,\n",
    "    random_state=SEED,\n",
    "    stratify=df_ytrain\n",
    ")\n",
    "\n",
    "print(\"Train split:\", X_tr.shape, y_tr.shape)\n",
    "print(\"Val   split:\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5cefa7",
   "metadata": {},
   "source": [
    "### 1.3 tf.data pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cc45a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764819803.640379  290275 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1764819803.640579  290275 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7196 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Text datasets created:\n",
      "   Train: 24680 samples\n",
      "   Val:   6170 samples\n",
      "   Test:  3428 samples\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# Extract text from DataFrames (reviewText column) and convert to string\n",
    "X_tr_text = X_tr['reviewText'].astype(str).values\n",
    "X_val_text = X_val['reviewText'].astype(str).values\n",
    "X_test_text = df_Xtest['reviewText'].astype(str).values\n",
    "\n",
    "# Convert labels to 0-indexed (1-5 stars -> 0-4 for sparse_categorical_crossentropy)\n",
    "# Flatten the DataFrame values to 1D array and convert to int32\n",
    "y_tr_indexed = y_tr['overall'].values.flatten().astype(np.int32) - 1\n",
    "y_val_indexed = y_val['overall'].values.flatten().astype(np.int32) - 1\n",
    "\n",
    "def make_train_ds(X_text, y):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_text, y))\n",
    "    ds = ds.shuffle(10_000, seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(BATCH).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def make_eval_ds(X_text, y):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_text, y))\n",
    "    ds = ds.batch(BATCH).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def make_test_ds(X_text):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(X_text)\n",
    "    ds = ds.batch(BATCH).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_train_ds(X_tr_text, y_tr_indexed)\n",
    "val_ds   = make_eval_ds(X_val_text, y_val_indexed)\n",
    "test_ds  = make_test_ds(X_test_text)\n",
    "\n",
    "print(f\"âœ… Text datasets created:\")\n",
    "print(f\"   Train: {len(X_tr_text)} samples\")\n",
    "print(f\"   Val:   {len(X_val_text)} samples\")\n",
    "print(f\"   Test:  {len(X_test_text)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d47014",
   "metadata": {},
   "source": [
    "## 2) Embeddings\n",
    "for scentence embeddings we wanna use \n",
    "https://huggingface.co/BAAI/bge-m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeaf349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4f237dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BAAI/bge-m3 (PyTorch for embedding generation)...\n",
      "âœ… BGE-M3 loaded on device: cuda\n",
      "   Embedding dimension: 1024\n",
      "   Max sequence length: 8192\n",
      "\n",
      "â„¹ï¸  Note: Embeddings will be generated using PyTorch, then used in TensorFlow/Keras for training\n",
      "âœ… BGE-M3 loaded on device: cuda\n",
      "   Embedding dimension: 1024\n",
      "   Max sequence length: 8192\n",
      "\n",
      "â„¹ï¸  Note: Embeddings will be generated using PyTorch, then used in TensorFlow/Keras for training\n"
     ]
    }
   ],
   "source": [
    "# Setup embeddings using BAAI/bge-m3 from Huggingface\n",
    "# Note: We'll use PyTorch for embedding generation (offline preprocessing),\n",
    "# then use the embeddings in TensorFlow/Keras for RNN training\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load BGE-M3 model and tokenizer (PyTorch for embedding generation only)\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "print(f\"Loading {model_name} (PyTorch for embedding generation)...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Use safetensors to avoid PyTorch version requirement\n",
    "embedding_model = AutoModel.from_pretrained(model_name, use_safetensors=True)\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "embedding_model = embedding_model.to(device)\n",
    "embedding_model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(f\"âœ… BGE-M3 loaded on device: {device}\")\n",
    "print(f\"   Embedding dimension: {embedding_model.config.hidden_size}\")\n",
    "print(f\"   Max sequence length: {tokenizer.model_max_length}\")\n",
    "print(f\"\\nâ„¹ï¸  Note: Embeddings will be generated using PyTorch, then used in TensorFlow/Keras for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d60e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def simple_sentence_split(text):\n",
    "    \"\"\"\n",
    "    Split text into sentences using simple regex.\n",
    "    Handles common sentence endings: . ! ?\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "    \n",
    "    # Split on sentence boundaries (., !, ?)\n",
    "    sentences = re.split(r'[.!?]+', text)\n",
    "    \n",
    "    # Clean and filter out empty sentences\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "def build_chunks(df, max_body_chunks=MAX_BODY_CHUNKS):\n",
    "    \"\"\"\n",
    "    Build chunks for each review: [title, sent1, sent2, ..., sentN]\n",
    "    \n",
    "    Returns list of lists, where each inner list has:\n",
    "    - First element: review title (summary)\n",
    "    - Next elements: up to max_body_chunks sentences from review body\n",
    "    \n",
    "    Example: [[\"Great product\", \"I love it\", \"Works perfectly\"], ...]\n",
    "    \"\"\"\n",
    "    all_chunks = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        chunks = []\n",
    "        \n",
    "        # Add title as first chunk\n",
    "        title = row['summary'] if pd.notna(row['summary']) else \"\"\n",
    "        chunks.append(title)\n",
    "        \n",
    "        # Split body into sentences\n",
    "        body = row['reviewText'] if pd.notna(row['reviewText']) else \"\"\n",
    "        sentences = simple_sentence_split(body)\n",
    "        \n",
    "        # Add up to max_body_chunks sentences\n",
    "        for i in range(min(len(sentences), max_body_chunks)):\n",
    "            chunks.append(sentences[i])\n",
    "        \n",
    "        all_chunks.append(chunks)\n",
    "    \n",
    "    return all_chunks\n",
    "\n",
    "print(\"âœ… Chunking functions ready (simple_sentence_split, build_chunks)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2829e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_chunks_with_bge(all_chunks, max_chunks=MAX_CHUNKS_TOTAL, embed_dim=EMBED_DIM, batch_size=32):\n",
    "    \"\"\"\n",
    "    Generate BGE-M3 embeddings for chunked text sequences.\n",
    "    \n",
    "    Input: List of chunk lists, e.g., [[\"title1\", \"sent1\", \"sent2\"], [\"title2\", \"sent1\"], ...]\n",
    "    Output: Numpy array of shape (N, max_chunks, embed_dim) with zero-padding\n",
    "    \n",
    "    Steps:\n",
    "    1. Flatten all chunks into a single list\n",
    "    2. Generate embeddings for all chunks in batches\n",
    "    3. Reconstruct into (N, max_chunks, embed_dim) with zero-padding\n",
    "    \"\"\"\n",
    "    import gc\n",
    "    \n",
    "    # Step 1: Flatten and track positions\n",
    "    flat_chunks = []\n",
    "    chunk_counts = []\n",
    "    \n",
    "    for chunks in all_chunks:\n",
    "        chunk_counts.append(len(chunks))\n",
    "        flat_chunks.extend(chunks)\n",
    "    \n",
    "    total_chunks = len(flat_chunks)\n",
    "    print(f\"Starting chunked embedding: {len(all_chunks)} reviews, {total_chunks} total chunks\")\n",
    "    \n",
    "    # Step 2: Generate embeddings for all chunks using existing function\n",
    "    flat_embeddings = get_bge_embeddings(flat_chunks, batch_size=batch_size)\n",
    "    \n",
    "    # Step 3: Reconstruct into (N, max_chunks, embed_dim)\n",
    "    result = np.zeros((len(all_chunks), max_chunks, embed_dim), dtype=np.float32)\n",
    "    \n",
    "    chunk_idx = 0\n",
    "    for review_idx, count in enumerate(chunk_counts):\n",
    "        # Take embeddings for this review's chunks\n",
    "        review_embeddings = flat_embeddings[chunk_idx:chunk_idx + count]\n",
    "        \n",
    "        # Place into result array (up to max_chunks)\n",
    "        num_to_copy = min(count, max_chunks)\n",
    "        result[review_idx, :num_to_copy, :] = review_embeddings[:num_to_copy]\n",
    "        \n",
    "        chunk_idx += count\n",
    "    \n",
    "    print(f\"âœ… Created chunked embeddings: shape {result.shape}\")\n",
    "    return result\n",
    "\n",
    "print(\"âœ… Chunked embedding function ready (embed_chunks_with_bge)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9003c826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… BGE-M3 embedding function ready (optimized with GPU memory management)\n"
     ]
    }
   ],
   "source": [
    "# Create embedding function with GPU memory management\n",
    "def get_bge_embeddings(texts, batch_size=32):\n",
    "    \"\"\"\n",
    "    Generate BGE-M3 embeddings for a list of texts using PyTorch.\n",
    "    Uses mean pooling on subword tokens for sentence-level embeddings.\n",
    "    Returns numpy arrays that can be used with TensorFlow/Keras.\n",
    "    Clears GPU memory periodically to avoid timeouts.\n",
    "    \"\"\"\n",
    "    import gc\n",
    "    all_embeddings = []\n",
    "    total_batches = (len(texts) + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"Starting embedding generation: {len(texts)} texts, {total_batches} batches, batch_size={batch_size}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            batch_num = i // batch_size + 1\n",
    "            \n",
    "            # Progress reporting (every 100 batches or first/last)\n",
    "            if batch_num % 100 == 0 or batch_num == 1 or batch_num == total_batches:\n",
    "                print(f\"  Processing batch {batch_num}/{total_batches}...\")\n",
    "            \n",
    "            # Tokenize with padding and truncation\n",
    "            encoded = tokenizer(\n",
    "                batch_texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=256,  # Reduced for GPU stability\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # Move to device\n",
    "            encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "            \n",
    "            # Get model outputs\n",
    "            outputs = embedding_model(**encoded)\n",
    "            \n",
    "            # Mean pooling: average over sequence length (subword tokens)\n",
    "            # Mask padding tokens using attention_mask\n",
    "            attention_mask = encoded['attention_mask']\n",
    "            token_embeddings = outputs.last_hidden_state  # (batch, seq_len, hidden_size)\n",
    "            \n",
    "            # Expand attention mask for broadcasting\n",
    "            mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "            \n",
    "            # Sum embeddings, mask padding\n",
    "            sum_embeddings = torch.sum(token_embeddings * mask_expanded, 1)\n",
    "            sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "            \n",
    "            # Mean pooling\n",
    "            mean_embeddings = sum_embeddings / sum_mask\n",
    "            \n",
    "            # Convert to numpy for TensorFlow compatibility\n",
    "            all_embeddings.append(mean_embeddings.cpu().numpy())\n",
    "            \n",
    "            # Clear GPU cache every 100 batches to prevent memory buildup\n",
    "            if batch_num % 100 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "    \n",
    "    print(f\"âœ… Completed {total_batches} batches\")\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "print(\"âœ… BGE-M3 embedding function ready (optimized with GPU memory management)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d6ef26e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgc\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     gc.collect()\n\u001b[32m      8\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… GPU cache cleared\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DataScience/conda_envs/ml/lib/python3.11/site-packages/torch/cuda/memory.py:162\u001b[39m, in \u001b[36mempty_cache\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[33;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[33;03m`nvidia-smi`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m \u001b[33;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: the launch timed out and was terminated\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Clear CUDA cache and reset GPU state\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"âœ… GPU cache cleared\")\n",
    "    print(f\"   GPU memory allocated: {torch.cuda.memory_allocated() / 1024**2:.1f} MB\")\n",
    "    print(f\"   GPU memory reserved: {torch.cuda.memory_reserved() / 1024**2:.1f} MB\")\n",
    "else:\n",
    "    print(\"âš ï¸  No CUDA device available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef192dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating BGE-M3 embeddings...\n",
      "Using batch_size=8 for GPU stability...\n",
      "This will take several minutes...\n",
      "Starting embedding generation: 24680 texts, 3085 batches, batch_size=8\n",
      "  Processing batch 1/3085...\n",
      "  Processing batch 100/3085...\n",
      "  Processing batch 100/3085...\n",
      "  Processing batch 200/3085...\n",
      "  Processing batch 200/3085...\n",
      "  Processing batch 300/3085...\n",
      "  Processing batch 300/3085...\n",
      "  Processing batch 400/3085...\n",
      "  Processing batch 400/3085...\n",
      "  Processing batch 500/3085...\n",
      "  Processing batch 500/3085...\n",
      "  Processing batch 600/3085...\n",
      "  Processing batch 600/3085...\n",
      "  Processing batch 700/3085...\n",
      "  Processing batch 700/3085...\n",
      "  Processing batch 800/3085...\n",
      "  Processing batch 800/3085...\n",
      "  Processing batch 900/3085...\n",
      "  Processing batch 900/3085...\n",
      "  Processing batch 1000/3085...\n",
      "  Processing batch 1000/3085...\n",
      "  Processing batch 1100/3085...\n",
      "  Processing batch 1100/3085...\n",
      "  Processing batch 1200/3085...\n",
      "  Processing batch 1200/3085...\n",
      "  Processing batch 1300/3085...\n",
      "  Processing batch 1300/3085...\n",
      "  Processing batch 1400/3085...\n",
      "  Processing batch 1400/3085...\n",
      "  Processing batch 1500/3085...\n",
      "  Processing batch 1500/3085...\n",
      "  Processing batch 1600/3085...\n",
      "  Processing batch 1600/3085...\n",
      "  Processing batch 1700/3085...\n",
      "  Processing batch 1700/3085...\n",
      "  Processing batch 1800/3085...\n",
      "  Processing batch 1800/3085...\n",
      "  Processing batch 1900/3085...\n",
      "  Processing batch 1900/3085...\n",
      "  Processing batch 2000/3085...\n",
      "  Processing batch 2000/3085...\n",
      "  Processing batch 2100/3085...\n",
      "  Processing batch 2100/3085...\n",
      "  Processing batch 2200/3085...\n",
      "  Processing batch 2200/3085...\n",
      "  Processing batch 2300/3085...\n",
      "  Processing batch 2300/3085...\n",
      "  Processing batch 2400/3085...\n",
      "  Processing batch 2400/3085...\n",
      "  Processing batch 2500/3085...\n",
      "  Processing batch 2500/3085...\n",
      "  Processing batch 2600/3085...\n",
      "  Processing batch 2600/3085...\n",
      "  Processing batch 2700/3085...\n",
      "  Processing batch 2700/3085...\n",
      "  Processing batch 2800/3085...\n",
      "  Processing batch 2800/3085...\n",
      "  Processing batch 2900/3085...\n",
      "  Processing batch 2900/3085...\n",
      "  Processing batch 3000/3085...\n",
      "  Processing batch 3000/3085...\n",
      "  Processing batch 3085/3085...\n",
      "  Processing batch 3085/3085...\n",
      "âœ… Completed 3085 batches\n",
      "Starting embedding generation: 6170 texts, 772 batches, batch_size=8\n",
      "  Processing batch 1/772...\n",
      "âœ… Completed 3085 batches\n",
      "Starting embedding generation: 6170 texts, 772 batches, batch_size=8\n",
      "  Processing batch 1/772...\n",
      "  Processing batch 100/772...\n",
      "  Processing batch 100/772...\n",
      "  Processing batch 200/772...\n",
      "  Processing batch 200/772...\n",
      "  Processing batch 300/772...\n",
      "  Processing batch 300/772...\n",
      "  Processing batch 400/772...\n",
      "  Processing batch 400/772...\n",
      "  Processing batch 500/772...\n",
      "  Processing batch 500/772...\n",
      "  Processing batch 600/772...\n",
      "  Processing batch 600/772...\n",
      "  Processing batch 700/772...\n",
      "  Processing batch 700/772...\n",
      "  Processing batch 772/772...\n",
      "âœ… Completed 772 batches\n",
      "Starting embedding generation: 3428 texts, 429 batches, batch_size=8\n",
      "  Processing batch 1/429...\n",
      "  Processing batch 772/772...\n",
      "âœ… Completed 772 batches\n",
      "Starting embedding generation: 3428 texts, 429 batches, batch_size=8\n",
      "  Processing batch 1/429...\n",
      "  Processing batch 100/429...\n",
      "  Processing batch 100/429...\n",
      "  Processing batch 200/429...\n",
      "  Processing batch 200/429...\n",
      "  Processing batch 300/429...\n",
      "  Processing batch 300/429...\n",
      "  Processing batch 400/429...\n",
      "  Processing batch 400/429...\n",
      "  Processing batch 429/429...\n",
      "  Processing batch 429/429...\n",
      "âœ… Completed 429 batches\n",
      "\n",
      "âœ… Embeddings generated:\n",
      "   Train: (24680, 1024)\n",
      "   Val:   (6170, 1024)\n",
      "   Test:  (3428, 1024)\n",
      "âœ… Completed 429 batches\n",
      "\n",
      "âœ… Embeddings generated:\n",
      "   Train: (24680, 1024)\n",
      "   Val:   (6170, 1024)\n",
      "   Test:  (3428, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for train, val, and test sets\n",
    "print(\"Generating BGE-M3 embeddings...\")\n",
    "print(\"Using batch_size=8 for GPU stability...\")\n",
    "print(\"This will take several minutes...\")\n",
    "\n",
    "# Generate embeddings with very small batch size\n",
    "X_tr_embeddings = get_bge_embeddings(X_tr_text.tolist(), batch_size=8)\n",
    "X_val_embeddings = get_bge_embeddings(X_val_text.tolist(), batch_size=8)\n",
    "X_test_embeddings = get_bge_embeddings(X_test_text.tolist(), batch_size=8)\n",
    "\n",
    "print(f\"\\nâœ… Embeddings generated:\")\n",
    "print(f\"   Train: {X_tr_embeddings.shape}\")\n",
    "print(f\"   Val:   {X_val_embeddings.shape}\")\n",
    "print(f\"   Test:  {X_test_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09096cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving embeddings to disk...\n",
      "âœ… Embeddings saved:\n",
      "   - X_tr_embeddings_bge-m3.npy\n",
      "   - X_val_embeddings_bge-m3.npy\n",
      "   - X_test_embeddings_bge-m3.npy\n"
     ]
    }
   ],
   "source": [
    "# Save embeddings to disk (so we don't have to regenerate them if kernel crashes)\n",
    "print(\"Saving embeddings to disk...\")\n",
    "np.save('X_tr_embeddings_bge-m3.npy', X_tr_embeddings)\n",
    "np.save('X_val_embeddings_bge-m3.npy', X_val_embeddings)\n",
    "np.save('X_test_embeddings_bge-m3.npy', X_test_embeddings)\n",
    "print(\"âœ… Embeddings saved:\")\n",
    "print(\"   - X_tr_embeddings_bge-m3.npy\")\n",
    "print(\"   - X_val_embeddings_bge-m3.npy\")\n",
    "print(\"   - X_test_embeddings_bge-m3.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d4f8cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embeddings loaded from disk:\n",
      "   Train: (24680, 1024)\n",
      "   Val:   (6170, 1024)\n",
      "   Test:  (3428, 1024)\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVE: Load embeddings from disk (skip the 27-minute generation step)\n",
    "X_tr_embeddings = np.load('X_tr_embeddings_bge-m3.npy')\n",
    "X_val_embeddings = np.load('X_val_embeddings_bge-m3.npy')\n",
    "X_test_embeddings = np.load('X_test_embeddings_bge-m3.npy')\n",
    "print(f\"âœ… Embeddings loaded from disk:\")\n",
    "print(f\"   Train: {X_tr_embeddings.shape}\")\n",
    "print(f\"   Val:   {X_val_embeddings.shape}\")\n",
    "print(f\"   Test:  {X_test_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f268125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embedding-based datasets created and ready for RNN training\n"
     ]
    }
   ],
   "source": [
    "# Create new datasets with embeddings instead of raw text\n",
    "def make_train_ds_embeddings(X_emb, y):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_emb, y))\n",
    "    ds = ds.shuffle(10_000, seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.batch(BATCH).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def make_eval_ds_embeddings(X_emb, y):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_emb, y))\n",
    "    ds = ds.batch(BATCH).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def make_test_ds_embeddings(X_emb):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(X_emb)\n",
    "    ds = ds.batch(BATCH).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Create datasets with BGE-M3 embeddings\n",
    "train_ds_emb = make_train_ds_embeddings(X_tr_embeddings, y_tr_indexed)\n",
    "val_ds_emb   = make_eval_ds_embeddings(X_val_embeddings, y_val_indexed)\n",
    "test_ds_emb  = make_test_ds_embeddings(X_test_embeddings)\n",
    "\n",
    "print(\"âœ… Embedding-based datasets created and ready for RNN training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# GENERATE CHUNKED EMBEDDINGS (TITLE + CHUNKS approach)\n",
    "# This will take 30-40 minutes - run once, then use load cell below\n",
    "# ====================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"GENERATING CHUNKED EMBEDDINGS (TITLE + CHUNKS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Build chunks for all datasets\n",
    "print(\"\\n1ï¸âƒ£ Building chunks...\")\n",
    "train_chunks = build_chunks(df_Xtrain_tr, max_body_chunks=MAX_BODY_CHUNKS)\n",
    "val_chunks = build_chunks(df_Xtrain_val, max_body_chunks=MAX_BODY_CHUNKS)\n",
    "test_chunks = build_chunks(pd.DataFrame(X_test, columns=['reviewerID', 'reviewText', 'summary']), max_body_chunks=MAX_BODY_CHUNKS)\n",
    "\n",
    "print(f\"   Train: {len(train_chunks)} reviews\")\n",
    "print(f\"   Val:   {len(val_chunks)} reviews\")\n",
    "print(f\"   Test:  {len(test_chunks)} reviews\")\n",
    "\n",
    "# Step 2: Generate chunked embeddings\n",
    "print(\"\\n2ï¸âƒ£ Generating chunked embeddings (this takes 30-40 minutes)...\")\n",
    "print(\"Using batch_size=8 for GPU stability...\")\n",
    "\n",
    "X_tr_embeddings_chunked = embed_chunks_with_bge(train_chunks, max_chunks=MAX_CHUNKS_TOTAL, embed_dim=EMBED_DIM, batch_size=8)\n",
    "X_val_embeddings_chunked = embed_chunks_with_bge(val_chunks, max_chunks=MAX_CHUNKS_TOTAL, embed_dim=EMBED_DIM, batch_size=8)\n",
    "X_test_embeddings_chunked = embed_chunks_with_bge(test_chunks, max_chunks=MAX_CHUNKS_TOTAL, embed_dim=EMBED_DIM, batch_size=8)\n",
    "\n",
    "print(f\"\\nâœ… Chunked embeddings generated:\")\n",
    "print(f\"   Train: {X_tr_embeddings_chunked.shape}\")\n",
    "print(f\"   Val:   {X_val_embeddings_chunked.shape}\")\n",
    "print(f\"   Test:  {X_test_embeddings_chunked.shape}\")\n",
    "\n",
    "# Step 3: Save to disk with _chunked suffix\n",
    "print(\"\\n3ï¸âƒ£ Saving chunked embeddings to disk...\")\n",
    "np.save('X_tr_embeddings_chunked_bge-m3.npy', X_tr_embeddings_chunked)\n",
    "np.save('X_val_embeddings_chunked_bge-m3.npy', X_val_embeddings_chunked)\n",
    "np.save('X_test_embeddings_chunked_bge-m3.npy', X_test_embeddings_chunked)\n",
    "\n",
    "print(\"âœ… Chunked embeddings saved:\")\n",
    "print(\"   - X_tr_embeddings_chunked_bge-m3.npy\")\n",
    "print(\"   - X_val_embeddings_chunked_bge-m3.npy\")\n",
    "print(\"   - X_test_embeddings_chunked_bge-m3.npy\")\n",
    "print(\"\\nğŸ’¡ Old embeddings preserved (no _chunked suffix)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c8719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# ALTERNATIVE: Load pre-computed CHUNKED embeddings from disk\n",
    "# Use this to skip the 30-40 minute generation step\n",
    "# ====================================================================\n",
    "\n",
    "print(\"Loading chunked embeddings from disk...\")\n",
    "X_tr_embeddings_chunked = np.load('X_tr_embeddings_chunked_bge-m3.npy')\n",
    "X_val_embeddings_chunked = np.load('X_val_embeddings_chunked_bge-m3.npy')\n",
    "X_test_embeddings_chunked = np.load('X_test_embeddings_chunked_bge-m3.npy')\n",
    "\n",
    "print(f\"âœ… Chunked embeddings loaded:\")\n",
    "print(f\"   Train: {X_tr_embeddings_chunked.shape}\")\n",
    "print(f\"   Val:   {X_val_embeddings_chunked.shape}\")\n",
    "print(f\"   Test:  {X_test_embeddings_chunked.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d38c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow datasets with CHUNKED embeddings\n",
    "# Uses same functions as before, but now with (N, 6, 1024) shape instead of (N, 1024)\n",
    "\n",
    "train_ds_chunked = make_train_ds_embeddings(X_tr_embeddings_chunked, y_tr_indexed)\n",
    "val_ds_chunked   = make_eval_ds_embeddings(X_val_embeddings_chunked, y_val_indexed)\n",
    "test_ds_chunked  = make_test_ds_embeddings(X_test_embeddings_chunked)\n",
    "\n",
    "print(\"âœ… Chunked embedding datasets created and ready for RNN training\")\n",
    "print(f\"   Input shape: ({MAX_CHUNKS_TOTAL}, {EMBED_DIM}) = (6, 1024)\")\n",
    "print(f\"   Output shape: (5,) for 5-class classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1209657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# COMPUTE CLASS WEIGHTS to handle class imbalance\n",
    "# ====================================================================\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute class weights based on training data\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_tr_indexed),\n",
    "    y=y_tr_indexed\n",
    ")\n",
    "\n",
    "# Convert to dictionary for Keras\n",
    "class_weights = {i: weight for i, weight in enumerate(class_weights_array)}\n",
    "\n",
    "print(\"âœ… Class weights computed:\")\n",
    "print(f\"   Class distribution in training data:\")\n",
    "for i in range(5):\n",
    "    count = np.sum(y_tr_indexed == i)\n",
    "    percentage = count / len(y_tr_indexed) * 100\n",
    "    print(f\"      {i+1} star: {count:5d} samples ({percentage:5.2f}%) â†’ weight: {class_weights[i]:.3f}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Class weights will be used during training to handle imbalance\")\n",
    "print(f\"   Minority classes get higher weights â†’ model pays more attention to them\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acfe245",
   "metadata": {},
   "source": [
    "### ğŸ¯ Key Improvements Implemented\n",
    "\n",
    "This notebook now addresses the critical issues from ChatGPT analysis:\n",
    "\n",
    "**âœ… Problem 5 & 7: RNN gets real sequence + Title preserved**\n",
    "- Input changed from `(1024,)` to `(6, 1024)` - true sequence!\n",
    "- TITLE + CHUNKS approach: `[title, sent1, sent2, sent3, sent4, sent5]`\n",
    "- Masking layer handles variable-length sequences\n",
    "- RNN can now learn temporal patterns\n",
    "\n",
    "**âœ… Problem 4: Early stopping on val_loss**\n",
    "- Changed from monitoring `val_accuracy` to `val_loss` (mode='min')\n",
    "- Better overfitting prevention\n",
    "- Should reduce high val_loss (was 0.6-0.8)\n",
    "\n",
    "**âœ… Problem 3: Class imbalance handled**\n",
    "- Computed balanced class weights using sklearn\n",
    "- Applied `class_weight` parameter in `model.fit()`\n",
    "- Minority classes (1-2 stars) get higher attention\n",
    "\n",
    "**âœ… Problem 1: Long reviews handled**\n",
    "- Chunking automatically handles reviews > 256 tokens\n",
    "- Each chunk max 256 tokens (BGE-M3 limit)\n",
    "- No information loss\n",
    "\n",
    "**Expected improvements:**\n",
    "- Val accuracy >> 76% (previous plateau)\n",
    "- Lower val_loss (< 0.6)\n",
    "- Better minority class performance (1-2 stars)\n",
    "- More meaningful hyperparameter differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad51559e",
   "metadata": {},
   "source": [
    "## 3) Modelling RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1fcf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LSTM_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"LSTM_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ reshape_to_sequence (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_hidden (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ reshape_to_sequence (\u001b[38;5;33mReshape\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm_layer (\u001b[38;5;33mLSTM\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m590,336\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_hidden (\u001b[38;5;33mDense\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ output (\u001b[38;5;33mDense\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              â”‚           \u001b[38;5;34m325\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">598,917</span> (2.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m598,917\u001b[0m (2.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">598,917</span> (2.28 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m598,917\u001b[0m (2.28 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… RNN model builder ready\n"
     ]
    }
   ],
   "source": [
    "# RNN Model Builder Function\n",
    "def build_rnn_model(\n",
    "    rnn_type='LSTM',           # 'LSTM', 'GRU', 'BiLSTM', 'BiGRU'\n",
    "    rnn_units=128,             # Number of units in RNN layer\n",
    "    activation='relu',         # Activation for dense layers\n",
    "    dropout=0.2,               # Dropout rate\n",
    "    use_batch_norm=False       # Whether to use batch normalization\n",
    "):\n",
    "    \"\"\"\n",
    "    Build RNN model for 5-class sentiment classification from BGE-M3 chunked embeddings.\n",
    "    \n",
    "    Input: (MAX_CHUNKS_TOTAL, EMBED_DIM) - Sequence of BGE-M3 embeddings [title, sent1, ..., sentN]\n",
    "    Output: (5,) - Probabilities for classes 0-4 (1-5 stars)\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential(name=f\"{rnn_type}_model\")\n",
    "    \n",
    "    # Input: Chunked BGE-M3 embeddings (MAX_CHUNKS_TOTAL, EMBED_DIM)\n",
    "    model.add(layers.Input(shape=(MAX_CHUNKS_TOTAL, EMBED_DIM), name='embedding_input'))\n",
    "    \n",
    "    # Masking layer to ignore zero-padded chunks\n",
    "    model.add(layers.Masking(mask_value=0.0, name='masking'))\n",
    "    \n",
    "    # RNN Layer (using unroll=True to avoid cuDNN and ensure compatibility)\n",
    "    if rnn_type == 'LSTM':\n",
    "        model.add(layers.LSTM(rnn_units, unroll=True, name='lstm_layer'))\n",
    "    elif rnn_type == 'GRU':\n",
    "        model.add(layers.GRU(rnn_units, unroll=True, name='gru_layer'))\n",
    "    elif rnn_type == 'BiLSTM':\n",
    "        model.add(layers.Bidirectional(layers.LSTM(rnn_units, unroll=True), name='bilstm_layer'))\n",
    "    elif rnn_type == 'BiGRU':\n",
    "        model.add(layers.Bidirectional(layers.GRU(rnn_units, unroll=True), name='bigru_layer'))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown rnn_type: {rnn_type}\")\n",
    "    \n",
    "    # Dropout\n",
    "    model.add(layers.Dropout(dropout, name='dropout'))\n",
    "    \n",
    "    # Batch Normalization (optional)\n",
    "    if use_batch_norm:\n",
    "        model.add(layers.BatchNormalization(name='batch_norm'))\n",
    "    \n",
    "    # Dense layer\n",
    "    model.add(layers.Dense(64, activation=activation, name='dense_hidden'))\n",
    "    \n",
    "    # Output layer: 5 classes (0-4 for 1-5 stars)\n",
    "    model.add(layers.Dense(5, activation='softmax', name='output'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Test the model builder\n",
    "test_model = build_rnn_model()\n",
    "test_model.summary()\n",
    "print(\"\\nâœ… RNN model builder ready (TITLE + CHUNKS architecture)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c08824",
   "metadata": {},
   "source": [
    "### 3.1 Hyperparameter Tuning\n",
    "\n",
    "We'll systematically test different RNN configurations to find the optimal hyperparameters:\n",
    "- **RNN Type**: LSTM, GRU, BiLSTM, BiGRU\n",
    "- **Optimizers**: Adam, RMSprop, SGD\n",
    "- **Activations**: relu, tanh, selu\n",
    "- **Dropout**: 0.2, 0.3333\n",
    "- **Batch Normalization**: True, False\n",
    "\n",
    "For each configuration, we'll track:\n",
    "- Training accuracy\n",
    "- Validation accuracy\n",
    "- Training time\n",
    "- Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce6964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to track best validation metrics for W&B\n",
    "class BestMetricsCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Custom callback to track and log best validation metrics to W&B.\n",
    "    Tracks best_val_loss and best_val_accuracy throughout training.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.best_val_acc = 0.0\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            return\n",
    "        \n",
    "        # Update best validation loss\n",
    "        current_val_loss = logs.get('val_loss')\n",
    "        if current_val_loss is not None and current_val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = current_val_loss\n",
    "        \n",
    "        # Update best validation accuracy\n",
    "        current_val_acc = logs.get('val_accuracy')\n",
    "        if current_val_acc is not None and current_val_acc > self.best_val_acc:\n",
    "            self.best_val_acc = current_val_acc\n",
    "        \n",
    "        # Log to W&B\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\n",
    "                'best_val_loss': self.best_val_loss,\n",
    "                'best_val_accuracy': self.best_val_acc\n",
    "            }, step=epoch)\n",
    "\n",
    "print(\"âœ… Custom W&B callback ready (BestMetricsCallback)\")\n",
    "print(\"   Tracks: best_val_loss, best_val_accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1ead6",
   "metadata": {},
   "source": [
    "### ğŸ§ª Quick Architecture Test (1-2 configs)\n",
    "\n",
    "Before running full hyperparameter tuning, let's verify the new TITLE + CHUNKS architecture works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed8c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# QUICK TEST: Verify TITLE + CHUNKS architecture works\n",
    "# Test 2 configs: BiGRU with relu and tanh\n",
    "# ====================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ§ª QUICK ARCHITECTURE TEST\")\n",
    "print(\"=\"*70)\n",
    "print(\"Testing 2 configurations to verify new architecture works correctly\")\n",
    "print(\"If these pass without errors, we can proceed with full tuning\\n\")\n",
    "\n",
    "# Test configs\n",
    "test_configs = [\n",
    "    {'rnn_type': 'BiGRU', 'activation': 'relu', 'dropout': 0.2, 'rnn_units': 128},\n",
    "    {'rnn_type': 'BiGRU', 'activation': 'tanh', 'dropout': 0.2, 'rnn_units': 128}\n",
    "]\n",
    "\n",
    "quick_test_results = []\n",
    "\n",
    "for i, config in enumerate(test_configs, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Test {i}/{len(test_configs)}: {config['rnn_type']} | {config['activation']} | units={config['rnn_units']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Build model\n",
    "    test_model = build_rnn_model(\n",
    "        rnn_type=config['rnn_type'],\n",
    "        rnn_units=config['rnn_units'],\n",
    "        activation=config['activation'],\n",
    "        dropout=config['dropout'],\n",
    "        use_batch_norm=True\n",
    "    )\n",
    "    \n",
    "    # Compile\n",
    "    test_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3,\n",
    "        mode='min',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Best metrics callback\n",
    "    best_metrics_cb = BestMetricsCallback()\n",
    "    \n",
    "    # Train for just 5 epochs to verify it works\n",
    "    print(f\"\\nTraining for 5 epochs (quick test)...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    history = test_model.fit(\n",
    "        train_ds_chunked,\n",
    "        validation_data=val_ds_chunked,\n",
    "        epochs=5,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=[early_stop, best_metrics_cb],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    train_time = time.time() - start_time\n",
    "    \n",
    "    # Get metrics\n",
    "    final_train_acc = history.history['accuracy'][-1]\n",
    "    final_val_acc = history.history['val_accuracy'][-1]\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_val_loss = history.history['val_loss'][-1]\n",
    "    \n",
    "    quick_test_results.append({\n",
    "        'config': f\"{config['rnn_type']}-{config['activation']}\",\n",
    "        'train_acc': final_train_acc,\n",
    "        'val_acc': final_val_acc,\n",
    "        'train_loss': final_train_loss,\n",
    "        'val_loss': final_val_loss,\n",
    "        'time_sec': train_time\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nâœ… Test {i} completed:\")\n",
    "    print(f\"   Train Acc: {final_train_acc:.4f} | Val Acc: {final_val_acc:.4f}\")\n",
    "    print(f\"   Train Loss: {final_train_loss:.4f} | Val Loss: {final_val_loss:.4f}\")\n",
    "    print(f\"   Time: {train_time:.1f}s\")\n",
    "    \n",
    "    # Clear session\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ QUICK TEST SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_df = pd.DataFrame(quick_test_results)\n",
    "print(test_df.to_string(index=False))\n",
    "\n",
    "print(\"\\nâœ… All tests passed! Architecture is working correctly.\")\n",
    "print(\"ğŸ’¡ Key observations:\")\n",
    "print(f\"   - Input shape (6, 1024) works âœ“\")\n",
    "print(f\"   - Masking layer handles variable sequences âœ“\")\n",
    "print(f\"   - Class weights applied correctly âœ“\")\n",
    "print(f\"   - Early stopping on val_loss works âœ“\")\n",
    "print(f\"   - Val accuracy > 0.0 (model is learning) âœ“\")\n",
    "print(\"\\nğŸš€ Ready for full hyperparameter tuning!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1894e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ” RNN HYPERPARAMETER TUNING\n",
      "======================================================================\n",
      "ğŸ“‚ Loaded 180 existing results from partial file\n",
      "   Resuming from config 181...\n",
      "\n",
      "ğŸ“Š Testing 36 configurations...\n",
      "â±ï¸  Estimated time: ~72 minutes (assuming ~2 min per config)\n",
      "\n",
      "â° Note: Each config runs max 50 epochs with early stopping (patience=6)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 181/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | relu | dropout=0.2 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-0862fc18/wandb/run-20251204_044436-jn4tl8h5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jn4tl8h5' target=\"_blank\">RNN-BiGRU-adamw-seed42-0862fc18</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jn4tl8h5' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jn4tl8h5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764819879.346237  290369 service.cc:148] XLA service 0x46d52120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1764819879.346282  290369 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce GTX 1080, Compute Capability 6.1\n",
      "2025-12-04 04:44:39.448596: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1764819879.716650  290369 cuda_dnn.cc:529] Loaded cuDNN version 91501\n",
      "I0000 00:00:1764819879.716650  290369 cuda_dnn.cc:529] Loaded cuDNN version 91501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 48/386\u001b[0m \u001b[32mâ”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5524 - loss: 1.1255"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1764819881.946600  290369 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6872 - loss: 0.7542 - val_accuracy: 0.7097 - val_loss: 0.6841\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - accuracy: 0.6872 - loss: 0.7542 - val_accuracy: 0.7097 - val_loss: 0.6841\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7329 - loss: 0.6352 - val_accuracy: 0.7352 - val_loss: 0.6367\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7329 - loss: 0.6352 - val_accuracy: 0.7352 - val_loss: 0.6367\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.5939 - val_accuracy: 0.7397 - val_loss: 0.6280\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.5939 - val_accuracy: 0.7397 - val_loss: 0.6280\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7655 - loss: 0.5582 - val_accuracy: 0.7423 - val_loss: 0.6242\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7655 - loss: 0.5582 - val_accuracy: 0.7423 - val_loss: 0.6242\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5314 - val_accuracy: 0.7408 - val_loss: 0.6295\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5314 - val_accuracy: 0.7408 - val_loss: 0.6295\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.4976 - val_accuracy: 0.7511 - val_loss: 0.6111\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.4976 - val_accuracy: 0.7511 - val_loss: 0.6111\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4688 - val_accuracy: 0.7360 - val_loss: 0.6673\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4688 - val_accuracy: 0.7360 - val_loss: 0.6673\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8174 - loss: 0.4412 - val_accuracy: 0.7577 - val_loss: 0.6495\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8174 - loss: 0.4412 - val_accuracy: 0.7577 - val_loss: 0.6495\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8255 - loss: 0.4156 - val_accuracy: 0.7515 - val_loss: 0.6442\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8255 - loss: 0.4156 - val_accuracy: 0.7515 - val_loss: 0.6442\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8367 - loss: 0.3947 - val_accuracy: 0.7577 - val_loss: 0.6885\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8367 - loss: 0.3947 - val_accuracy: 0.7577 - val_loss: 0.6885\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.3734 - val_accuracy: 0.7486 - val_loss: 0.7055\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.3734 - val_accuracy: 0.7486 - val_loss: 0.7055\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8540 - loss: 0.3530 - val_accuracy: 0.7592 - val_loss: 0.6869\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8540 - loss: 0.3530 - val_accuracy: 0.7592 - val_loss: 0.6869\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3320 - val_accuracy: 0.7541 - val_loss: 0.7243\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3320 - val_accuracy: 0.7541 - val_loss: 0.7243\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8710 - loss: 0.3217 - val_accuracy: 0.7540 - val_loss: 0.7406\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8710 - loss: 0.3217 - val_accuracy: 0.7540 - val_loss: 0.7406\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8767 - loss: 0.3011 - val_accuracy: 0.7524 - val_loss: 0.7888\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8767 - loss: 0.3011 - val_accuracy: 0.7524 - val_loss: 0.7888\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8849 - loss: 0.2843 - val_accuracy: 0.7491 - val_loss: 0.8157\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8849 - loss: 0.2843 - val_accuracy: 0.7491 - val_loss: 0.8157\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8920 - loss: 0.2709 - val_accuracy: 0.7614 - val_loss: 0.7777\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8920 - loss: 0.2709 - val_accuracy: 0.7614 - val_loss: 0.7777\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8961 - loss: 0.2595 - val_accuracy: 0.7608 - val_loss: 0.8159\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8961 - loss: 0.2595 - val_accuracy: 0.7608 - val_loss: 0.8159\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.2552 - val_accuracy: 0.7616 - val_loss: 0.8847\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8992 - loss: 0.2552 - val_accuracy: 0.7616 - val_loss: 0.8847\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9018 - loss: 0.2473 - val_accuracy: 0.7528 - val_loss: 0.8554\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9018 - loss: 0.2473 - val_accuracy: 0.7528 - val_loss: 0.8554\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2355 - val_accuracy: 0.7504 - val_loss: 0.8610\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.2355 - val_accuracy: 0.7504 - val_loss: 0.8610\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.2262 - val_accuracy: 0.7545 - val_loss: 0.8740\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.2262 - val_accuracy: 0.7545 - val_loss: 0.8740\n",
      "Epoch 23/50\n",
      "\u001b[1m  1/386\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9375 - loss: 0.2084Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2136 - val_accuracy: 0.7558 - val_loss: 0.8597\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2136 - val_accuracy: 0.7558 - val_loss: 0.8597\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9159 - loss: 0.2105 - val_accuracy: 0.7621 - val_loss: 0.9247\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9159 - loss: 0.2105 - val_accuracy: 0.7621 - val_loss: 0.9247\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9222 - loss: 0.1950 - val_accuracy: 0.7441 - val_loss: 0.9593\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9222 - loss: 0.1950 - val_accuracy: 0.7441 - val_loss: 0.9593\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2094 - val_accuracy: 0.7428 - val_loss: 0.9097\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2094 - val_accuracy: 0.7428 - val_loss: 0.9097\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.1995 - val_accuracy: 0.7553 - val_loss: 0.9429\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.1995 - val_accuracy: 0.7553 - val_loss: 0.9429\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9287 - loss: 0.1833 - val_accuracy: 0.7559 - val_loss: 0.9635\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9287 - loss: 0.1833 - val_accuracy: 0.7559 - val_loss: 0.9635\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9300 - loss: 0.1776 - val_accuracy: 0.7616 - val_loss: 0.9634\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9300 - loss: 0.1776 - val_accuracy: 0.7616 - val_loss: 0.9634\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.1834 - val_accuracy: 0.7624 - val_loss: 1.0440\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9286 - loss: 0.1834 - val_accuracy: 0.7624 - val_loss: 1.0440\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9363 - loss: 0.1625 - val_accuracy: 0.7590 - val_loss: 0.9884\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9363 - loss: 0.1625 - val_accuracy: 0.7590 - val_loss: 0.9884\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.1652 - val_accuracy: 0.7569 - val_loss: 1.0052\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.1652 - val_accuracy: 0.7569 - val_loss: 1.0052\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.1628 - val_accuracy: 0.7635 - val_loss: 1.0680\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9383 - loss: 0.1628 - val_accuracy: 0.7635 - val_loss: 1.0680\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.1539 - val_accuracy: 0.7455 - val_loss: 1.0499\n",
      "Epoch 35/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.1539 - val_accuracy: 0.7455 - val_loss: 1.0499\n",
      "Epoch 35/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.1522 - val_accuracy: 0.7614 - val_loss: 1.0546\n",
      "Epoch 36/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.1522 - val_accuracy: 0.7614 - val_loss: 1.0546\n",
      "Epoch 36/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9422 - loss: 0.1505 - val_accuracy: 0.7595 - val_loss: 1.0977\n",
      "Epoch 37/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9422 - loss: 0.1505 - val_accuracy: 0.7595 - val_loss: 1.0977\n",
      "Epoch 37/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9392 - loss: 0.1604 - val_accuracy: 0.7606 - val_loss: 1.0989\n",
      "Epoch 38/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9392 - loss: 0.1604 - val_accuracy: 0.7606 - val_loss: 1.0989\n",
      "Epoch 38/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9428 - loss: 0.1484 - val_accuracy: 0.7603 - val_loss: 1.0804\n",
      "Epoch 39/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9428 - loss: 0.1484 - val_accuracy: 0.7603 - val_loss: 1.0804\n",
      "Epoch 39/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.1442 - val_accuracy: 0.7574 - val_loss: 1.0885\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.1442 - val_accuracy: 0.7574 - val_loss: 1.0885\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "âœ… Train Acc: 0.9449 | Val Acc: 0.7574\n",
      "   Train Loss: 0.1442 | Val Loss: 1.0885\n",
      "   Epochs: 39/50 | Time: 62.6s\n",
      "   ğŸŒŸ NEW BEST MODEL! Val Acc: 0.7574\n",
      "âœ… Train Acc: 0.9449 | Val Acc: 0.7574\n",
      "   Train Loss: 0.1442 | Val Loss: 1.0885\n",
      "   Epochs: 39/50 | Time: 62.6s\n",
      "   ğŸŒŸ NEW BEST MODEL! Val Acc: 0.7574\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–‡â–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–…â–…â–…â–†â–„â–‡â–†â–‡â–†â–‡â–‡â–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–‡â–†â–‡â–‡â–ˆâ–…â–…â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–†â–ˆâ–‡â–ˆâ–ˆâ–‡</td></tr><tr><td>epoch/val_loss</td><td>â–‚â–â–â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–„â–…â–…â–…â–…â–…â–†â–†â–…â–†â–†â–†â–‡â–†â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>39</td></tr><tr><td>best_val_acc</td><td>0.75737</td></tr><tr><td>epoch/accuracy</td><td>0.94494</td></tr><tr><td>epoch/epoch</td><td>38</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.14418</td></tr><tr><td>epoch/val_accuracy</td><td>0.75737</td></tr><tr><td>epoch/val_loss</td><td>1.08845</td></tr><tr><td>final_train_acc</td><td>0.94494</td></tr><tr><td>final_train_loss</td><td>0.14418</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-0862fc18</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jn4tl8h5' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jn4tl8h5</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-0862fc18/wandb/run-20251204_044436-jn4tl8h5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 182/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | relu | dropout=0.2 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-0d53356f/wandb/run-20251204_044544-7o77i3j5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/7o77i3j5' target=\"_blank\">RNN-BiGRU-adamw-seed42-0d53356f</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/7o77i3j5' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/7o77i3j5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6814 - loss: 0.7756 - val_accuracy: 0.7036 - val_loss: 0.7271\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6814 - loss: 0.7756 - val_accuracy: 0.7036 - val_loss: 0.7271\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.6361 - val_accuracy: 0.7339 - val_loss: 0.6483\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7309 - loss: 0.6361 - val_accuracy: 0.7339 - val_loss: 0.6483\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7553 - loss: 0.5889 - val_accuracy: 0.7417 - val_loss: 0.6410\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7553 - loss: 0.5889 - val_accuracy: 0.7417 - val_loss: 0.6410\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7677 - loss: 0.5586 - val_accuracy: 0.7496 - val_loss: 0.6128\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7677 - loss: 0.5586 - val_accuracy: 0.7496 - val_loss: 0.6128\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7832 - loss: 0.5198 - val_accuracy: 0.7536 - val_loss: 0.6165\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7832 - loss: 0.5198 - val_accuracy: 0.7536 - val_loss: 0.6165\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4892 - val_accuracy: 0.7525 - val_loss: 0.6152\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4892 - val_accuracy: 0.7525 - val_loss: 0.6152\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.4567 - val_accuracy: 0.7460 - val_loss: 0.6397\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8099 - loss: 0.4567 - val_accuracy: 0.7460 - val_loss: 0.6397\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8204 - loss: 0.4329 - val_accuracy: 0.7436 - val_loss: 0.6566\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8204 - loss: 0.4329 - val_accuracy: 0.7436 - val_loss: 0.6566\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8331 - loss: 0.4026 - val_accuracy: 0.7535 - val_loss: 0.6614\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8331 - loss: 0.4026 - val_accuracy: 0.7535 - val_loss: 0.6614\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.3760 - val_accuracy: 0.7611 - val_loss: 0.6943\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8458 - loss: 0.3760 - val_accuracy: 0.7611 - val_loss: 0.6943\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3533 - val_accuracy: 0.7593 - val_loss: 0.6952\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3533 - val_accuracy: 0.7593 - val_loss: 0.6952\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8647 - loss: 0.3321 - val_accuracy: 0.7540 - val_loss: 0.7207\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8647 - loss: 0.3321 - val_accuracy: 0.7540 - val_loss: 0.7207\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.3196 - val_accuracy: 0.7653 - val_loss: 0.7173\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.3196 - val_accuracy: 0.7653 - val_loss: 0.7173\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.2965 - val_accuracy: 0.7629 - val_loss: 0.7304\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.2965 - val_accuracy: 0.7629 - val_loss: 0.7304\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.2850 - val_accuracy: 0.7496 - val_loss: 0.7721\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.2850 - val_accuracy: 0.7496 - val_loss: 0.7721\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2623 - val_accuracy: 0.7459 - val_loss: 0.7820\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2623 - val_accuracy: 0.7459 - val_loss: 0.7820\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9003 - loss: 0.2486 - val_accuracy: 0.7652 - val_loss: 0.8071\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9003 - loss: 0.2486 - val_accuracy: 0.7652 - val_loss: 0.8071\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.2407 - val_accuracy: 0.7592 - val_loss: 0.8546\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.2407 - val_accuracy: 0.7592 - val_loss: 0.8546\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.2265 - val_accuracy: 0.7622 - val_loss: 0.8515\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.2265 - val_accuracy: 0.7622 - val_loss: 0.8515\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "âœ… Train Acc: 0.9105 | Val Acc: 0.7622\n",
      "   Train Loss: 0.2265 | Val Loss: 0.8515\n",
      "   Epochs: 19/50 | Time: 36.1s\n",
      "   ğŸŒŸ NEW BEST MODEL! Val Acc: 0.7622\n",
      "âœ… Train Acc: 0.9105 | Val Acc: 0.7622\n",
      "   Train Loss: 0.2265 | Val Loss: 0.8515\n",
      "   Epochs: 19/50 | Time: 36.1s\n",
      "   ğŸŒŸ NEW BEST MODEL! Val Acc: 0.7622\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–…â–†â–‡â–‡â–†â–†â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–†â–†â–ˆâ–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–„â–‚â–‚â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–†â–†â–‡â–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>19</td></tr><tr><td>best_val_acc</td><td>0.76224</td></tr><tr><td>epoch/accuracy</td><td>0.91045</td></tr><tr><td>epoch/epoch</td><td>18</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.22655</td></tr><tr><td>epoch/val_accuracy</td><td>0.76224</td></tr><tr><td>epoch/val_loss</td><td>0.85149</td></tr><tr><td>final_train_acc</td><td>0.91045</td></tr><tr><td>final_train_loss</td><td>0.22655</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-0d53356f</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/7o77i3j5' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/7o77i3j5</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-0d53356f/wandb/run-20251204_044544-7o77i3j5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 183/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | relu | dropout=0.2 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-0a4e1d6e/wandb/run-20251204_044624-izx7f0ft</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/izx7f0ft' target=\"_blank\">RNN-BiGRU-adamw-seed42-0a4e1d6e</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/izx7f0ft' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/izx7f0ft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6820 - loss: 0.7790 - val_accuracy: 0.7044 - val_loss: 0.6953\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6820 - loss: 0.7790 - val_accuracy: 0.7044 - val_loss: 0.6953\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7331 - loss: 0.6355 - val_accuracy: 0.7125 - val_loss: 0.6646\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7331 - loss: 0.6355 - val_accuracy: 0.7125 - val_loss: 0.6646\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.5843 - val_accuracy: 0.7485 - val_loss: 0.6157\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.5843 - val_accuracy: 0.7485 - val_loss: 0.6157\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7744 - loss: 0.5445 - val_accuracy: 0.7524 - val_loss: 0.6149\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7744 - loss: 0.5445 - val_accuracy: 0.7524 - val_loss: 0.6149\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7881 - loss: 0.5082 - val_accuracy: 0.7499 - val_loss: 0.6224\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7881 - loss: 0.5082 - val_accuracy: 0.7499 - val_loss: 0.6224\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7996 - loss: 0.4825 - val_accuracy: 0.7499 - val_loss: 0.6201\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7996 - loss: 0.4825 - val_accuracy: 0.7499 - val_loss: 0.6201\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.4495 - val_accuracy: 0.7428 - val_loss: 0.6366\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8125 - loss: 0.4495 - val_accuracy: 0.7428 - val_loss: 0.6366\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8202 - loss: 0.4283 - val_accuracy: 0.7400 - val_loss: 0.7121\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8202 - loss: 0.4283 - val_accuracy: 0.7400 - val_loss: 0.7121\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.4008 - val_accuracy: 0.7502 - val_loss: 0.6943\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.4008 - val_accuracy: 0.7502 - val_loss: 0.6943\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8442 - loss: 0.3779 - val_accuracy: 0.7596 - val_loss: 0.7117\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8442 - loss: 0.3779 - val_accuracy: 0.7596 - val_loss: 0.7117\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 0.3474 - val_accuracy: 0.7582 - val_loss: 0.7334\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8566 - loss: 0.3474 - val_accuracy: 0.7582 - val_loss: 0.7334\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8709 - loss: 0.3176 - val_accuracy: 0.7574 - val_loss: 0.6988\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8709 - loss: 0.3176 - val_accuracy: 0.7574 - val_loss: 0.6988\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8768 - loss: 0.3057 - val_accuracy: 0.7499 - val_loss: 0.7719\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8768 - loss: 0.3057 - val_accuracy: 0.7499 - val_loss: 0.7719\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.2818 - val_accuracy: 0.7546 - val_loss: 0.7970\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.2818 - val_accuracy: 0.7546 - val_loss: 0.7970\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8959 - loss: 0.2627 - val_accuracy: 0.7467 - val_loss: 0.8698\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8959 - loss: 0.2627 - val_accuracy: 0.7467 - val_loss: 0.8698\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8984 - loss: 0.2529 - val_accuracy: 0.7402 - val_loss: 0.8530\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8984 - loss: 0.2529 - val_accuracy: 0.7402 - val_loss: 0.8530\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "âœ… Train Acc: 0.8984 | Val Acc: 0.7402\n",
      "   Train Loss: 0.2529 | Val Loss: 0.8530\n",
      "   Epochs: 16/50 | Time: 34.4s\n",
      "âœ… Train Acc: 0.8984 | Val Acc: 0.7402\n",
      "   Train Loss: 0.2529 | Val Loss: 0.8530\n",
      "   Epochs: 16/50 | Time: 34.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–‡â–‡â–‡â–‡â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–‚â–â–â–â–â–‚â–„â–ƒâ–„â–„â–ƒâ–…â–†â–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>16</td></tr><tr><td>best_val_acc</td><td>0.74019</td></tr><tr><td>epoch/accuracy</td><td>0.89838</td></tr><tr><td>epoch/epoch</td><td>15</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.2529</td></tr><tr><td>epoch/val_accuracy</td><td>0.74019</td></tr><tr><td>epoch/val_loss</td><td>0.853</td></tr><tr><td>final_train_acc</td><td>0.89838</td></tr><tr><td>final_train_loss</td><td>0.2529</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-0a4e1d6e</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/izx7f0ft' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/izx7f0ft</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-0a4e1d6e/wandb/run-20251204_044624-izx7f0ft/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 184/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | relu | dropout=0.3333 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-c7076dd8/wandb/run-20251204_044702-3fdltr6k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/3fdltr6k' target=\"_blank\">RNN-BiGRU-adamw-seed42-c7076dd8</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/3fdltr6k' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/3fdltr6k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6709 - loss: 0.7986 - val_accuracy: 0.6935 - val_loss: 0.7250\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6709 - loss: 0.7986 - val_accuracy: 0.6935 - val_loss: 0.7250\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7208 - loss: 0.6678 - val_accuracy: 0.7276 - val_loss: 0.6653\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7208 - loss: 0.6678 - val_accuracy: 0.7276 - val_loss: 0.6653\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7358 - loss: 0.6298 - val_accuracy: 0.7340 - val_loss: 0.6423\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7358 - loss: 0.6298 - val_accuracy: 0.7340 - val_loss: 0.6423\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7458 - loss: 0.6008 - val_accuracy: 0.7480 - val_loss: 0.6112\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7458 - loss: 0.6008 - val_accuracy: 0.7480 - val_loss: 0.6112\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7543 - loss: 0.5789 - val_accuracy: 0.7507 - val_loss: 0.6030\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7543 - loss: 0.5789 - val_accuracy: 0.7507 - val_loss: 0.6030\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7686 - loss: 0.5535 - val_accuracy: 0.7391 - val_loss: 0.6344\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7686 - loss: 0.5535 - val_accuracy: 0.7391 - val_loss: 0.6344\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.5323 - val_accuracy: 0.7431 - val_loss: 0.6197\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.5323 - val_accuracy: 0.7431 - val_loss: 0.6197\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7833 - loss: 0.5136 - val_accuracy: 0.7494 - val_loss: 0.6220\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7833 - loss: 0.5136 - val_accuracy: 0.7494 - val_loss: 0.6220\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7930 - loss: 0.4964 - val_accuracy: 0.7524 - val_loss: 0.6260\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7930 - loss: 0.4964 - val_accuracy: 0.7524 - val_loss: 0.6260\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.4759 - val_accuracy: 0.7571 - val_loss: 0.6035\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.4759 - val_accuracy: 0.7571 - val_loss: 0.6035\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.4617 - val_accuracy: 0.7428 - val_loss: 0.6450\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8075 - loss: 0.4617 - val_accuracy: 0.7428 - val_loss: 0.6450\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 0.4396 - val_accuracy: 0.7447 - val_loss: 0.6437\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8167 - loss: 0.4396 - val_accuracy: 0.7447 - val_loss: 0.6437\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8203 - loss: 0.4310 - val_accuracy: 0.7558 - val_loss: 0.6304\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8203 - loss: 0.4310 - val_accuracy: 0.7558 - val_loss: 0.6304\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.4104 - val_accuracy: 0.7614 - val_loss: 0.6417\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8274 - loss: 0.4104 - val_accuracy: 0.7614 - val_loss: 0.6417\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.3954 - val_accuracy: 0.7677 - val_loss: 0.6521\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8359 - loss: 0.3954 - val_accuracy: 0.7677 - val_loss: 0.6521\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.3877 - val_accuracy: 0.7582 - val_loss: 0.6541\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.3877 - val_accuracy: 0.7582 - val_loss: 0.6541\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8430 - loss: 0.3765 - val_accuracy: 0.7627 - val_loss: 0.6637\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8430 - loss: 0.3765 - val_accuracy: 0.7627 - val_loss: 0.6637\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8505 - loss: 0.3596 - val_accuracy: 0.7611 - val_loss: 0.6895\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8505 - loss: 0.3596 - val_accuracy: 0.7611 - val_loss: 0.6895\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 0.3494 - val_accuracy: 0.7470 - val_loss: 0.7065\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8573 - loss: 0.3494 - val_accuracy: 0.7470 - val_loss: 0.7065\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 0.3453 - val_accuracy: 0.7613 - val_loss: 0.6735\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8585 - loss: 0.3453 - val_accuracy: 0.7613 - val_loss: 0.6735\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8660 - loss: 0.3326 - val_accuracy: 0.7648 - val_loss: 0.7101\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8660 - loss: 0.3326 - val_accuracy: 0.7648 - val_loss: 0.7101\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "âœ… Train Acc: 0.8660 | Val Acc: 0.7648\n",
      "   Train Loss: 0.3326 | Val Loss: 0.7101\n",
      "   Epochs: 21/50 | Time: 39.7s\n",
      "   ğŸŒŸ NEW BEST MODEL! Val Acc: 0.7648\n",
      "âœ… Train Acc: 0.8660 | Val Acc: 0.7648\n",
      "   Train Loss: 0.3326 | Val Loss: 0.7101\n",
      "   Epochs: 21/50 | Time: 39.7s\n",
      "   ğŸŒŸ NEW BEST MODEL! Val Acc: 0.7648\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–…â–†â–†â–…â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–†â–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–…â–ƒâ–â–â–ƒâ–‚â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–†â–‡â–…â–‡</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>21</td></tr><tr><td>best_val_acc</td><td>0.76483</td></tr><tr><td>epoch/accuracy</td><td>0.866</td></tr><tr><td>epoch/epoch</td><td>20</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.33256</td></tr><tr><td>epoch/val_accuracy</td><td>0.76483</td></tr><tr><td>epoch/val_loss</td><td>0.71007</td></tr><tr><td>final_train_acc</td><td>0.866</td></tr><tr><td>final_train_loss</td><td>0.33256</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-c7076dd8</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/3fdltr6k' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/3fdltr6k</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-c7076dd8/wandb/run-20251204_044702-3fdltr6k/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 185/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | relu | dropout=0.3333 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-a5c8fac8/wandb/run-20251204_044745-h7r9p53u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/h7r9p53u' target=\"_blank\">RNN-BiGRU-adamw-seed42-a5c8fac8</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/h7r9p53u' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/h7r9p53u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6687 - loss: 0.8111 - val_accuracy: 0.7238 - val_loss: 0.6662\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6687 - loss: 0.8111 - val_accuracy: 0.7238 - val_loss: 0.6662\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7184 - loss: 0.6618 - val_accuracy: 0.7329 - val_loss: 0.6438\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7184 - loss: 0.6618 - val_accuracy: 0.7329 - val_loss: 0.6438\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7408 - loss: 0.6137 - val_accuracy: 0.7455 - val_loss: 0.6207\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7408 - loss: 0.6137 - val_accuracy: 0.7455 - val_loss: 0.6207\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7545 - loss: 0.5870 - val_accuracy: 0.7452 - val_loss: 0.6118\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7545 - loss: 0.5870 - val_accuracy: 0.7452 - val_loss: 0.6118\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7641 - loss: 0.5635 - val_accuracy: 0.7506 - val_loss: 0.6123\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7641 - loss: 0.5635 - val_accuracy: 0.7506 - val_loss: 0.6123\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7743 - loss: 0.5353 - val_accuracy: 0.7520 - val_loss: 0.6110\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7743 - loss: 0.5353 - val_accuracy: 0.7520 - val_loss: 0.6110\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.5102 - val_accuracy: 0.7442 - val_loss: 0.6311\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.5102 - val_accuracy: 0.7442 - val_loss: 0.6311\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.4915 - val_accuracy: 0.7575 - val_loss: 0.6129\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.4915 - val_accuracy: 0.7575 - val_loss: 0.6129\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4725 - val_accuracy: 0.7546 - val_loss: 0.6248\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4725 - val_accuracy: 0.7546 - val_loss: 0.6248\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8119 - loss: 0.4520 - val_accuracy: 0.7619 - val_loss: 0.6132\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8119 - loss: 0.4520 - val_accuracy: 0.7619 - val_loss: 0.6132\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8157 - loss: 0.4386 - val_accuracy: 0.7548 - val_loss: 0.6559\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8157 - loss: 0.4386 - val_accuracy: 0.7548 - val_loss: 0.6559\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.4201 - val_accuracy: 0.7676 - val_loss: 0.6533\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.4201 - val_accuracy: 0.7676 - val_loss: 0.6533\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8341 - loss: 0.4029 - val_accuracy: 0.7606 - val_loss: 0.6591\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8341 - loss: 0.4029 - val_accuracy: 0.7606 - val_loss: 0.6591\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8360 - loss: 0.3926 - val_accuracy: 0.7661 - val_loss: 0.6696\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8360 - loss: 0.3926 - val_accuracy: 0.7661 - val_loss: 0.6696\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8468 - loss: 0.3698 - val_accuracy: 0.7692 - val_loss: 0.6676\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8468 - loss: 0.3698 - val_accuracy: 0.7692 - val_loss: 0.6676\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.3494 - val_accuracy: 0.7551 - val_loss: 0.7183\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8566 - loss: 0.3494 - val_accuracy: 0.7551 - val_loss: 0.7183\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8556 - loss: 0.3499 - val_accuracy: 0.7605 - val_loss: 0.7077\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8556 - loss: 0.3499 - val_accuracy: 0.7605 - val_loss: 0.7077\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3256 - val_accuracy: 0.7606 - val_loss: 0.7345\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3256 - val_accuracy: 0.7606 - val_loss: 0.7345\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8683 - loss: 0.3222 - val_accuracy: 0.7640 - val_loss: 0.7352\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8683 - loss: 0.3222 - val_accuracy: 0.7640 - val_loss: 0.7352\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8709 - loss: 0.3157 - val_accuracy: 0.7668 - val_loss: 0.7092\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8709 - loss: 0.3157 - val_accuracy: 0.7668 - val_loss: 0.7092\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8768 - loss: 0.3019 - val_accuracy: 0.7720 - val_loss: 0.7884\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8768 - loss: 0.3019 - val_accuracy: 0.7720 - val_loss: 0.7884\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.2935 - val_accuracy: 0.7600 - val_loss: 0.7902\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8784 - loss: 0.2935 - val_accuracy: 0.7600 - val_loss: 0.7902\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.2861 - val_accuracy: 0.7647 - val_loss: 0.8025\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.2861 - val_accuracy: 0.7647 - val_loss: 0.8025\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8907 - loss: 0.2733 - val_accuracy: 0.7684 - val_loss: 0.7922\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8907 - loss: 0.2733 - val_accuracy: 0.7684 - val_loss: 0.7922\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8897 - loss: 0.2726 - val_accuracy: 0.7645 - val_loss: 0.7759\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8897 - loss: 0.2726 - val_accuracy: 0.7645 - val_loss: 0.7759\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.2576 - val_accuracy: 0.7697 - val_loss: 0.7770\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8931 - loss: 0.2576 - val_accuracy: 0.7697 - val_loss: 0.7770\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8994 - loss: 0.2510 - val_accuracy: 0.7598 - val_loss: 0.8261\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8994 - loss: 0.2510 - val_accuracy: 0.7598 - val_loss: 0.8261\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "âœ… Train Acc: 0.8994 | Val Acc: 0.7598\n",
      "   Train Loss: 0.2510 | Val Loss: 0.8261\n",
      "   Epochs: 27/50 | Time: 48.2s\n",
      "âœ… Train Acc: 0.8994 | Val Acc: 0.7598\n",
      "   Train Loss: 0.2510 | Val Loss: 0.8261\n",
      "   Epochs: 27/50 | Time: 48.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–„â–„â–…â–…â–„â–†â–…â–‡â–†â–‡â–†â–‡â–ˆâ–†â–†â–†â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–ˆâ–†</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–‚â–â–â–â–â–‚â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–„â–‡â–‡â–‡â–‡â–†â–†â–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>27</td></tr><tr><td>best_val_acc</td><td>0.75981</td></tr><tr><td>epoch/accuracy</td><td>0.89939</td></tr><tr><td>epoch/epoch</td><td>26</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.25096</td></tr><tr><td>epoch/val_accuracy</td><td>0.75981</td></tr><tr><td>epoch/val_loss</td><td>0.82614</td></tr><tr><td>final_train_acc</td><td>0.89939</td></tr><tr><td>final_train_loss</td><td>0.25096</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-a5c8fac8</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/h7r9p53u' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/h7r9p53u</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-a5c8fac8/wandb/run-20251204_044745-h7r9p53u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ’¾ Progress saved (185/36)\n",
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 186/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | relu | dropout=0.3333 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-ae8d1c9f/wandb/run-20251204_044837-njosydp1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/njosydp1' target=\"_blank\">RNN-BiGRU-adamw-seed42-ae8d1c9f</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/njosydp1' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/njosydp1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6708 - loss: 0.8065 - val_accuracy: 0.7264 - val_loss: 0.6729\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6708 - loss: 0.8065 - val_accuracy: 0.7264 - val_loss: 0.6729\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.6657 - val_accuracy: 0.7332 - val_loss: 0.6470\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7188 - loss: 0.6657 - val_accuracy: 0.7332 - val_loss: 0.6470\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7371 - loss: 0.6190 - val_accuracy: 0.7342 - val_loss: 0.6337\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7371 - loss: 0.6190 - val_accuracy: 0.7342 - val_loss: 0.6337\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7528 - loss: 0.5863 - val_accuracy: 0.7489 - val_loss: 0.6095\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7528 - loss: 0.5863 - val_accuracy: 0.7489 - val_loss: 0.6095\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7651 - loss: 0.5549 - val_accuracy: 0.7506 - val_loss: 0.6132\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7651 - loss: 0.5549 - val_accuracy: 0.7506 - val_loss: 0.6132\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.5369 - val_accuracy: 0.7514 - val_loss: 0.5994\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.5369 - val_accuracy: 0.7514 - val_loss: 0.5994\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.5034 - val_accuracy: 0.7558 - val_loss: 0.6082\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.5034 - val_accuracy: 0.7558 - val_loss: 0.6082\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4830 - val_accuracy: 0.7575 - val_loss: 0.6458\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.4830 - val_accuracy: 0.7575 - val_loss: 0.6458\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4666 - val_accuracy: 0.7567 - val_loss: 0.6314\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8032 - loss: 0.4666 - val_accuracy: 0.7567 - val_loss: 0.6314\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.4445 - val_accuracy: 0.7504 - val_loss: 0.6525\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.4445 - val_accuracy: 0.7504 - val_loss: 0.6525\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8242 - loss: 0.4227 - val_accuracy: 0.7619 - val_loss: 0.6571\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8242 - loss: 0.4227 - val_accuracy: 0.7619 - val_loss: 0.6571\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8289 - loss: 0.4115 - val_accuracy: 0.7630 - val_loss: 0.6521\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8289 - loss: 0.4115 - val_accuracy: 0.7630 - val_loss: 0.6521\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.3932 - val_accuracy: 0.7650 - val_loss: 0.6403\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.3932 - val_accuracy: 0.7650 - val_loss: 0.6403\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8411 - loss: 0.3795 - val_accuracy: 0.7603 - val_loss: 0.6826\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8411 - loss: 0.3795 - val_accuracy: 0.7603 - val_loss: 0.6826\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8482 - loss: 0.3613 - val_accuracy: 0.7715 - val_loss: 0.6625\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8482 - loss: 0.3613 - val_accuracy: 0.7715 - val_loss: 0.6625\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8622 - loss: 0.3377 - val_accuracy: 0.7703 - val_loss: 0.7146\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8622 - loss: 0.3377 - val_accuracy: 0.7703 - val_loss: 0.7146\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8650 - loss: 0.3242 - val_accuracy: 0.7618 - val_loss: 0.7209\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8650 - loss: 0.3242 - val_accuracy: 0.7618 - val_loss: 0.7209\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8675 - loss: 0.3171 - val_accuracy: 0.7640 - val_loss: 0.7673\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8675 - loss: 0.3171 - val_accuracy: 0.7640 - val_loss: 0.7673\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8755 - loss: 0.3013 - val_accuracy: 0.7575 - val_loss: 0.7346\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8755 - loss: 0.3013 - val_accuracy: 0.7575 - val_loss: 0.7346\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.2968 - val_accuracy: 0.7729 - val_loss: 0.7439\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.2968 - val_accuracy: 0.7729 - val_loss: 0.7439\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 0.2829 - val_accuracy: 0.7489 - val_loss: 0.7959\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 0.2829 - val_accuracy: 0.7489 - val_loss: 0.7959\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8913 - loss: 0.2721 - val_accuracy: 0.7611 - val_loss: 0.7486\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8913 - loss: 0.2721 - val_accuracy: 0.7611 - val_loss: 0.7486\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.2684 - val_accuracy: 0.7669 - val_loss: 0.7779\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.2684 - val_accuracy: 0.7669 - val_loss: 0.7779\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8981 - loss: 0.2588 - val_accuracy: 0.7614 - val_loss: 0.8301\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8981 - loss: 0.2588 - val_accuracy: 0.7614 - val_loss: 0.8301\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9013 - loss: 0.2497 - val_accuracy: 0.7592 - val_loss: 0.8281\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9013 - loss: 0.2497 - val_accuracy: 0.7592 - val_loss: 0.8281\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 0.2382 - val_accuracy: 0.7592 - val_loss: 0.8233\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 0.2382 - val_accuracy: 0.7592 - val_loss: 0.8233\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "âœ… Train Acc: 0.9055 | Val Acc: 0.7592\n",
      "   Train Loss: 0.2382 | Val Loss: 0.8233\n",
      "   Epochs: 26/50 | Time: 48.6s\n",
      "âœ… Train Acc: 0.9055 | Val Acc: 0.7592\n",
      "   Train Loss: 0.2382 | Val Loss: 0.8233\n",
      "   Epochs: 26/50 | Time: 48.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–‚â–„â–…â–…â–…â–†â–†â–…â–†â–‡â–‡â–†â–ˆâ–ˆâ–†â–‡â–†â–ˆâ–„â–†â–‡â–†â–†â–†</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–‚â–‚â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–„â–…â–†â–…â–…â–‡â–†â–†â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>26</td></tr><tr><td>best_val_acc</td><td>0.75916</td></tr><tr><td>epoch/accuracy</td><td>0.90547</td></tr><tr><td>epoch/epoch</td><td>25</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.23816</td></tr><tr><td>epoch/val_accuracy</td><td>0.75916</td></tr><tr><td>epoch/val_loss</td><td>0.82333</td></tr><tr><td>final_train_acc</td><td>0.90547</td></tr><tr><td>final_train_loss</td><td>0.23816</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-ae8d1c9f</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/njosydp1' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/njosydp1</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-ae8d1c9f/wandb/run-20251204_044837-njosydp1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 187/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | tanh | dropout=0.2 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-a871d11f/wandb/run-20251204_044930-fr4dlo07</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/fr4dlo07' target=\"_blank\">RNN-BiGRU-adamw-seed42-a871d11f</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/fr4dlo07' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/fr4dlo07</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6817 - loss: 0.8022 - val_accuracy: 0.7209 - val_loss: 0.6805\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6817 - loss: 0.8022 - val_accuracy: 0.7209 - val_loss: 0.6805\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7281 - loss: 0.6458 - val_accuracy: 0.7300 - val_loss: 0.6437\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7281 - loss: 0.6458 - val_accuracy: 0.7300 - val_loss: 0.6437\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7481 - loss: 0.6004 - val_accuracy: 0.7352 - val_loss: 0.6266\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7481 - loss: 0.6004 - val_accuracy: 0.7352 - val_loss: 0.6266\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7617 - loss: 0.5692 - val_accuracy: 0.7502 - val_loss: 0.6210\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7617 - loss: 0.5692 - val_accuracy: 0.7502 - val_loss: 0.6210\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.5421 - val_accuracy: 0.7496 - val_loss: 0.6128\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7746 - loss: 0.5421 - val_accuracy: 0.7496 - val_loss: 0.6128\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.5148 - val_accuracy: 0.7478 - val_loss: 0.6111\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7876 - loss: 0.5148 - val_accuracy: 0.7478 - val_loss: 0.6111\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4776 - val_accuracy: 0.7498 - val_loss: 0.6181\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4776 - val_accuracy: 0.7498 - val_loss: 0.6181\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 0.4568 - val_accuracy: 0.7494 - val_loss: 0.6491\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 0.4568 - val_accuracy: 0.7494 - val_loss: 0.6491\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4292 - val_accuracy: 0.7515 - val_loss: 0.6482\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8264 - loss: 0.4292 - val_accuracy: 0.7515 - val_loss: 0.6482\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: 0.4018 - val_accuracy: 0.7489 - val_loss: 0.6462\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8364 - loss: 0.4018 - val_accuracy: 0.7489 - val_loss: 0.6462\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.3767 - val_accuracy: 0.7520 - val_loss: 0.6730\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.3767 - val_accuracy: 0.7520 - val_loss: 0.6730\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8505 - loss: 0.3665 - val_accuracy: 0.7598 - val_loss: 0.6943\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8505 - loss: 0.3665 - val_accuracy: 0.7598 - val_loss: 0.6943\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8635 - loss: 0.3448 - val_accuracy: 0.7605 - val_loss: 0.6912\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8635 - loss: 0.3448 - val_accuracy: 0.7605 - val_loss: 0.6912\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8641 - loss: 0.3355 - val_accuracy: 0.7545 - val_loss: 0.7090\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8641 - loss: 0.3355 - val_accuracy: 0.7545 - val_loss: 0.7090\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8731 - loss: 0.3130 - val_accuracy: 0.7611 - val_loss: 0.7359\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8731 - loss: 0.3130 - val_accuracy: 0.7611 - val_loss: 0.7359\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8841 - loss: 0.2944 - val_accuracy: 0.7536 - val_loss: 0.7678\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8841 - loss: 0.2944 - val_accuracy: 0.7536 - val_loss: 0.7678\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8890 - loss: 0.2802 - val_accuracy: 0.7585 - val_loss: 0.7438\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8890 - loss: 0.2802 - val_accuracy: 0.7585 - val_loss: 0.7438\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.2684 - val_accuracy: 0.7580 - val_loss: 0.7798\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8910 - loss: 0.2684 - val_accuracy: 0.7580 - val_loss: 0.7798\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8967 - loss: 0.2642 - val_accuracy: 0.7316 - val_loss: 0.8202\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8967 - loss: 0.2642 - val_accuracy: 0.7316 - val_loss: 0.8202\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9024 - loss: 0.2470 - val_accuracy: 0.7611 - val_loss: 0.7915\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9024 - loss: 0.2470 - val_accuracy: 0.7611 - val_loss: 0.7915\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9073 - loss: 0.2388 - val_accuracy: 0.7446 - val_loss: 0.8313\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9073 - loss: 0.2388 - val_accuracy: 0.7446 - val_loss: 0.8313\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "âœ… Train Acc: 0.9073 | Val Acc: 0.7446\n",
      "   Train Loss: 0.2388 | Val Loss: 0.8313\n",
      "   Epochs: 21/50 | Time: 40.6s\n",
      "âœ… Train Acc: 0.9073 | Val Acc: 0.7446\n",
      "   Train Loss: 0.2388 | Val Loss: 0.8313\n",
      "   Epochs: 21/50 | Time: 40.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–ƒâ–†â–†â–†â–†â–†â–†â–†â–†â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ƒâ–ˆâ–…</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–‚â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–„â–„â–„â–…â–†â–…â–†â–ˆâ–‡â–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>21</td></tr><tr><td>best_val_acc</td><td>0.74457</td></tr><tr><td>epoch/accuracy</td><td>0.90733</td></tr><tr><td>epoch/epoch</td><td>20</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.23878</td></tr><tr><td>epoch/val_accuracy</td><td>0.74457</td></tr><tr><td>epoch/val_loss</td><td>0.83134</td></tr><tr><td>final_train_acc</td><td>0.90733</td></tr><tr><td>final_train_loss</td><td>0.23878</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-a871d11f</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/fr4dlo07' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/fr4dlo07</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-a871d11f/wandb/run-20251204_044930-fr4dlo07/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 188/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | tanh | dropout=0.2 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-fb4e1ec5/wandb/run-20251204_045014-pk48cd5d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/pk48cd5d' target=\"_blank\">RNN-BiGRU-adamw-seed42-fb4e1ec5</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/pk48cd5d' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/pk48cd5d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.6844 - loss: 0.7946 - val_accuracy: 0.7138 - val_loss: 0.6917\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.6844 - loss: 0.7946 - val_accuracy: 0.7138 - val_loss: 0.6917\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7323 - loss: 0.6479 - val_accuracy: 0.7405 - val_loss: 0.6364\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7323 - loss: 0.6479 - val_accuracy: 0.7405 - val_loss: 0.6364\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7509 - loss: 0.5967 - val_accuracy: 0.7282 - val_loss: 0.6487\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7509 - loss: 0.5967 - val_accuracy: 0.7282 - val_loss: 0.6487\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7669 - loss: 0.5630 - val_accuracy: 0.7512 - val_loss: 0.6094\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7669 - loss: 0.5630 - val_accuracy: 0.7512 - val_loss: 0.6094\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.5283 - val_accuracy: 0.7417 - val_loss: 0.6492\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.5283 - val_accuracy: 0.7417 - val_loss: 0.6492\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7950 - loss: 0.4946 - val_accuracy: 0.7446 - val_loss: 0.6571\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7950 - loss: 0.4946 - val_accuracy: 0.7446 - val_loss: 0.6571\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4706 - val_accuracy: 0.7515 - val_loss: 0.6444\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8054 - loss: 0.4706 - val_accuracy: 0.7515 - val_loss: 0.6444\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 0.4426 - val_accuracy: 0.7391 - val_loss: 0.6598\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 0.4426 - val_accuracy: 0.7391 - val_loss: 0.6598\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.4126 - val_accuracy: 0.7512 - val_loss: 0.6561\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8327 - loss: 0.4126 - val_accuracy: 0.7512 - val_loss: 0.6561\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8455 - loss: 0.3805 - val_accuracy: 0.7561 - val_loss: 0.6699\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8455 - loss: 0.3805 - val_accuracy: 0.7561 - val_loss: 0.6699\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8548 - loss: 0.3602 - val_accuracy: 0.7485 - val_loss: 0.6832\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8548 - loss: 0.3602 - val_accuracy: 0.7485 - val_loss: 0.6832\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8613 - loss: 0.3416 - val_accuracy: 0.7496 - val_loss: 0.7142\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8613 - loss: 0.3416 - val_accuracy: 0.7496 - val_loss: 0.7142\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8716 - loss: 0.3218 - val_accuracy: 0.7549 - val_loss: 0.7196\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8716 - loss: 0.3218 - val_accuracy: 0.7549 - val_loss: 0.7196\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8780 - loss: 0.3080 - val_accuracy: 0.7506 - val_loss: 0.7405\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8780 - loss: 0.3080 - val_accuracy: 0.7506 - val_loss: 0.7405\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8894 - loss: 0.2808 - val_accuracy: 0.7608 - val_loss: 0.7629\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8894 - loss: 0.2808 - val_accuracy: 0.7608 - val_loss: 0.7629\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.2671 - val_accuracy: 0.7564 - val_loss: 0.8052\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8944 - loss: 0.2671 - val_accuracy: 0.7564 - val_loss: 0.8052\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9033 - loss: 0.2500 - val_accuracy: 0.7614 - val_loss: 0.8040\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9033 - loss: 0.2500 - val_accuracy: 0.7614 - val_loss: 0.8040\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9041 - loss: 0.2452 - val_accuracy: 0.7567 - val_loss: 0.8152\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9041 - loss: 0.2452 - val_accuracy: 0.7567 - val_loss: 0.8152\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9116 - loss: 0.2258 - val_accuracy: 0.7650 - val_loss: 0.8016\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9116 - loss: 0.2258 - val_accuracy: 0.7650 - val_loss: 0.8016\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.2185 - val_accuracy: 0.7627 - val_loss: 0.8420\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.2185 - val_accuracy: 0.7627 - val_loss: 0.8420\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2082 - val_accuracy: 0.7564 - val_loss: 0.8669\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2082 - val_accuracy: 0.7564 - val_loss: 0.8669\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.1987 - val_accuracy: 0.7559 - val_loss: 0.8588\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.1987 - val_accuracy: 0.7559 - val_loss: 0.8588\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9265 - loss: 0.1912 - val_accuracy: 0.7588 - val_loss: 0.8927\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9265 - loss: 0.1912 - val_accuracy: 0.7588 - val_loss: 0.8927\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.1858 - val_accuracy: 0.7624 - val_loss: 0.9076\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9279 - loss: 0.1858 - val_accuracy: 0.7624 - val_loss: 0.9076\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9281 - loss: 0.1846 - val_accuracy: 0.7545 - val_loss: 0.9276\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9281 - loss: 0.1846 - val_accuracy: 0.7545 - val_loss: 0.9276\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "âœ… Train Acc: 0.9281 | Val Acc: 0.7545\n",
      "   Train Loss: 0.1846 | Val Loss: 0.9276\n",
      "   Epochs: 25/50 | Time: 45.8s\n",
      "âœ… Train Acc: 0.9281 | Val Acc: 0.7545\n",
      "   Train Loss: 0.1846 | Val Loss: 0.9276\n",
      "   Epochs: 25/50 | Time: 45.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–…â–ƒâ–†â–…â–…â–†â–„â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–…â–†â–‡â–†â–‡â–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>25</td></tr><tr><td>best_val_acc</td><td>0.75446</td></tr><tr><td>epoch/accuracy</td><td>0.92808</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.18457</td></tr><tr><td>epoch/val_accuracy</td><td>0.75446</td></tr><tr><td>epoch/val_loss</td><td>0.92761</td></tr><tr><td>final_train_acc</td><td>0.92808</td></tr><tr><td>final_train_loss</td><td>0.18457</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-fb4e1ec5</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/pk48cd5d' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/pk48cd5d</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-fb4e1ec5/wandb/run-20251204_045014-pk48cd5d/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 189/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | tanh | dropout=0.2 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-ebe1a488/wandb/run-20251204_045104-l4653al0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/l4653al0' target=\"_blank\">RNN-BiGRU-adamw-seed42-ebe1a488</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/l4653al0' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/l4653al0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6821 - loss: 0.8009 - val_accuracy: 0.7053 - val_loss: 0.7417\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6821 - loss: 0.8009 - val_accuracy: 0.7053 - val_loss: 0.7417\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7286 - loss: 0.6475 - val_accuracy: 0.7355 - val_loss: 0.6559\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7286 - loss: 0.6475 - val_accuracy: 0.7355 - val_loss: 0.6559\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.5951 - val_accuracy: 0.7478 - val_loss: 0.6369\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.5951 - val_accuracy: 0.7478 - val_loss: 0.6369\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7711 - loss: 0.5545 - val_accuracy: 0.7457 - val_loss: 0.6226\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7711 - loss: 0.5545 - val_accuracy: 0.7457 - val_loss: 0.6226\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7857 - loss: 0.5204 - val_accuracy: 0.7292 - val_loss: 0.6455\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7857 - loss: 0.5204 - val_accuracy: 0.7292 - val_loss: 0.6455\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.4958 - val_accuracy: 0.7556 - val_loss: 0.6320\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.4958 - val_accuracy: 0.7556 - val_loss: 0.6320\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.4637 - val_accuracy: 0.7473 - val_loss: 0.6247\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8110 - loss: 0.4637 - val_accuracy: 0.7473 - val_loss: 0.6247\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8265 - loss: 0.4279 - val_accuracy: 0.7658 - val_loss: 0.6305\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8265 - loss: 0.4279 - val_accuracy: 0.7658 - val_loss: 0.6305\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8373 - loss: 0.4003 - val_accuracy: 0.7433 - val_loss: 0.6591\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8373 - loss: 0.4003 - val_accuracy: 0.7433 - val_loss: 0.6591\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8490 - loss: 0.3742 - val_accuracy: 0.7566 - val_loss: 0.6518\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8490 - loss: 0.3742 - val_accuracy: 0.7566 - val_loss: 0.6518\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 0.3537 - val_accuracy: 0.7616 - val_loss: 0.6830\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 0.3537 - val_accuracy: 0.7616 - val_loss: 0.6830\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.3236 - val_accuracy: 0.7543 - val_loss: 0.6892\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8703 - loss: 0.3236 - val_accuracy: 0.7543 - val_loss: 0.6892\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8773 - loss: 0.3062 - val_accuracy: 0.7494 - val_loss: 0.7516\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8773 - loss: 0.3062 - val_accuracy: 0.7494 - val_loss: 0.7516\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.2928 - val_accuracy: 0.7501 - val_loss: 0.7426\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.2928 - val_accuracy: 0.7501 - val_loss: 0.7426\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "âœ… Train Acc: 0.8846 | Val Acc: 0.7501\n",
      "   Train Loss: 0.2928 | Val Loss: 0.7426\n",
      "   Epochs: 14/50 | Time: 30.2s\n",
      "âœ… Train Acc: 0.8846 | Val Acc: 0.7501\n",
      "   Train Loss: 0.2928 | Val Loss: 0.7426\n",
      "   Epochs: 14/50 | Time: 30.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–…â–…â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–†â–†â–„â–‡â–†â–ˆâ–…â–‡â–ˆâ–‡â–†â–†</td></tr><tr><td>epoch/val_loss</td><td>â–‡â–ƒâ–‚â–â–‚â–‚â–â–â–ƒâ–ƒâ–„â–…â–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>14</td></tr><tr><td>best_val_acc</td><td>0.75008</td></tr><tr><td>epoch/accuracy</td><td>0.88464</td></tr><tr><td>epoch/epoch</td><td>13</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.29277</td></tr><tr><td>epoch/val_accuracy</td><td>0.75008</td></tr><tr><td>epoch/val_loss</td><td>0.74262</td></tr><tr><td>final_train_acc</td><td>0.88464</td></tr><tr><td>final_train_loss</td><td>0.29277</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-ebe1a488</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/l4653al0' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/l4653al0</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-ebe1a488/wandb/run-20251204_045104-l4653al0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 190/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | tanh | dropout=0.3333 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-ece8fe8b/wandb/run-20251204_045138-ilpso9xr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ilpso9xr' target=\"_blank\">RNN-BiGRU-adamw-seed42-ece8fe8b</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ilpso9xr' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ilpso9xr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6738 - loss: 0.8239 - val_accuracy: 0.6898 - val_loss: 0.7453\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6738 - loss: 0.8239 - val_accuracy: 0.6898 - val_loss: 0.7453\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7173 - loss: 0.6711 - val_accuracy: 0.7267 - val_loss: 0.6515\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7173 - loss: 0.6711 - val_accuracy: 0.7267 - val_loss: 0.6515\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.6357 - val_accuracy: 0.7323 - val_loss: 0.6486\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7329 - loss: 0.6357 - val_accuracy: 0.7323 - val_loss: 0.6486\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7461 - loss: 0.6080 - val_accuracy: 0.7387 - val_loss: 0.6411\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7461 - loss: 0.6080 - val_accuracy: 0.7387 - val_loss: 0.6411\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.5864 - val_accuracy: 0.7412 - val_loss: 0.6538\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7547 - loss: 0.5864 - val_accuracy: 0.7412 - val_loss: 0.6538\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7651 - loss: 0.5589 - val_accuracy: 0.7444 - val_loss: 0.6245\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7651 - loss: 0.5589 - val_accuracy: 0.7444 - val_loss: 0.6245\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7761 - loss: 0.5378 - val_accuracy: 0.7465 - val_loss: 0.6316\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7761 - loss: 0.5378 - val_accuracy: 0.7465 - val_loss: 0.6316\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.5269 - val_accuracy: 0.7473 - val_loss: 0.6380\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.5269 - val_accuracy: 0.7473 - val_loss: 0.6380\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7926 - loss: 0.5009 - val_accuracy: 0.7481 - val_loss: 0.6345\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7926 - loss: 0.5009 - val_accuracy: 0.7481 - val_loss: 0.6345\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.4798 - val_accuracy: 0.7467 - val_loss: 0.6386\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8015 - loss: 0.4798 - val_accuracy: 0.7467 - val_loss: 0.6386\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.4635 - val_accuracy: 0.7551 - val_loss: 0.6322\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.4635 - val_accuracy: 0.7551 - val_loss: 0.6322\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 0.4491 - val_accuracy: 0.7582 - val_loss: 0.6454\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8129 - loss: 0.4491 - val_accuracy: 0.7582 - val_loss: 0.6454\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.4339 - val_accuracy: 0.7600 - val_loss: 0.6499\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.4339 - val_accuracy: 0.7600 - val_loss: 0.6499\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8297 - loss: 0.4194 - val_accuracy: 0.7564 - val_loss: 0.6555\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8297 - loss: 0.4194 - val_accuracy: 0.7564 - val_loss: 0.6555\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8352 - loss: 0.4064 - val_accuracy: 0.7653 - val_loss: 0.6519\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8352 - loss: 0.4064 - val_accuracy: 0.7653 - val_loss: 0.6519\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8389 - loss: 0.3957 - val_accuracy: 0.7598 - val_loss: 0.6574\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8389 - loss: 0.3957 - val_accuracy: 0.7598 - val_loss: 0.6574\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.3855 - val_accuracy: 0.7559 - val_loss: 0.6750\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8436 - loss: 0.3855 - val_accuracy: 0.7559 - val_loss: 0.6750\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8476 - loss: 0.3748 - val_accuracy: 0.7590 - val_loss: 0.7012\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8476 - loss: 0.3748 - val_accuracy: 0.7590 - val_loss: 0.7012\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3580 - val_accuracy: 0.7519 - val_loss: 0.6981\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.3580 - val_accuracy: 0.7519 - val_loss: 0.6981\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 0.3485 - val_accuracy: 0.7637 - val_loss: 0.7020\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8596 - loss: 0.3485 - val_accuracy: 0.7637 - val_loss: 0.7020\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.3339 - val_accuracy: 0.7629 - val_loss: 0.7066\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8648 - loss: 0.3339 - val_accuracy: 0.7629 - val_loss: 0.7066\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "âœ… Train Acc: 0.8648 | Val Acc: 0.7629\n",
      "   Train Loss: 0.3339 | Val Loss: 0.7066\n",
      "   Epochs: 21/50 | Time: 40.4s\n",
      "âœ… Train Acc: 0.8648 | Val Acc: 0.7629\n",
      "   Train Loss: 0.3339 | Val Loss: 0.7066\n",
      "   Epochs: 21/50 | Time: 40.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ƒâ–‚â–‚â–ƒâ–â–â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–†</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>21</td></tr><tr><td>best_val_acc</td><td>0.76288</td></tr><tr><td>epoch/accuracy</td><td>0.86483</td></tr><tr><td>epoch/epoch</td><td>20</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.33387</td></tr><tr><td>epoch/val_accuracy</td><td>0.76288</td></tr><tr><td>epoch/val_loss</td><td>0.70661</td></tr><tr><td>final_train_acc</td><td>0.86483</td></tr><tr><td>final_train_loss</td><td>0.33387</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-ece8fe8b</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ilpso9xr' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ilpso9xr</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-ece8fe8b/wandb/run-20251204_045138-ilpso9xr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ’¾ Progress saved (190/36)\n",
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 191/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | tanh | dropout=0.3333 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-5582e865/wandb/run-20251204_045222-elsbv9cw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/elsbv9cw' target=\"_blank\">RNN-BiGRU-adamw-seed42-5582e865</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/elsbv9cw' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/elsbv9cw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6723 - loss: 0.8254 - val_accuracy: 0.7212 - val_loss: 0.6863\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6723 - loss: 0.8254 - val_accuracy: 0.7212 - val_loss: 0.6863\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7202 - loss: 0.6697 - val_accuracy: 0.7279 - val_loss: 0.6670\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7202 - loss: 0.6697 - val_accuracy: 0.7279 - val_loss: 0.6670\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.6282 - val_accuracy: 0.7384 - val_loss: 0.6353\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.6282 - val_accuracy: 0.7384 - val_loss: 0.6353\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7520 - loss: 0.5950 - val_accuracy: 0.7423 - val_loss: 0.6387\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7520 - loss: 0.5950 - val_accuracy: 0.7423 - val_loss: 0.6387\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7662 - loss: 0.5664 - val_accuracy: 0.7494 - val_loss: 0.6212\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7662 - loss: 0.5664 - val_accuracy: 0.7494 - val_loss: 0.6212\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7707 - loss: 0.5497 - val_accuracy: 0.7486 - val_loss: 0.6299\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7707 - loss: 0.5497 - val_accuracy: 0.7486 - val_loss: 0.6299\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.5276 - val_accuracy: 0.7310 - val_loss: 0.6880\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.5276 - val_accuracy: 0.7310 - val_loss: 0.6880\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.5109 - val_accuracy: 0.7530 - val_loss: 0.6245\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7870 - loss: 0.5109 - val_accuracy: 0.7530 - val_loss: 0.6245\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.4912 - val_accuracy: 0.7580 - val_loss: 0.6294\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7967 - loss: 0.4912 - val_accuracy: 0.7580 - val_loss: 0.6294\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.4662 - val_accuracy: 0.7567 - val_loss: 0.6256\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8081 - loss: 0.4662 - val_accuracy: 0.7567 - val_loss: 0.6256\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 0.4435 - val_accuracy: 0.7527 - val_loss: 0.6620\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8191 - loss: 0.4435 - val_accuracy: 0.7527 - val_loss: 0.6620\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.4356 - val_accuracy: 0.7558 - val_loss: 0.6480\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8212 - loss: 0.4356 - val_accuracy: 0.7558 - val_loss: 0.6480\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8296 - loss: 0.4175 - val_accuracy: 0.7545 - val_loss: 0.6586\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8296 - loss: 0.4175 - val_accuracy: 0.7545 - val_loss: 0.6586\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8416 - loss: 0.3894 - val_accuracy: 0.7655 - val_loss: 0.6478\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8416 - loss: 0.3894 - val_accuracy: 0.7655 - val_loss: 0.6478\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8416 - loss: 0.3873 - val_accuracy: 0.7540 - val_loss: 0.6602\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8416 - loss: 0.3873 - val_accuracy: 0.7540 - val_loss: 0.6602\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3688 - val_accuracy: 0.7601 - val_loss: 0.6608\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3688 - val_accuracy: 0.7601 - val_loss: 0.6608\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 0.3510 - val_accuracy: 0.7635 - val_loss: 0.6948\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 0.3510 - val_accuracy: 0.7635 - val_loss: 0.6948\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8610 - loss: 0.3430 - val_accuracy: 0.7592 - val_loss: 0.6753\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8610 - loss: 0.3430 - val_accuracy: 0.7592 - val_loss: 0.6753\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3294 - val_accuracy: 0.7582 - val_loss: 0.7094\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3294 - val_accuracy: 0.7582 - val_loss: 0.7094\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.3216 - val_accuracy: 0.7616 - val_loss: 0.7327\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8712 - loss: 0.3216 - val_accuracy: 0.7616 - val_loss: 0.7327\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "âœ… Train Acc: 0.8712 | Val Acc: 0.7616\n",
      "   Train Loss: 0.3216 | Val Loss: 0.7327\n",
      "   Epochs: 20/50 | Time: 39.1s\n",
      "âœ… Train Acc: 0.8712 | Val Acc: 0.7616\n",
      "   Train Loss: 0.3216 | Val Loss: 0.7327\n",
      "   Epochs: 20/50 | Time: 39.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–„â–„â–…â–…â–ƒâ–†â–‡â–‡â–†â–†â–†â–ˆâ–†â–‡â–ˆâ–‡â–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–…â–„â–‚â–‚â–â–‚â–…â–â–‚â–â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–„â–‡â–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>20</td></tr><tr><td>best_val_acc</td><td>0.76159</td></tr><tr><td>epoch/accuracy</td><td>0.87115</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.3216</td></tr><tr><td>epoch/val_accuracy</td><td>0.76159</td></tr><tr><td>epoch/val_loss</td><td>0.73266</td></tr><tr><td>final_train_acc</td><td>0.87115</td></tr><tr><td>final_train_loss</td><td>0.3216</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-5582e865</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/elsbv9cw' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/elsbv9cw</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-5582e865/wandb/run-20251204_045222-elsbv9cw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 192/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | tanh | dropout=0.3333 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-1726dabf/wandb/run-20251204_045305-97ta84vh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/97ta84vh' target=\"_blank\">RNN-BiGRU-adamw-seed42-1726dabf</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/97ta84vh' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/97ta84vh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6776 - loss: 0.8134 - val_accuracy: 0.7117 - val_loss: 0.6923\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6776 - loss: 0.8134 - val_accuracy: 0.7117 - val_loss: 0.6923\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7191 - loss: 0.6688 - val_accuracy: 0.7293 - val_loss: 0.6762\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7191 - loss: 0.6688 - val_accuracy: 0.7293 - val_loss: 0.6762\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7364 - loss: 0.6284 - val_accuracy: 0.7410 - val_loss: 0.6276\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7364 - loss: 0.6284 - val_accuracy: 0.7410 - val_loss: 0.6276\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7518 - loss: 0.5963 - val_accuracy: 0.7423 - val_loss: 0.6238\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7518 - loss: 0.5963 - val_accuracy: 0.7423 - val_loss: 0.6238\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7585 - loss: 0.5738 - val_accuracy: 0.7486 - val_loss: 0.6262\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7585 - loss: 0.5738 - val_accuracy: 0.7486 - val_loss: 0.6262\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7733 - loss: 0.5448 - val_accuracy: 0.7408 - val_loss: 0.6289\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7733 - loss: 0.5448 - val_accuracy: 0.7408 - val_loss: 0.6289\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7833 - loss: 0.5234 - val_accuracy: 0.7426 - val_loss: 0.6330\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7833 - loss: 0.5234 - val_accuracy: 0.7426 - val_loss: 0.6330\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7932 - loss: 0.4996 - val_accuracy: 0.7595 - val_loss: 0.6042\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7932 - loss: 0.4996 - val_accuracy: 0.7595 - val_loss: 0.6042\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4700 - val_accuracy: 0.7541 - val_loss: 0.6263\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8053 - loss: 0.4700 - val_accuracy: 0.7541 - val_loss: 0.6263\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.4540 - val_accuracy: 0.7598 - val_loss: 0.6226\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8132 - loss: 0.4540 - val_accuracy: 0.7598 - val_loss: 0.6226\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 0.4324 - val_accuracy: 0.7577 - val_loss: 0.6305\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8231 - loss: 0.4324 - val_accuracy: 0.7577 - val_loss: 0.6305\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8321 - loss: 0.4094 - val_accuracy: 0.7626 - val_loss: 0.6304\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8321 - loss: 0.4094 - val_accuracy: 0.7626 - val_loss: 0.6304\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 0.3931 - val_accuracy: 0.7606 - val_loss: 0.6593\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8387 - loss: 0.3931 - val_accuracy: 0.7606 - val_loss: 0.6593\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8444 - loss: 0.3800 - val_accuracy: 0.7647 - val_loss: 0.6665\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8444 - loss: 0.3800 - val_accuracy: 0.7647 - val_loss: 0.6665\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8444 - loss: 0.3802 - val_accuracy: 0.7532 - val_loss: 0.6716\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8444 - loss: 0.3802 - val_accuracy: 0.7532 - val_loss: 0.6716\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.3530 - val_accuracy: 0.7600 - val_loss: 0.6893\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.3530 - val_accuracy: 0.7600 - val_loss: 0.6893\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8637 - loss: 0.3393 - val_accuracy: 0.7549 - val_loss: 0.7056\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8637 - loss: 0.3393 - val_accuracy: 0.7549 - val_loss: 0.7056\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8682 - loss: 0.3275 - val_accuracy: 0.7596 - val_loss: 0.7324\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8682 - loss: 0.3275 - val_accuracy: 0.7596 - val_loss: 0.7324\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8730 - loss: 0.3187 - val_accuracy: 0.7605 - val_loss: 0.7090\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8730 - loss: 0.3187 - val_accuracy: 0.7605 - val_loss: 0.7090\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.3022 - val_accuracy: 0.7700 - val_loss: 0.7053\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.3022 - val_accuracy: 0.7700 - val_loss: 0.7053\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8847 - loss: 0.2895 - val_accuracy: 0.7629 - val_loss: 0.7519\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8847 - loss: 0.2895 - val_accuracy: 0.7629 - val_loss: 0.7519\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8874 - loss: 0.2823 - val_accuracy: 0.7614 - val_loss: 0.7231\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8874 - loss: 0.2823 - val_accuracy: 0.7614 - val_loss: 0.7231\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8949 - loss: 0.2677 - val_accuracy: 0.7629 - val_loss: 0.8133\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8949 - loss: 0.2677 - val_accuracy: 0.7629 - val_loss: 0.8133\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8959 - loss: 0.2636 - val_accuracy: 0.7674 - val_loss: 0.7837\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8959 - loss: 0.2636 - val_accuracy: 0.7674 - val_loss: 0.7837\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.2532 - val_accuracy: 0.7679 - val_loss: 0.8015\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.2532 - val_accuracy: 0.7679 - val_loss: 0.8015\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9038 - loss: 0.2456 - val_accuracy: 0.7637 - val_loss: 0.8022\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9038 - loss: 0.2456 - val_accuracy: 0.7637 - val_loss: 0.8022\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "âœ… Train Acc: 0.9038 | Val Acc: 0.7637\n",
      "   Train Loss: 0.2456 | Val Loss: 0.8022\n",
      "   Epochs: 26/50 | Time: 49.1s\n",
      "âœ… Train Acc: 0.9038 | Val Acc: 0.7637\n",
      "   Train Loss: 0.2456 | Val Loss: 0.8022\n",
      "   Epochs: 26/50 | Time: 49.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–…â–…â–…â–„â–…â–‡â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡</td></tr><tr><td>epoch/val_loss</td><td>â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–„â–†â–…â–ˆâ–‡â–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>26</td></tr><tr><td>best_val_acc</td><td>0.7637</td></tr><tr><td>epoch/accuracy</td><td>0.90385</td></tr><tr><td>epoch/epoch</td><td>25</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.24556</td></tr><tr><td>epoch/val_accuracy</td><td>0.7637</td></tr><tr><td>epoch/val_loss</td><td>0.80223</td></tr><tr><td>final_train_acc</td><td>0.90385</td></tr><tr><td>final_train_loss</td><td>0.24556</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-1726dabf</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/97ta84vh' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/97ta84vh</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-1726dabf/wandb/run-20251204_045305-97ta84vh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 193/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | selu | dropout=0.2 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-fe7d22ed/wandb/run-20251204_045358-1lh7x14e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/1lh7x14e' target=\"_blank\">RNN-BiGRU-adamw-seed42-fe7d22ed</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/1lh7x14e' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/1lh7x14e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6766 - loss: 0.8102 - val_accuracy: 0.7256 - val_loss: 0.6711\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.6766 - loss: 0.8102 - val_accuracy: 0.7256 - val_loss: 0.6711\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7307 - loss: 0.6465 - val_accuracy: 0.7339 - val_loss: 0.6596\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7307 - loss: 0.6465 - val_accuracy: 0.7339 - val_loss: 0.6596\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7476 - loss: 0.6010 - val_accuracy: 0.7426 - val_loss: 0.6258\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7476 - loss: 0.6010 - val_accuracy: 0.7426 - val_loss: 0.6258\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7635 - loss: 0.5682 - val_accuracy: 0.7478 - val_loss: 0.6358\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7635 - loss: 0.5682 - val_accuracy: 0.7478 - val_loss: 0.6358\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7771 - loss: 0.5308 - val_accuracy: 0.7499 - val_loss: 0.6420\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7771 - loss: 0.5308 - val_accuracy: 0.7499 - val_loss: 0.6420\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.5082 - val_accuracy: 0.7498 - val_loss: 0.6377\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.5082 - val_accuracy: 0.7498 - val_loss: 0.6377\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.4747 - val_accuracy: 0.7446 - val_loss: 0.6726\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8036 - loss: 0.4747 - val_accuracy: 0.7446 - val_loss: 0.6726\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.4549 - val_accuracy: 0.7556 - val_loss: 0.6620\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8094 - loss: 0.4549 - val_accuracy: 0.7556 - val_loss: 0.6620\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8230 - loss: 0.4317 - val_accuracy: 0.7501 - val_loss: 0.6726\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8230 - loss: 0.4317 - val_accuracy: 0.7501 - val_loss: 0.6726\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8326 - loss: 0.4053 - val_accuracy: 0.7619 - val_loss: 0.6608\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8326 - loss: 0.4053 - val_accuracy: 0.7619 - val_loss: 0.6608\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8451 - loss: 0.3798 - val_accuracy: 0.7564 - val_loss: 0.7230\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8451 - loss: 0.3798 - val_accuracy: 0.7564 - val_loss: 0.7230\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8500 - loss: 0.3639 - val_accuracy: 0.7467 - val_loss: 0.6959\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8500 - loss: 0.3639 - val_accuracy: 0.7467 - val_loss: 0.6959\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8622 - loss: 0.3384 - val_accuracy: 0.7580 - val_loss: 0.7114\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8622 - loss: 0.3384 - val_accuracy: 0.7580 - val_loss: 0.7114\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8695 - loss: 0.3211 - val_accuracy: 0.7412 - val_loss: 0.7961\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8695 - loss: 0.3211 - val_accuracy: 0.7412 - val_loss: 0.7961\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.2997 - val_accuracy: 0.7574 - val_loss: 0.7605\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.2997 - val_accuracy: 0.7574 - val_loss: 0.7605\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.2882 - val_accuracy: 0.7561 - val_loss: 0.8125\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8833 - loss: 0.2882 - val_accuracy: 0.7561 - val_loss: 0.8125\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "âœ… Train Acc: 0.8833 | Val Acc: 0.7561\n",
      "   Train Loss: 0.2882 | Val Loss: 0.8125\n",
      "   Epochs: 16/50 | Time: 32.6s\n",
      "âœ… Train Acc: 0.8833 | Val Acc: 0.7561\n",
      "   Train Loss: 0.2882 | Val Loss: 0.8125\n",
      "   Epochs: 16/50 | Time: 32.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–„â–…â–†â–†â–…â–‡â–†â–ˆâ–‡â–…â–‡â–„â–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–‚â–â–â–‚â–â–ƒâ–‚â–ƒâ–‚â–…â–„â–„â–‡â–†â–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>16</td></tr><tr><td>best_val_acc</td><td>0.75608</td></tr><tr><td>epoch/accuracy</td><td>0.88331</td></tr><tr><td>epoch/epoch</td><td>15</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.28819</td></tr><tr><td>epoch/val_accuracy</td><td>0.75608</td></tr><tr><td>epoch/val_loss</td><td>0.81252</td></tr><tr><td>final_train_acc</td><td>0.88331</td></tr><tr><td>final_train_loss</td><td>0.28819</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-fe7d22ed</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/1lh7x14e' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/1lh7x14e</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-fe7d22ed/wandb/run-20251204_045358-1lh7x14e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 194/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | selu | dropout=0.2 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-ac67422a/wandb/run-20251204_045435-j7ro7svb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/j7ro7svb' target=\"_blank\">RNN-BiGRU-adamw-seed42-ac67422a</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/j7ro7svb' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/j7ro7svb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6784 - loss: 0.8110 - val_accuracy: 0.7050 - val_loss: 0.6957\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6784 - loss: 0.8110 - val_accuracy: 0.7050 - val_loss: 0.6957\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7323 - loss: 0.6449 - val_accuracy: 0.7254 - val_loss: 0.6795\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7323 - loss: 0.6449 - val_accuracy: 0.7254 - val_loss: 0.6795\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7517 - loss: 0.5987 - val_accuracy: 0.7334 - val_loss: 0.6347\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7517 - loss: 0.5987 - val_accuracy: 0.7334 - val_loss: 0.6347\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 0.5585 - val_accuracy: 0.7519 - val_loss: 0.6095\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 0.5585 - val_accuracy: 0.7519 - val_loss: 0.6095\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.5213 - val_accuracy: 0.7347 - val_loss: 0.6455\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.5213 - val_accuracy: 0.7347 - val_loss: 0.6455\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4905 - val_accuracy: 0.7562 - val_loss: 0.6321\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7961 - loss: 0.4905 - val_accuracy: 0.7562 - val_loss: 0.6321\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4642 - val_accuracy: 0.7566 - val_loss: 0.6304\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8056 - loss: 0.4642 - val_accuracy: 0.7566 - val_loss: 0.6304\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8210 - loss: 0.4315 - val_accuracy: 0.7525 - val_loss: 0.6673\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8210 - loss: 0.4315 - val_accuracy: 0.7525 - val_loss: 0.6673\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8330 - loss: 0.4061 - val_accuracy: 0.7605 - val_loss: 0.6874\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8330 - loss: 0.4061 - val_accuracy: 0.7605 - val_loss: 0.6874\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8434 - loss: 0.3801 - val_accuracy: 0.7619 - val_loss: 0.6661\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8434 - loss: 0.3801 - val_accuracy: 0.7619 - val_loss: 0.6661\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 0.3515 - val_accuracy: 0.7569 - val_loss: 0.7075\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8579 - loss: 0.3515 - val_accuracy: 0.7569 - val_loss: 0.7075\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8621 - loss: 0.3342 - val_accuracy: 0.7536 - val_loss: 0.7156\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8621 - loss: 0.3342 - val_accuracy: 0.7536 - val_loss: 0.7156\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8706 - loss: 0.3164 - val_accuracy: 0.7489 - val_loss: 0.7506\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8706 - loss: 0.3164 - val_accuracy: 0.7489 - val_loss: 0.7506\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8810 - loss: 0.2930 - val_accuracy: 0.7603 - val_loss: 0.7720\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8810 - loss: 0.2930 - val_accuracy: 0.7603 - val_loss: 0.7720\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 0.2794 - val_accuracy: 0.7571 - val_loss: 0.8032\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 0.2794 - val_accuracy: 0.7571 - val_loss: 0.8032\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8958 - loss: 0.2599 - val_accuracy: 0.7611 - val_loss: 0.8752\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8958 - loss: 0.2599 - val_accuracy: 0.7611 - val_loss: 0.8752\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "âœ… Train Acc: 0.8958 | Val Acc: 0.7611\n",
      "   Train Loss: 0.2599 | Val Loss: 0.8752\n",
      "   Epochs: 16/50 | Time: 32.8s\n",
      "âœ… Train Acc: 0.8958 | Val Acc: 0.7611\n",
      "   Train Loss: 0.2599 | Val Loss: 0.8752\n",
      "   Epochs: 16/50 | Time: 32.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–„â–‡â–…â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–†â–ˆâ–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–„â–„â–…â–…â–†â–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>16</td></tr><tr><td>best_val_acc</td><td>0.7611</td></tr><tr><td>epoch/accuracy</td><td>0.89579</td></tr><tr><td>epoch/epoch</td><td>15</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.25987</td></tr><tr><td>epoch/val_accuracy</td><td>0.7611</td></tr><tr><td>epoch/val_loss</td><td>0.87525</td></tr><tr><td>final_train_acc</td><td>0.89579</td></tr><tr><td>final_train_loss</td><td>0.25987</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-ac67422a</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/j7ro7svb' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/j7ro7svb</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-ac67422a/wandb/run-20251204_045435-j7ro7svb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 195/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | selu | dropout=0.2 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-29ed3f61/wandb/run-20251204_045512-f1f0gzf5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/f1f0gzf5' target=\"_blank\">RNN-BiGRU-adamw-seed42-29ed3f61</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/f1f0gzf5' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/f1f0gzf5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6729 - loss: 0.8514 - val_accuracy: 0.7143 - val_loss: 0.6934\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6729 - loss: 0.8514 - val_accuracy: 0.7143 - val_loss: 0.6934\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7273 - loss: 0.6578 - val_accuracy: 0.7285 - val_loss: 0.6597\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7273 - loss: 0.6578 - val_accuracy: 0.7285 - val_loss: 0.6597\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7507 - loss: 0.6017 - val_accuracy: 0.7455 - val_loss: 0.6295\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7507 - loss: 0.6017 - val_accuracy: 0.7455 - val_loss: 0.6295\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.5518 - val_accuracy: 0.7417 - val_loss: 0.6292\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.5518 - val_accuracy: 0.7417 - val_loss: 0.6292\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7818 - loss: 0.5199 - val_accuracy: 0.7509 - val_loss: 0.6177\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7818 - loss: 0.5199 - val_accuracy: 0.7509 - val_loss: 0.6177\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4893 - val_accuracy: 0.7527 - val_loss: 0.6197\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4893 - val_accuracy: 0.7527 - val_loss: 0.6197\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8088 - loss: 0.4564 - val_accuracy: 0.7439 - val_loss: 0.6532\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8088 - loss: 0.4564 - val_accuracy: 0.7439 - val_loss: 0.6532\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.4229 - val_accuracy: 0.7378 - val_loss: 0.6530\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.4229 - val_accuracy: 0.7378 - val_loss: 0.6530\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8378 - loss: 0.3917 - val_accuracy: 0.7540 - val_loss: 0.7049\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8378 - loss: 0.3917 - val_accuracy: 0.7540 - val_loss: 0.7049\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3681 - val_accuracy: 0.7491 - val_loss: 0.7330\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3681 - val_accuracy: 0.7491 - val_loss: 0.7330\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8605 - loss: 0.3388 - val_accuracy: 0.7588 - val_loss: 0.7188\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8605 - loss: 0.3388 - val_accuracy: 0.7588 - val_loss: 0.7188\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8699 - loss: 0.3236 - val_accuracy: 0.7493 - val_loss: 0.7258\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8699 - loss: 0.3236 - val_accuracy: 0.7493 - val_loss: 0.7258\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 0.2949 - val_accuracy: 0.7619 - val_loss: 0.7762\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8812 - loss: 0.2949 - val_accuracy: 0.7619 - val_loss: 0.7762\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8882 - loss: 0.2784 - val_accuracy: 0.7572 - val_loss: 0.7985\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8882 - loss: 0.2784 - val_accuracy: 0.7572 - val_loss: 0.7985\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8976 - loss: 0.2523 - val_accuracy: 0.7577 - val_loss: 0.8690\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8976 - loss: 0.2523 - val_accuracy: 0.7577 - val_loss: 0.8690\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9046 - loss: 0.2407 - val_accuracy: 0.7454 - val_loss: 0.8812\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9046 - loss: 0.2407 - val_accuracy: 0.7454 - val_loss: 0.8812\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9070 - loss: 0.2281 - val_accuracy: 0.7455 - val_loss: 0.9251\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9070 - loss: 0.2281 - val_accuracy: 0.7455 - val_loss: 0.9251\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.2132 - val_accuracy: 0.7520 - val_loss: 1.0134\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.2132 - val_accuracy: 0.7520 - val_loss: 1.0134\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9179 - loss: 0.2100 - val_accuracy: 0.7374 - val_loss: 0.9585\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9179 - loss: 0.2100 - val_accuracy: 0.7374 - val_loss: 0.9585\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "âœ… Train Acc: 0.9179 | Val Acc: 0.7374\n",
      "   Train Loss: 0.2100 | Val Loss: 0.9585\n",
      "   Epochs: 19/50 | Time: 37.8s\n",
      "âœ… Train Acc: 0.9179 | Val Acc: 0.7374\n",
      "   Train Loss: 0.2100 | Val Loss: 0.9585\n",
      "   Epochs: 19/50 | Time: 37.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–„â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–†â–…â–†â–‡â–…â–„â–‡â–†â–ˆâ–†â–ˆâ–‡â–‡â–†â–†â–‡â–„</td></tr><tr><td>epoch/val_loss</td><td>â–‚â–‚â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–†â–†â–ˆâ–‡</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>19</td></tr><tr><td>best_val_acc</td><td>0.73744</td></tr><tr><td>epoch/accuracy</td><td>0.91787</td></tr><tr><td>epoch/epoch</td><td>18</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.21</td></tr><tr><td>epoch/val_accuracy</td><td>0.73744</td></tr><tr><td>epoch/val_loss</td><td>0.95854</td></tr><tr><td>final_train_acc</td><td>0.91787</td></tr><tr><td>final_train_loss</td><td>0.21</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-29ed3f61</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/f1f0gzf5' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/f1f0gzf5</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-29ed3f61/wandb/run-20251204_045512-f1f0gzf5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ’¾ Progress saved (195/36)\n",
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 196/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | selu | dropout=0.3333 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-9febe8d7/wandb/run-20251204_045553-pk71hs20</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/pk71hs20' target=\"_blank\">RNN-BiGRU-adamw-seed42-9febe8d7</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/pk71hs20' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/pk71hs20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6705 - loss: 0.8279 - val_accuracy: 0.6643 - val_loss: 0.8334\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6705 - loss: 0.8279 - val_accuracy: 0.6643 - val_loss: 0.8334\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7206 - loss: 0.6723 - val_accuracy: 0.7290 - val_loss: 0.6479\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7206 - loss: 0.6723 - val_accuracy: 0.7290 - val_loss: 0.6479\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7353 - loss: 0.6301 - val_accuracy: 0.7350 - val_loss: 0.6354\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7353 - loss: 0.6301 - val_accuracy: 0.7350 - val_loss: 0.6354\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7462 - loss: 0.6003 - val_accuracy: 0.7379 - val_loss: 0.6359\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7462 - loss: 0.6003 - val_accuracy: 0.7379 - val_loss: 0.6359\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7626 - loss: 0.5732 - val_accuracy: 0.7425 - val_loss: 0.6255\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7626 - loss: 0.5732 - val_accuracy: 0.7425 - val_loss: 0.6255\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7695 - loss: 0.5505 - val_accuracy: 0.7446 - val_loss: 0.6261\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7695 - loss: 0.5505 - val_accuracy: 0.7446 - val_loss: 0.6261\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5326 - val_accuracy: 0.7504 - val_loss: 0.6161\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5326 - val_accuracy: 0.7504 - val_loss: 0.6161\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.5153 - val_accuracy: 0.7522 - val_loss: 0.6272\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.5153 - val_accuracy: 0.7522 - val_loss: 0.6272\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4864 - val_accuracy: 0.7415 - val_loss: 0.6438\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4864 - val_accuracy: 0.7415 - val_loss: 0.6438\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4665 - val_accuracy: 0.7536 - val_loss: 0.6379\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8066 - loss: 0.4665 - val_accuracy: 0.7536 - val_loss: 0.6379\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.4552 - val_accuracy: 0.7451 - val_loss: 0.6453\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8124 - loss: 0.4552 - val_accuracy: 0.7451 - val_loss: 0.6453\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 0.4313 - val_accuracy: 0.7496 - val_loss: 0.6688\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8222 - loss: 0.4313 - val_accuracy: 0.7496 - val_loss: 0.6688\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.4229 - val_accuracy: 0.7575 - val_loss: 0.6416\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.4229 - val_accuracy: 0.7575 - val_loss: 0.6416\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8352 - loss: 0.4004 - val_accuracy: 0.7648 - val_loss: 0.6449\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8352 - loss: 0.4004 - val_accuracy: 0.7648 - val_loss: 0.6449\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.3849 - val_accuracy: 0.7592 - val_loss: 0.6670\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8409 - loss: 0.3849 - val_accuracy: 0.7592 - val_loss: 0.6670\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3786 - val_accuracy: 0.7608 - val_loss: 0.6520\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8471 - loss: 0.3786 - val_accuracy: 0.7608 - val_loss: 0.6520\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8502 - loss: 0.3654 - val_accuracy: 0.7624 - val_loss: 0.6826\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8502 - loss: 0.3654 - val_accuracy: 0.7624 - val_loss: 0.6826\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 0.3548 - val_accuracy: 0.7585 - val_loss: 0.6966\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 0.3548 - val_accuracy: 0.7585 - val_loss: 0.6966\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.3390 - val_accuracy: 0.7629 - val_loss: 0.7078\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8625 - loss: 0.3390 - val_accuracy: 0.7629 - val_loss: 0.7078\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.3270 - val_accuracy: 0.7614 - val_loss: 0.7553\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.3270 - val_accuracy: 0.7614 - val_loss: 0.7553\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "âœ… Train Acc: 0.8671 | Val Acc: 0.7614\n",
      "   Train Loss: 0.3270 | Val Loss: 0.7553\n",
      "   Epochs: 20/50 | Time: 37.8s\n",
      "âœ… Train Acc: 0.8671 | Val Acc: 0.7614\n",
      "   Train Loss: 0.3270 | Val Loss: 0.7553\n",
      "   Epochs: 20/50 | Time: 37.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–†â–†â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–„â–„â–…</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>20</td></tr><tr><td>best_val_acc</td><td>0.76143</td></tr><tr><td>epoch/accuracy</td><td>0.86706</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.32705</td></tr><tr><td>epoch/val_accuracy</td><td>0.76143</td></tr><tr><td>epoch/val_loss</td><td>0.75535</td></tr><tr><td>final_train_acc</td><td>0.86706</td></tr><tr><td>final_train_loss</td><td>0.32705</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-9febe8d7</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/pk71hs20' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/pk71hs20</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-9febe8d7/wandb/run-20251204_045553-pk71hs20/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 197/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | selu | dropout=0.3333 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-ee31ec15/wandb/run-20251204_045635-zhiys5dh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/zhiys5dh' target=\"_blank\">RNN-BiGRU-adamw-seed42-ee31ec15</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/zhiys5dh' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/zhiys5dh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6703 - loss: 0.8407 - val_accuracy: 0.7230 - val_loss: 0.6632\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6703 - loss: 0.8407 - val_accuracy: 0.7230 - val_loss: 0.6632\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7177 - loss: 0.6729 - val_accuracy: 0.7305 - val_loss: 0.6470\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7177 - loss: 0.6729 - val_accuracy: 0.7305 - val_loss: 0.6470\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7372 - loss: 0.6255 - val_accuracy: 0.7363 - val_loss: 0.6469\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7372 - loss: 0.6255 - val_accuracy: 0.7363 - val_loss: 0.6469\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7512 - loss: 0.5974 - val_accuracy: 0.7496 - val_loss: 0.6130\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7512 - loss: 0.5974 - val_accuracy: 0.7496 - val_loss: 0.6130\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7617 - loss: 0.5677 - val_accuracy: 0.7499 - val_loss: 0.6281\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7617 - loss: 0.5677 - val_accuracy: 0.7499 - val_loss: 0.6281\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7758 - loss: 0.5432 - val_accuracy: 0.7371 - val_loss: 0.6382\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7758 - loss: 0.5432 - val_accuracy: 0.7371 - val_loss: 0.6382\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.5203 - val_accuracy: 0.7476 - val_loss: 0.6310\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.5203 - val_accuracy: 0.7476 - val_loss: 0.6310\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4945 - val_accuracy: 0.7509 - val_loss: 0.6562\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7936 - loss: 0.4945 - val_accuracy: 0.7509 - val_loss: 0.6562\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4680 - val_accuracy: 0.7630 - val_loss: 0.6119\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8057 - loss: 0.4680 - val_accuracy: 0.7630 - val_loss: 0.6119\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8137 - loss: 0.4493 - val_accuracy: 0.7616 - val_loss: 0.6326\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8137 - loss: 0.4493 - val_accuracy: 0.7616 - val_loss: 0.6326\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.4290 - val_accuracy: 0.7669 - val_loss: 0.6190\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8235 - loss: 0.4290 - val_accuracy: 0.7669 - val_loss: 0.6190\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8295 - loss: 0.4145 - val_accuracy: 0.7331 - val_loss: 0.6985\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8295 - loss: 0.4145 - val_accuracy: 0.7331 - val_loss: 0.6985\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8379 - loss: 0.3943 - val_accuracy: 0.7632 - val_loss: 0.6645\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8379 - loss: 0.3943 - val_accuracy: 0.7632 - val_loss: 0.6645\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8441 - loss: 0.3833 - val_accuracy: 0.7669 - val_loss: 0.6723\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8441 - loss: 0.3833 - val_accuracy: 0.7669 - val_loss: 0.6723\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8507 - loss: 0.3669 - val_accuracy: 0.7536 - val_loss: 0.6970\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8507 - loss: 0.3669 - val_accuracy: 0.7536 - val_loss: 0.6970\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 0.3534 - val_accuracy: 0.7580 - val_loss: 0.7214\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 0.3534 - val_accuracy: 0.7580 - val_loss: 0.7214\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8645 - loss: 0.3332 - val_accuracy: 0.7661 - val_loss: 0.7043\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8645 - loss: 0.3332 - val_accuracy: 0.7661 - val_loss: 0.7043\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "âœ… Train Acc: 0.8645 | Val Acc: 0.7661\n",
      "   Train Loss: 0.3332 | Val Loss: 0.7043\n",
      "   Epochs: 17/50 | Time: 33.5s\n",
      "   ğŸŒŸ NEW BEST MODEL! Val Acc: 0.7661\n",
      "âœ… Train Acc: 0.8645 | Val Acc: 0.7661\n",
      "   Train Loss: 0.3332 | Val Loss: 0.7043\n",
      "   Epochs: 17/50 | Time: 33.5s\n",
      "   ğŸŒŸ NEW BEST MODEL! Val Acc: 0.7661\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–ƒâ–…â–…â–ƒâ–…â–…â–‡â–‡â–ˆâ–ƒâ–‡â–ˆâ–†â–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–„â–ƒâ–ƒâ–â–‚â–ƒâ–‚â–„â–â–‚â–â–‡â–„â–…â–†â–ˆâ–‡</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>17</td></tr><tr><td>best_val_acc</td><td>0.76613</td></tr><tr><td>epoch/accuracy</td><td>0.86451</td></tr><tr><td>epoch/epoch</td><td>16</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.33317</td></tr><tr><td>epoch/val_accuracy</td><td>0.76613</td></tr><tr><td>epoch/val_loss</td><td>0.70427</td></tr><tr><td>final_train_acc</td><td>0.86451</td></tr><tr><td>final_train_loss</td><td>0.33317</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-ee31ec15</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/zhiys5dh' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/zhiys5dh</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-ee31ec15/wandb/run-20251204_045635-zhiys5dh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 198/36 configurations\n",
      "Config: BiGRU | adamw | lr=0.001 | mom=0.95 | selu | dropout=0.3333 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-adamw-seed42-328e668d/wandb/run-20251204_045713-yw4koeyy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/yw4koeyy' target=\"_blank\">RNN-BiGRU-adamw-seed42-328e668d</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/yw4koeyy' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/yw4koeyy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6638 - loss: 0.8721 - val_accuracy: 0.7115 - val_loss: 0.6898\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.6638 - loss: 0.8721 - val_accuracy: 0.7115 - val_loss: 0.6898\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7181 - loss: 0.6792 - val_accuracy: 0.7303 - val_loss: 0.6546\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7181 - loss: 0.6792 - val_accuracy: 0.7303 - val_loss: 0.6546\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7373 - loss: 0.6254 - val_accuracy: 0.7468 - val_loss: 0.6243\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7373 - loss: 0.6254 - val_accuracy: 0.7468 - val_loss: 0.6243\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7550 - loss: 0.5885 - val_accuracy: 0.7543 - val_loss: 0.6058\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7550 - loss: 0.5885 - val_accuracy: 0.7543 - val_loss: 0.6058\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7677 - loss: 0.5577 - val_accuracy: 0.7520 - val_loss: 0.6168\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7677 - loss: 0.5577 - val_accuracy: 0.7520 - val_loss: 0.6168\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.5351 - val_accuracy: 0.7533 - val_loss: 0.6185\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.5351 - val_accuracy: 0.7533 - val_loss: 0.6185\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7882 - loss: 0.5118 - val_accuracy: 0.7480 - val_loss: 0.6198\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7882 - loss: 0.5118 - val_accuracy: 0.7480 - val_loss: 0.6198\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4859 - val_accuracy: 0.7595 - val_loss: 0.6177\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7988 - loss: 0.4859 - val_accuracy: 0.7595 - val_loss: 0.6177\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8097 - loss: 0.4608 - val_accuracy: 0.7512 - val_loss: 0.6335\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8097 - loss: 0.4608 - val_accuracy: 0.7512 - val_loss: 0.6335\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8161 - loss: 0.4428 - val_accuracy: 0.7606 - val_loss: 0.6373\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8161 - loss: 0.4428 - val_accuracy: 0.7606 - val_loss: 0.6373\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.4160 - val_accuracy: 0.7582 - val_loss: 0.6475\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.4160 - val_accuracy: 0.7582 - val_loss: 0.6475\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 0.4082 - val_accuracy: 0.7540 - val_loss: 0.6537\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8322 - loss: 0.4082 - val_accuracy: 0.7540 - val_loss: 0.6537\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8402 - loss: 0.3869 - val_accuracy: 0.7556 - val_loss: 0.6856\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8402 - loss: 0.3869 - val_accuracy: 0.7556 - val_loss: 0.6856\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8527 - loss: 0.3603 - val_accuracy: 0.7652 - val_loss: 0.6827\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8527 - loss: 0.3603 - val_accuracy: 0.7652 - val_loss: 0.6827\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 0.3412 - val_accuracy: 0.7674 - val_loss: 0.6912\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8591 - loss: 0.3412 - val_accuracy: 0.7674 - val_loss: 0.6912\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8630 - loss: 0.3309 - val_accuracy: 0.7530 - val_loss: 0.7112\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8630 - loss: 0.3309 - val_accuracy: 0.7530 - val_loss: 0.7112\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8729 - loss: 0.3144 - val_accuracy: 0.7603 - val_loss: 0.7154\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8729 - loss: 0.3144 - val_accuracy: 0.7603 - val_loss: 0.7154\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.3094 - val_accuracy: 0.7577 - val_loss: 0.7184\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.3094 - val_accuracy: 0.7577 - val_loss: 0.7184\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.2954 - val_accuracy: 0.7639 - val_loss: 0.7590\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8818 - loss: 0.2954 - val_accuracy: 0.7639 - val_loss: 0.7590\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8878 - loss: 0.2826 - val_accuracy: 0.7686 - val_loss: 0.7684\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8878 - loss: 0.2826 - val_accuracy: 0.7686 - val_loss: 0.7684\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8892 - loss: 0.2735 - val_accuracy: 0.7630 - val_loss: 0.7979\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8892 - loss: 0.2735 - val_accuracy: 0.7630 - val_loss: 0.7979\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.2524 - val_accuracy: 0.7498 - val_loss: 0.8168\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9007 - loss: 0.2524 - val_accuracy: 0.7498 - val_loss: 0.8168\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8968 - loss: 0.2552 - val_accuracy: 0.7626 - val_loss: 0.8344\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8968 - loss: 0.2552 - val_accuracy: 0.7626 - val_loss: 0.8344\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.2556 - val_accuracy: 0.7684 - val_loss: 0.7925\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8977 - loss: 0.2556 - val_accuracy: 0.7684 - val_loss: 0.7925\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9075 - loss: 0.2368 - val_accuracy: 0.7564 - val_loss: 0.8373\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9075 - loss: 0.2368 - val_accuracy: 0.7564 - val_loss: 0.8373\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9098 - loss: 0.2296 - val_accuracy: 0.7606 - val_loss: 0.8411\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9098 - loss: 0.2296 - val_accuracy: 0.7606 - val_loss: 0.8411\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "âœ… Train Acc: 0.9098 | Val Acc: 0.7606\n",
      "   Train Loss: 0.2296 | Val Loss: 0.8411\n",
      "   Epochs: 26/50 | Time: 48.1s\n",
      "âœ… Train Acc: 0.9098 | Val Acc: 0.7606\n",
      "   Train Loss: 0.2296 | Val Loss: 0.8411\n",
      "   Epochs: 26/50 | Time: 48.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–…â–†â–†â–†â–…â–‡â–†â–‡â–‡â–†â–†â–ˆâ–ˆâ–†â–‡â–‡â–‡â–ˆâ–‡â–†â–‡â–ˆâ–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–‚â–‚â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>26</td></tr><tr><td>best_val_acc</td><td>0.76062</td></tr><tr><td>epoch/accuracy</td><td>0.90985</td></tr><tr><td>epoch/epoch</td><td>25</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.2296</td></tr><tr><td>epoch/val_accuracy</td><td>0.76062</td></tr><tr><td>epoch/val_loss</td><td>0.84108</td></tr><tr><td>final_train_acc</td><td>0.90985</td></tr><tr><td>final_train_loss</td><td>0.2296</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-adamw-seed42-328e668d</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/yw4koeyy' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/yw4koeyy</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-adamw-seed42-328e668d/wandb/run-20251204_045713-yw4koeyy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 199/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | relu | dropout=0.2 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-c64b8457/wandb/run-20251204_045805-olf547os</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/olf547os' target=\"_blank\">RNN-BiGRU-sgd-seed42-c64b8457</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/olf547os' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/olf547os</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6373 - loss: 0.8832 - val_accuracy: 0.7049 - val_loss: 0.7124\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6373 - loss: 0.8832 - val_accuracy: 0.7049 - val_loss: 0.7124\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7017 - loss: 0.7122 - val_accuracy: 0.7245 - val_loss: 0.6676\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7017 - loss: 0.7122 - val_accuracy: 0.7245 - val_loss: 0.6676\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7176 - loss: 0.6722 - val_accuracy: 0.7318 - val_loss: 0.6548\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7176 - loss: 0.6722 - val_accuracy: 0.7318 - val_loss: 0.6548\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7278 - loss: 0.6496 - val_accuracy: 0.7263 - val_loss: 0.6548\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7278 - loss: 0.6496 - val_accuracy: 0.7263 - val_loss: 0.6548\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.6313 - val_accuracy: 0.7280 - val_loss: 0.6538\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.6313 - val_accuracy: 0.7280 - val_loss: 0.6538\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7391 - loss: 0.6187 - val_accuracy: 0.7370 - val_loss: 0.6344\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7391 - loss: 0.6187 - val_accuracy: 0.7370 - val_loss: 0.6344\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7489 - loss: 0.6033 - val_accuracy: 0.7392 - val_loss: 0.6256\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7489 - loss: 0.6033 - val_accuracy: 0.7392 - val_loss: 0.6256\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7505 - loss: 0.5917 - val_accuracy: 0.7418 - val_loss: 0.6309\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7505 - loss: 0.5917 - val_accuracy: 0.7418 - val_loss: 0.6309\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7612 - loss: 0.5802 - val_accuracy: 0.7451 - val_loss: 0.6261\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7612 - loss: 0.5802 - val_accuracy: 0.7451 - val_loss: 0.6261\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7644 - loss: 0.5651 - val_accuracy: 0.7520 - val_loss: 0.6113\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7644 - loss: 0.5651 - val_accuracy: 0.7520 - val_loss: 0.6113\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7687 - loss: 0.5575 - val_accuracy: 0.7485 - val_loss: 0.6191\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7687 - loss: 0.5575 - val_accuracy: 0.7485 - val_loss: 0.6191\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7758 - loss: 0.5429 - val_accuracy: 0.7509 - val_loss: 0.6080\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7758 - loss: 0.5429 - val_accuracy: 0.7509 - val_loss: 0.6080\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7780 - loss: 0.5322 - val_accuracy: 0.7232 - val_loss: 0.6690\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7780 - loss: 0.5322 - val_accuracy: 0.7232 - val_loss: 0.6690\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.5239 - val_accuracy: 0.7515 - val_loss: 0.6225\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.5239 - val_accuracy: 0.7515 - val_loss: 0.6225\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.5147 - val_accuracy: 0.7499 - val_loss: 0.6218\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7877 - loss: 0.5147 - val_accuracy: 0.7499 - val_loss: 0.6218\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.5019 - val_accuracy: 0.7541 - val_loss: 0.6151\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7949 - loss: 0.5019 - val_accuracy: 0.7541 - val_loss: 0.6151\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4886 - val_accuracy: 0.7551 - val_loss: 0.6176\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7981 - loss: 0.4886 - val_accuracy: 0.7551 - val_loss: 0.6176\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4805 - val_accuracy: 0.7600 - val_loss: 0.6136\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8031 - loss: 0.4805 - val_accuracy: 0.7600 - val_loss: 0.6136\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.4724 - val_accuracy: 0.7627 - val_loss: 0.5948\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.4724 - val_accuracy: 0.7627 - val_loss: 0.5948\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.4643 - val_accuracy: 0.7410 - val_loss: 0.6323\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8107 - loss: 0.4643 - val_accuracy: 0.7410 - val_loss: 0.6323\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.4530 - val_accuracy: 0.7549 - val_loss: 0.6562\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.4530 - val_accuracy: 0.7549 - val_loss: 0.6562\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.4507 - val_accuracy: 0.7527 - val_loss: 0.6370\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.4507 - val_accuracy: 0.7527 - val_loss: 0.6370\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8224 - loss: 0.4367 - val_accuracy: 0.7386 - val_loss: 0.6610\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8224 - loss: 0.4367 - val_accuracy: 0.7386 - val_loss: 0.6610\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.4323 - val_accuracy: 0.7616 - val_loss: 0.6084\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8251 - loss: 0.4323 - val_accuracy: 0.7616 - val_loss: 0.6084\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.4230 - val_accuracy: 0.7645 - val_loss: 0.6158\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8305 - loss: 0.4230 - val_accuracy: 0.7645 - val_loss: 0.6158\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.4107 - val_accuracy: 0.7546 - val_loss: 0.6500\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.4107 - val_accuracy: 0.7546 - val_loss: 0.6500\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.4034 - val_accuracy: 0.7582 - val_loss: 0.6400\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.4034 - val_accuracy: 0.7582 - val_loss: 0.6400\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.3946 - val_accuracy: 0.7546 - val_loss: 0.6539\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.3946 - val_accuracy: 0.7546 - val_loss: 0.6539\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.3867 - val_accuracy: 0.7609 - val_loss: 0.6351\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.3867 - val_accuracy: 0.7609 - val_loss: 0.6351\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3777 - val_accuracy: 0.7452 - val_loss: 0.6760\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8486 - loss: 0.3777 - val_accuracy: 0.7452 - val_loss: 0.6760\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.3677 - val_accuracy: 0.7575 - val_loss: 0.6644\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.3677 - val_accuracy: 0.7575 - val_loss: 0.6644\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "âœ… Train Acc: 0.8514 | Val Acc: 0.7575\n",
      "   Train Loss: 0.3677 | Val Loss: 0.6644\n",
      "   Epochs: 31/50 | Time: 48.7s\n",
      "âœ… Train Acc: 0.8514 | Val Acc: 0.7575\n",
      "   Train Loss: 0.3677 | Val Loss: 0.6644\n",
      "   Epochs: 31/50 | Time: 48.7s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–„â–„â–„â–…â–…â–…â–†â–‡â–†â–†â–ƒâ–†â–†â–‡â–‡â–‡â–ˆâ–…â–‡â–‡â–…â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–†â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–…â–…â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–…â–ƒâ–ƒâ–‚â–‚â–‚â–â–ƒâ–…â–„â–…â–‚â–‚â–„â–„â–…â–ƒâ–†â–…</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>31</td></tr><tr><td>best_val_acc</td><td>0.75754</td></tr><tr><td>epoch/accuracy</td><td>0.85142</td></tr><tr><td>epoch/epoch</td><td>30</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.36765</td></tr><tr><td>epoch/val_accuracy</td><td>0.75754</td></tr><tr><td>epoch/val_loss</td><td>0.66437</td></tr><tr><td>final_train_acc</td><td>0.85142</td></tr><tr><td>final_train_loss</td><td>0.36765</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-c64b8457</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/olf547os' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/olf547os</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-c64b8457/wandb/run-20251204_045805-olf547os/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 200/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | relu | dropout=0.2 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-8e396ab0/wandb/run-20251204_045857-iixyz5ii</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/iixyz5ii' target=\"_blank\">RNN-BiGRU-sgd-seed42-8e396ab0</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/iixyz5ii' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/iixyz5ii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6363 - loss: 0.9032 - val_accuracy: 0.7089 - val_loss: 0.7095\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6363 - loss: 0.9032 - val_accuracy: 0.7089 - val_loss: 0.7095\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7035 - loss: 0.7081 - val_accuracy: 0.7078 - val_loss: 0.7025\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7035 - loss: 0.7081 - val_accuracy: 0.7078 - val_loss: 0.7025\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7201 - loss: 0.6669 - val_accuracy: 0.7308 - val_loss: 0.6585\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7201 - loss: 0.6669 - val_accuracy: 0.7308 - val_loss: 0.6585\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7314 - loss: 0.6403 - val_accuracy: 0.7319 - val_loss: 0.6347\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7314 - loss: 0.6403 - val_accuracy: 0.7319 - val_loss: 0.6347\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7366 - loss: 0.6240 - val_accuracy: 0.7329 - val_loss: 0.6469\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7366 - loss: 0.6240 - val_accuracy: 0.7329 - val_loss: 0.6469\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7454 - loss: 0.6056 - val_accuracy: 0.7368 - val_loss: 0.6370\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7454 - loss: 0.6056 - val_accuracy: 0.7368 - val_loss: 0.6370\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7538 - loss: 0.5896 - val_accuracy: 0.7433 - val_loss: 0.6240\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7538 - loss: 0.5896 - val_accuracy: 0.7433 - val_loss: 0.6240\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7608 - loss: 0.5759 - val_accuracy: 0.7473 - val_loss: 0.6176\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7608 - loss: 0.5759 - val_accuracy: 0.7473 - val_loss: 0.6176\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7687 - loss: 0.5578 - val_accuracy: 0.7449 - val_loss: 0.6455\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7687 - loss: 0.5578 - val_accuracy: 0.7449 - val_loss: 0.6455\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7729 - loss: 0.5435 - val_accuracy: 0.7527 - val_loss: 0.6241\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7729 - loss: 0.5435 - val_accuracy: 0.7527 - val_loss: 0.6241\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7811 - loss: 0.5320 - val_accuracy: 0.7515 - val_loss: 0.6105\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7811 - loss: 0.5320 - val_accuracy: 0.7515 - val_loss: 0.6105\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.5204 - val_accuracy: 0.7509 - val_loss: 0.6123\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.5204 - val_accuracy: 0.7509 - val_loss: 0.6123\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7930 - loss: 0.5039 - val_accuracy: 0.7546 - val_loss: 0.6127\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7930 - loss: 0.5039 - val_accuracy: 0.7546 - val_loss: 0.6127\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7976 - loss: 0.4906 - val_accuracy: 0.7423 - val_loss: 0.6324\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7976 - loss: 0.4906 - val_accuracy: 0.7423 - val_loss: 0.6324\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8038 - loss: 0.4800 - val_accuracy: 0.7400 - val_loss: 0.6258\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8038 - loss: 0.4800 - val_accuracy: 0.7400 - val_loss: 0.6258\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8070 - loss: 0.4709 - val_accuracy: 0.7519 - val_loss: 0.6160\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8070 - loss: 0.4709 - val_accuracy: 0.7519 - val_loss: 0.6160\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8109 - loss: 0.4603 - val_accuracy: 0.7613 - val_loss: 0.6059\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8109 - loss: 0.4603 - val_accuracy: 0.7613 - val_loss: 0.6059\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8188 - loss: 0.4464 - val_accuracy: 0.7567 - val_loss: 0.6294\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8188 - loss: 0.4464 - val_accuracy: 0.7567 - val_loss: 0.6294\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.4355 - val_accuracy: 0.7553 - val_loss: 0.6160\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.4355 - val_accuracy: 0.7553 - val_loss: 0.6160\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.4201 - val_accuracy: 0.7603 - val_loss: 0.6300\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.4201 - val_accuracy: 0.7603 - val_loss: 0.6300\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8319 - loss: 0.4110 - val_accuracy: 0.7485 - val_loss: 0.6439\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8319 - loss: 0.4110 - val_accuracy: 0.7485 - val_loss: 0.6439\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8393 - loss: 0.4002 - val_accuracy: 0.7582 - val_loss: 0.6300\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8393 - loss: 0.4002 - val_accuracy: 0.7582 - val_loss: 0.6300\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8436 - loss: 0.3905 - val_accuracy: 0.7465 - val_loss: 0.6454\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8436 - loss: 0.3905 - val_accuracy: 0.7465 - val_loss: 0.6454\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "âœ… Train Acc: 0.8436 | Val Acc: 0.7465\n",
      "   Train Loss: 0.3905 | Val Loss: 0.6454\n",
      "   Epochs: 23/50 | Time: 38.1s\n",
      "âœ… Train Acc: 0.8436 | Val Acc: 0.7465\n",
      "   Train Loss: 0.3905 | Val Loss: 0.6454\n",
      "   Epochs: 23/50 | Time: 38.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–â–„â–„â–„â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–†â–…â–‡â–ˆâ–‡â–‡â–ˆâ–†â–ˆâ–†</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–ˆâ–…â–ƒâ–„â–ƒâ–‚â–‚â–„â–‚â–â–â–â–ƒâ–‚â–‚â–â–ƒâ–‚â–ƒâ–„â–ƒâ–„</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>23</td></tr><tr><td>best_val_acc</td><td>0.74652</td></tr><tr><td>epoch/accuracy</td><td>0.84364</td></tr><tr><td>epoch/epoch</td><td>22</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.39047</td></tr><tr><td>epoch/val_accuracy</td><td>0.74652</td></tr><tr><td>epoch/val_loss</td><td>0.64543</td></tr><tr><td>final_train_acc</td><td>0.84364</td></tr><tr><td>final_train_loss</td><td>0.39047</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-8e396ab0</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/iixyz5ii' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/iixyz5ii</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-8e396ab0/wandb/run-20251204_045857-iixyz5ii/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ’¾ Progress saved (200/36)\n",
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 201/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | relu | dropout=0.2 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-f563d795/wandb/run-20251204_045940-jadx27i2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jadx27i2' target=\"_blank\">RNN-BiGRU-sgd-seed42-f563d795</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jadx27i2' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jadx27i2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6465 - loss: 0.8658 - val_accuracy: 0.6981 - val_loss: 0.7405\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6465 - loss: 0.8658 - val_accuracy: 0.6981 - val_loss: 0.7405\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7103 - loss: 0.6896 - val_accuracy: 0.7229 - val_loss: 0.6648\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7103 - loss: 0.6896 - val_accuracy: 0.7229 - val_loss: 0.6648\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7267 - loss: 0.6474 - val_accuracy: 0.7371 - val_loss: 0.6392\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7267 - loss: 0.6474 - val_accuracy: 0.7371 - val_loss: 0.6392\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.6220 - val_accuracy: 0.7306 - val_loss: 0.6410\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.6220 - val_accuracy: 0.7306 - val_loss: 0.6410\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7491 - loss: 0.5956 - val_accuracy: 0.7407 - val_loss: 0.6316\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7491 - loss: 0.5956 - val_accuracy: 0.7407 - val_loss: 0.6316\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.5843 - val_accuracy: 0.7254 - val_loss: 0.6457\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.5843 - val_accuracy: 0.7254 - val_loss: 0.6457\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7643 - loss: 0.5623 - val_accuracy: 0.7355 - val_loss: 0.6303\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7643 - loss: 0.5623 - val_accuracy: 0.7355 - val_loss: 0.6303\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7730 - loss: 0.5498 - val_accuracy: 0.7397 - val_loss: 0.6217\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7730 - loss: 0.5498 - val_accuracy: 0.7397 - val_loss: 0.6217\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7796 - loss: 0.5334 - val_accuracy: 0.7478 - val_loss: 0.6120\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7796 - loss: 0.5334 - val_accuracy: 0.7478 - val_loss: 0.6120\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.5154 - val_accuracy: 0.7535 - val_loss: 0.6096\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7908 - loss: 0.5154 - val_accuracy: 0.7535 - val_loss: 0.6096\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.5031 - val_accuracy: 0.7442 - val_loss: 0.6302\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.5031 - val_accuracy: 0.7442 - val_loss: 0.6302\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.4880 - val_accuracy: 0.7408 - val_loss: 0.6343\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8002 - loss: 0.4880 - val_accuracy: 0.7408 - val_loss: 0.6343\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.4733 - val_accuracy: 0.7528 - val_loss: 0.6124\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8084 - loss: 0.4733 - val_accuracy: 0.7528 - val_loss: 0.6124\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.4587 - val_accuracy: 0.7452 - val_loss: 0.6292\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8138 - loss: 0.4587 - val_accuracy: 0.7452 - val_loss: 0.6292\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8194 - loss: 0.4404 - val_accuracy: 0.7499 - val_loss: 0.6245\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8194 - loss: 0.4404 - val_accuracy: 0.7499 - val_loss: 0.6245\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.4349 - val_accuracy: 0.7543 - val_loss: 0.6224\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.4349 - val_accuracy: 0.7543 - val_loss: 0.6224\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8315 - loss: 0.4204 - val_accuracy: 0.7551 - val_loss: 0.6311\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8315 - loss: 0.4204 - val_accuracy: 0.7551 - val_loss: 0.6311\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.4055 - val_accuracy: 0.7514 - val_loss: 0.6402\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8357 - loss: 0.4055 - val_accuracy: 0.7514 - val_loss: 0.6402\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 0.3943 - val_accuracy: 0.7533 - val_loss: 0.6413\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 0.3943 - val_accuracy: 0.7533 - val_loss: 0.6413\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8495 - loss: 0.3770 - val_accuracy: 0.7514 - val_loss: 0.6458\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8495 - loss: 0.3770 - val_accuracy: 0.7514 - val_loss: 0.6458\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 0.3646 - val_accuracy: 0.7579 - val_loss: 0.6531\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8557 - loss: 0.3646 - val_accuracy: 0.7579 - val_loss: 0.6531\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8612 - loss: 0.3507 - val_accuracy: 0.7512 - val_loss: 0.6654\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8612 - loss: 0.3507 - val_accuracy: 0.7512 - val_loss: 0.6654\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3439 - val_accuracy: 0.7548 - val_loss: 0.6803\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3439 - val_accuracy: 0.7548 - val_loss: 0.6803\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.3298 - val_accuracy: 0.7582 - val_loss: 0.6675\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.3298 - val_accuracy: 0.7582 - val_loss: 0.6675\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8765 - loss: 0.3170 - val_accuracy: 0.7536 - val_loss: 0.6945\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8765 - loss: 0.3170 - val_accuracy: 0.7536 - val_loss: 0.6945\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.3020 - val_accuracy: 0.7464 - val_loss: 0.7121\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.3020 - val_accuracy: 0.7464 - val_loss: 0.7121\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.2940 - val_accuracy: 0.7540 - val_loss: 0.7148\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.2940 - val_accuracy: 0.7540 - val_loss: 0.7148\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.2802 - val_accuracy: 0.7630 - val_loss: 0.7309\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.2802 - val_accuracy: 0.7630 - val_loss: 0.7309\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.2667 - val_accuracy: 0.7561 - val_loss: 0.7384\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.2667 - val_accuracy: 0.7561 - val_loss: 0.7384\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: 0.2646 - val_accuracy: 0.7512 - val_loss: 0.7445\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8965 - loss: 0.2646 - val_accuracy: 0.7512 - val_loss: 0.7445\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9021 - loss: 0.2542 - val_accuracy: 0.7598 - val_loss: 0.7656\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9021 - loss: 0.2542 - val_accuracy: 0.7598 - val_loss: 0.7656\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.2398 - val_accuracy: 0.7614 - val_loss: 0.7645\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.2398 - val_accuracy: 0.7614 - val_loss: 0.7645\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2319 - val_accuracy: 0.7410 - val_loss: 0.8052\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2319 - val_accuracy: 0.7410 - val_loss: 0.8052\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2225 - val_accuracy: 0.7564 - val_loss: 0.7799\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2225 - val_accuracy: 0.7564 - val_loss: 0.7799\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "âœ… Train Acc: 0.9141 | Val Acc: 0.7564\n",
      "   Train Loss: 0.2225 | Val Loss: 0.7799\n",
      "   Epochs: 34/50 | Time: 54.9s\n",
      "âœ… Train Acc: 0.9141 | Val Acc: 0.7564\n",
      "   Train Loss: 0.2225 | Val Loss: 0.7799\n",
      "   Epochs: 34/50 | Time: 54.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–…â–…â–†â–„â–…â–…â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–†â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–†â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–„â–…â–…â–…â–†â–†â–‡â–‡â–ˆâ–‡</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>34</td></tr><tr><td>best_val_acc</td><td>0.7564</td></tr><tr><td>epoch/accuracy</td><td>0.91414</td></tr><tr><td>epoch/epoch</td><td>33</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.22246</td></tr><tr><td>epoch/val_accuracy</td><td>0.7564</td></tr><tr><td>epoch/val_loss</td><td>0.77989</td></tr><tr><td>final_train_acc</td><td>0.91414</td></tr><tr><td>final_train_loss</td><td>0.22246</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-f563d795</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jadx27i2' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jadx27i2</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-f563d795/wandb/run-20251204_045940-jadx27i2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 202/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | relu | dropout=0.3333 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-d652868c/wandb/run-20251204_050039-1gc28763</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/1gc28763' target=\"_blank\">RNN-BiGRU-sgd-seed42-d652868c</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/1gc28763' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/1gc28763</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6287 - loss: 0.9204 - val_accuracy: 0.7021 - val_loss: 0.7369\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6287 - loss: 0.9204 - val_accuracy: 0.7021 - val_loss: 0.7369\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6896 - loss: 0.7413 - val_accuracy: 0.7109 - val_loss: 0.6991\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6896 - loss: 0.7413 - val_accuracy: 0.7109 - val_loss: 0.6991\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7033 - loss: 0.7051 - val_accuracy: 0.7182 - val_loss: 0.6741\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7033 - loss: 0.7051 - val_accuracy: 0.7182 - val_loss: 0.6741\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.6782 - val_accuracy: 0.7220 - val_loss: 0.6628\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.6782 - val_accuracy: 0.7220 - val_loss: 0.6628\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7221 - loss: 0.6627 - val_accuracy: 0.7219 - val_loss: 0.6555\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7221 - loss: 0.6627 - val_accuracy: 0.7219 - val_loss: 0.6555\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7282 - loss: 0.6484 - val_accuracy: 0.7254 - val_loss: 0.6399\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7282 - loss: 0.6484 - val_accuracy: 0.7254 - val_loss: 0.6399\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7339 - loss: 0.6369 - val_accuracy: 0.7298 - val_loss: 0.6401\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7339 - loss: 0.6369 - val_accuracy: 0.7298 - val_loss: 0.6401\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.6284 - val_accuracy: 0.7274 - val_loss: 0.6452\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7369 - loss: 0.6284 - val_accuracy: 0.7274 - val_loss: 0.6452\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7419 - loss: 0.6163 - val_accuracy: 0.7261 - val_loss: 0.6414\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7419 - loss: 0.6163 - val_accuracy: 0.7261 - val_loss: 0.6414\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7463 - loss: 0.6105 - val_accuracy: 0.7348 - val_loss: 0.6427\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7463 - loss: 0.6105 - val_accuracy: 0.7348 - val_loss: 0.6427\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.6001 - val_accuracy: 0.7421 - val_loss: 0.6298\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7492 - loss: 0.6001 - val_accuracy: 0.7421 - val_loss: 0.6298\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7528 - loss: 0.5900 - val_accuracy: 0.7379 - val_loss: 0.6269\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7528 - loss: 0.5900 - val_accuracy: 0.7379 - val_loss: 0.6269\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7566 - loss: 0.5838 - val_accuracy: 0.7238 - val_loss: 0.6520\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7566 - loss: 0.5838 - val_accuracy: 0.7238 - val_loss: 0.6520\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7547 - loss: 0.5771 - val_accuracy: 0.7329 - val_loss: 0.6459\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7547 - loss: 0.5771 - val_accuracy: 0.7329 - val_loss: 0.6459\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7629 - loss: 0.5690 - val_accuracy: 0.7407 - val_loss: 0.6353\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7629 - loss: 0.5690 - val_accuracy: 0.7407 - val_loss: 0.6353\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.5638 - val_accuracy: 0.7465 - val_loss: 0.6152\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.5638 - val_accuracy: 0.7465 - val_loss: 0.6152\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7715 - loss: 0.5530 - val_accuracy: 0.7391 - val_loss: 0.6406\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7715 - loss: 0.5530 - val_accuracy: 0.7391 - val_loss: 0.6406\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.5456 - val_accuracy: 0.7446 - val_loss: 0.6138\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.5456 - val_accuracy: 0.7446 - val_loss: 0.6138\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7747 - loss: 0.5428 - val_accuracy: 0.7467 - val_loss: 0.6196\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7747 - loss: 0.5428 - val_accuracy: 0.7467 - val_loss: 0.6196\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 0.5297 - val_accuracy: 0.7536 - val_loss: 0.6086\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7801 - loss: 0.5297 - val_accuracy: 0.7536 - val_loss: 0.6086\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7821 - loss: 0.5278 - val_accuracy: 0.7473 - val_loss: 0.6235\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7821 - loss: 0.5278 - val_accuracy: 0.7473 - val_loss: 0.6235\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7816 - loss: 0.5248 - val_accuracy: 0.7549 - val_loss: 0.6106\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7816 - loss: 0.5248 - val_accuracy: 0.7549 - val_loss: 0.6106\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.5100 - val_accuracy: 0.7535 - val_loss: 0.6026\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.5100 - val_accuracy: 0.7535 - val_loss: 0.6026\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7896 - loss: 0.5083 - val_accuracy: 0.7549 - val_loss: 0.6061\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7896 - loss: 0.5083 - val_accuracy: 0.7549 - val_loss: 0.6061\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.4975 - val_accuracy: 0.7496 - val_loss: 0.6159\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.4975 - val_accuracy: 0.7496 - val_loss: 0.6159\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.4913 - val_accuracy: 0.7423 - val_loss: 0.6380\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.4913 - val_accuracy: 0.7423 - val_loss: 0.6380\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7982 - loss: 0.4876 - val_accuracy: 0.7530 - val_loss: 0.6180\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7982 - loss: 0.4876 - val_accuracy: 0.7530 - val_loss: 0.6180\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4769 - val_accuracy: 0.7549 - val_loss: 0.6130\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4769 - val_accuracy: 0.7549 - val_loss: 0.6130\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "âœ… Train Acc: 0.8067 | Val Acc: 0.7549\n",
      "   Train Loss: 0.4769 | Val Loss: 0.6130\n",
      "   Epochs: 28/50 | Time: 44.9s\n",
      "âœ… Train Acc: 0.8067 | Val Acc: 0.7549\n",
      "   Train Loss: 0.4769 | Val Loss: 0.6130\n",
      "   Epochs: 28/50 | Time: 44.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–ƒâ–„â–„â–„â–…â–„â–„â–…â–†â–†â–„â–…â–†â–‡â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–â–â–‚â–ƒâ–‚â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>28</td></tr><tr><td>best_val_acc</td><td>0.75494</td></tr><tr><td>epoch/accuracy</td><td>0.80673</td></tr><tr><td>epoch/epoch</td><td>27</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.47691</td></tr><tr><td>epoch/val_accuracy</td><td>0.75494</td></tr><tr><td>epoch/val_loss</td><td>0.61303</td></tr><tr><td>final_train_acc</td><td>0.80673</td></tr><tr><td>final_train_loss</td><td>0.47691</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-d652868c</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/1gc28763' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/1gc28763</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-d652868c/wandb/run-20251204_050039-1gc28763/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 203/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | relu | dropout=0.3333 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-af3e5072/wandb/run-20251204_050127-65tzmdrr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/65tzmdrr' target=\"_blank\">RNN-BiGRU-sgd-seed42-af3e5072</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/65tzmdrr' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/65tzmdrr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6200 - loss: 0.9398 - val_accuracy: 0.7070 - val_loss: 0.7170\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6200 - loss: 0.9398 - val_accuracy: 0.7070 - val_loss: 0.7170\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6947 - loss: 0.7296 - val_accuracy: 0.7241 - val_loss: 0.6735\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6947 - loss: 0.7296 - val_accuracy: 0.7241 - val_loss: 0.6735\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7062 - loss: 0.6987 - val_accuracy: 0.6934 - val_loss: 0.7167\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7062 - loss: 0.6987 - val_accuracy: 0.6934 - val_loss: 0.7167\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7207 - loss: 0.6707 - val_accuracy: 0.7271 - val_loss: 0.6472\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7207 - loss: 0.6707 - val_accuracy: 0.7271 - val_loss: 0.6472\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7265 - loss: 0.6565 - val_accuracy: 0.7282 - val_loss: 0.6440\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7265 - loss: 0.6565 - val_accuracy: 0.7282 - val_loss: 0.6440\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7319 - loss: 0.6393 - val_accuracy: 0.7297 - val_loss: 0.6473\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7319 - loss: 0.6393 - val_accuracy: 0.7297 - val_loss: 0.6473\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.6290 - val_accuracy: 0.7235 - val_loss: 0.6434\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.6290 - val_accuracy: 0.7235 - val_loss: 0.6434\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7357 - loss: 0.6222 - val_accuracy: 0.7165 - val_loss: 0.6669\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7357 - loss: 0.6222 - val_accuracy: 0.7165 - val_loss: 0.6669\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7443 - loss: 0.6065 - val_accuracy: 0.7342 - val_loss: 0.6339\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7443 - loss: 0.6065 - val_accuracy: 0.7342 - val_loss: 0.6339\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7504 - loss: 0.5986 - val_accuracy: 0.7285 - val_loss: 0.6436\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7504 - loss: 0.5986 - val_accuracy: 0.7285 - val_loss: 0.6436\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7499 - loss: 0.5915 - val_accuracy: 0.7400 - val_loss: 0.6185\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7499 - loss: 0.5915 - val_accuracy: 0.7400 - val_loss: 0.6185\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7530 - loss: 0.5854 - val_accuracy: 0.7464 - val_loss: 0.6120\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7530 - loss: 0.5854 - val_accuracy: 0.7464 - val_loss: 0.6120\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7620 - loss: 0.5733 - val_accuracy: 0.7425 - val_loss: 0.6155\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7620 - loss: 0.5733 - val_accuracy: 0.7425 - val_loss: 0.6155\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7622 - loss: 0.5686 - val_accuracy: 0.7418 - val_loss: 0.6159\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7622 - loss: 0.5686 - val_accuracy: 0.7418 - val_loss: 0.6159\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7700 - loss: 0.5530 - val_accuracy: 0.7412 - val_loss: 0.6174\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7700 - loss: 0.5530 - val_accuracy: 0.7412 - val_loss: 0.6174\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.5432 - val_accuracy: 0.7486 - val_loss: 0.6087\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.5432 - val_accuracy: 0.7486 - val_loss: 0.6087\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7737 - loss: 0.5421 - val_accuracy: 0.7480 - val_loss: 0.6051\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7737 - loss: 0.5421 - val_accuracy: 0.7480 - val_loss: 0.6051\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.5306 - val_accuracy: 0.7551 - val_loss: 0.6056\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.5306 - val_accuracy: 0.7551 - val_loss: 0.6056\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.5201 - val_accuracy: 0.7379 - val_loss: 0.6281\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.5201 - val_accuracy: 0.7379 - val_loss: 0.6281\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7887 - loss: 0.5106 - val_accuracy: 0.7506 - val_loss: 0.6081\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7887 - loss: 0.5106 - val_accuracy: 0.7506 - val_loss: 0.6081\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7911 - loss: 0.5070 - val_accuracy: 0.7395 - val_loss: 0.6527\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7911 - loss: 0.5070 - val_accuracy: 0.7395 - val_loss: 0.6527\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7964 - loss: 0.4973 - val_accuracy: 0.7462 - val_loss: 0.6072\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7964 - loss: 0.4973 - val_accuracy: 0.7462 - val_loss: 0.6072\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7976 - loss: 0.4901 - val_accuracy: 0.7530 - val_loss: 0.6064\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7976 - loss: 0.4901 - val_accuracy: 0.7530 - val_loss: 0.6064\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4822 - val_accuracy: 0.7580 - val_loss: 0.6099\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4822 - val_accuracy: 0.7580 - val_loss: 0.6099\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.4800 - val_accuracy: 0.7476 - val_loss: 0.6199\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.4800 - val_accuracy: 0.7476 - val_loss: 0.6199\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8081 - loss: 0.4672 - val_accuracy: 0.7478 - val_loss: 0.6092\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8081 - loss: 0.4672 - val_accuracy: 0.7478 - val_loss: 0.6092\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.4584 - val_accuracy: 0.7558 - val_loss: 0.6117\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.4584 - val_accuracy: 0.7558 - val_loss: 0.6117\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.4510 - val_accuracy: 0.7514 - val_loss: 0.6343\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.4510 - val_accuracy: 0.7514 - val_loss: 0.6343\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 0.4460 - val_accuracy: 0.7511 - val_loss: 0.6280\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 0.4460 - val_accuracy: 0.7511 - val_loss: 0.6280\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.4370 - val_accuracy: 0.7493 - val_loss: 0.6216\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.4370 - val_accuracy: 0.7493 - val_loss: 0.6216\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "âœ… Train Acc: 0.8206 | Val Acc: 0.7493\n",
      "   Train Loss: 0.4370 | Val Loss: 0.6216\n",
      "   Epochs: 30/50 | Time: 48.3s\n",
      "âœ… Train Acc: 0.8206 | Val Acc: 0.7493\n",
      "   Train Loss: 0.4370 | Val Loss: 0.6216\n",
      "   Epochs: 30/50 | Time: 48.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–‚â–„â–â–…â–…â–…â–„â–„â–…â–…â–†â–‡â–†â–†â–†â–‡â–‡â–ˆâ–†â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–…â–ˆâ–„â–ƒâ–„â–ƒâ–…â–ƒâ–ƒâ–‚â–â–‚â–‚â–‚â–â–â–â–‚â–â–„â–â–â–â–‚â–â–â–ƒâ–‚â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>30</td></tr><tr><td>best_val_acc</td><td>0.74927</td></tr><tr><td>epoch/accuracy</td><td>0.82058</td></tr><tr><td>epoch/epoch</td><td>29</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.43703</td></tr><tr><td>epoch/val_accuracy</td><td>0.74927</td></tr><tr><td>epoch/val_loss</td><td>0.62162</td></tr><tr><td>final_train_acc</td><td>0.82058</td></tr><tr><td>final_train_loss</td><td>0.43703</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-af3e5072</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/65tzmdrr' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/65tzmdrr</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-af3e5072/wandb/run-20251204_050127-65tzmdrr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 204/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | relu | dropout=0.3333 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-37223089/wandb/run-20251204_050219-iekaxh9o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/iekaxh9o' target=\"_blank\">RNN-BiGRU-sgd-seed42-37223089</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/iekaxh9o' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/iekaxh9o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6327 - loss: 0.9195 - val_accuracy: 0.7029 - val_loss: 0.7170\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6327 - loss: 0.9195 - val_accuracy: 0.7029 - val_loss: 0.7170\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6994 - loss: 0.7169 - val_accuracy: 0.7097 - val_loss: 0.7018\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6994 - loss: 0.7169 - val_accuracy: 0.7097 - val_loss: 0.7018\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7162 - loss: 0.6802 - val_accuracy: 0.7264 - val_loss: 0.6494\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7162 - loss: 0.6802 - val_accuracy: 0.7264 - val_loss: 0.6494\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7229 - loss: 0.6592 - val_accuracy: 0.7113 - val_loss: 0.6983\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7229 - loss: 0.6592 - val_accuracy: 0.7113 - val_loss: 0.6983\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7323 - loss: 0.6372 - val_accuracy: 0.7395 - val_loss: 0.6330\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7323 - loss: 0.6372 - val_accuracy: 0.7395 - val_loss: 0.6330\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7388 - loss: 0.6243 - val_accuracy: 0.7363 - val_loss: 0.6368\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7388 - loss: 0.6243 - val_accuracy: 0.7363 - val_loss: 0.6368\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7430 - loss: 0.6174 - val_accuracy: 0.7446 - val_loss: 0.6265\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7430 - loss: 0.6174 - val_accuracy: 0.7446 - val_loss: 0.6265\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.6022 - val_accuracy: 0.7442 - val_loss: 0.6169\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7503 - loss: 0.6022 - val_accuracy: 0.7442 - val_loss: 0.6169\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7534 - loss: 0.5886 - val_accuracy: 0.7290 - val_loss: 0.6431\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7534 - loss: 0.5886 - val_accuracy: 0.7290 - val_loss: 0.6431\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7579 - loss: 0.5839 - val_accuracy: 0.7527 - val_loss: 0.6052\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7579 - loss: 0.5839 - val_accuracy: 0.7527 - val_loss: 0.6052\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7605 - loss: 0.5700 - val_accuracy: 0.7554 - val_loss: 0.6107\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7605 - loss: 0.5700 - val_accuracy: 0.7554 - val_loss: 0.6107\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7661 - loss: 0.5632 - val_accuracy: 0.7483 - val_loss: 0.6262\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7661 - loss: 0.5632 - val_accuracy: 0.7483 - val_loss: 0.6262\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7680 - loss: 0.5519 - val_accuracy: 0.7499 - val_loss: 0.6190\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7680 - loss: 0.5519 - val_accuracy: 0.7499 - val_loss: 0.6190\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7774 - loss: 0.5425 - val_accuracy: 0.7543 - val_loss: 0.6181\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7774 - loss: 0.5425 - val_accuracy: 0.7543 - val_loss: 0.6181\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7822 - loss: 0.5292 - val_accuracy: 0.7494 - val_loss: 0.6082\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7822 - loss: 0.5292 - val_accuracy: 0.7494 - val_loss: 0.6082\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.5191 - val_accuracy: 0.7585 - val_loss: 0.6020\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.5191 - val_accuracy: 0.7585 - val_loss: 0.6020\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7906 - loss: 0.5108 - val_accuracy: 0.7574 - val_loss: 0.6170\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7906 - loss: 0.5108 - val_accuracy: 0.7574 - val_loss: 0.6170\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.5013 - val_accuracy: 0.7609 - val_loss: 0.6118\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.5013 - val_accuracy: 0.7609 - val_loss: 0.6118\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.4960 - val_accuracy: 0.7618 - val_loss: 0.6087\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7935 - loss: 0.4960 - val_accuracy: 0.7618 - val_loss: 0.6087\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4811 - val_accuracy: 0.7308 - val_loss: 0.6712\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4811 - val_accuracy: 0.7308 - val_loss: 0.6712\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.4757 - val_accuracy: 0.7554 - val_loss: 0.6005\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.4757 - val_accuracy: 0.7554 - val_loss: 0.6005\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.4616 - val_accuracy: 0.7596 - val_loss: 0.6090\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 0.4616 - val_accuracy: 0.7596 - val_loss: 0.6090\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.4614 - val_accuracy: 0.7473 - val_loss: 0.6226\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.4614 - val_accuracy: 0.7473 - val_loss: 0.6226\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8142 - loss: 0.4514 - val_accuracy: 0.7540 - val_loss: 0.6093\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8142 - loss: 0.4514 - val_accuracy: 0.7540 - val_loss: 0.6093\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8216 - loss: 0.4392 - val_accuracy: 0.7475 - val_loss: 0.6251\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8216 - loss: 0.4392 - val_accuracy: 0.7475 - val_loss: 0.6251\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "âœ… Train Acc: 0.8216 | Val Acc: 0.7475\n",
      "   Train Loss: 0.4392 | Val Loss: 0.6251\n",
      "   Epochs: 25/50 | Time: 43.2s\n",
      "âœ… Train Acc: 0.8216 | Val Acc: 0.7475\n",
      "   Train Loss: 0.4392 | Val Loss: 0.6251\n",
      "   Epochs: 25/50 | Time: 43.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–„â–‚â–…â–…â–†â–†â–„â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–„â–‡â–ˆâ–†â–‡â–†</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‡â–„â–‡â–ƒâ–ƒâ–ƒâ–‚â–„â–â–‚â–ƒâ–‚â–‚â–â–â–‚â–‚â–â–…â–â–‚â–‚â–‚â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>25</td></tr><tr><td>best_val_acc</td><td>0.74749</td></tr><tr><td>epoch/accuracy</td><td>0.8216</td></tr><tr><td>epoch/epoch</td><td>24</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.43917</td></tr><tr><td>epoch/val_accuracy</td><td>0.74749</td></tr><tr><td>epoch/val_loss</td><td>0.62512</td></tr><tr><td>final_train_acc</td><td>0.8216</td></tr><tr><td>final_train_loss</td><td>0.43917</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-37223089</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/iekaxh9o' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/iekaxh9o</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-37223089/wandb/run-20251204_050219-iekaxh9o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 205/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | tanh | dropout=0.2 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-0ce372f7/wandb/run-20251204_050307-4bvhguw3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/4bvhguw3' target=\"_blank\">RNN-BiGRU-sgd-seed42-0ce372f7</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/4bvhguw3' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/4bvhguw3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6169 - loss: 0.9743 - val_accuracy: 0.7052 - val_loss: 0.7387\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6169 - loss: 0.9743 - val_accuracy: 0.7052 - val_loss: 0.7387\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7030 - loss: 0.7254 - val_accuracy: 0.7229 - val_loss: 0.6720\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7030 - loss: 0.7254 - val_accuracy: 0.7229 - val_loss: 0.6720\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7166 - loss: 0.6833 - val_accuracy: 0.7301 - val_loss: 0.6528\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7166 - loss: 0.6833 - val_accuracy: 0.7301 - val_loss: 0.6528\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7278 - loss: 0.6579 - val_accuracy: 0.7272 - val_loss: 0.6554\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7278 - loss: 0.6579 - val_accuracy: 0.7272 - val_loss: 0.6554\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7370 - loss: 0.6358 - val_accuracy: 0.7350 - val_loss: 0.6398\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7370 - loss: 0.6358 - val_accuracy: 0.7350 - val_loss: 0.6398\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7417 - loss: 0.6239 - val_accuracy: 0.7425 - val_loss: 0.6306\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7417 - loss: 0.6239 - val_accuracy: 0.7425 - val_loss: 0.6306\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7456 - loss: 0.6128 - val_accuracy: 0.7421 - val_loss: 0.6304\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7456 - loss: 0.6128 - val_accuracy: 0.7421 - val_loss: 0.6304\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7519 - loss: 0.5991 - val_accuracy: 0.7459 - val_loss: 0.6283\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7519 - loss: 0.5991 - val_accuracy: 0.7459 - val_loss: 0.6283\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7577 - loss: 0.5875 - val_accuracy: 0.7462 - val_loss: 0.6206\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7577 - loss: 0.5875 - val_accuracy: 0.7462 - val_loss: 0.6206\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7622 - loss: 0.5782 - val_accuracy: 0.7429 - val_loss: 0.6268\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7622 - loss: 0.5782 - val_accuracy: 0.7429 - val_loss: 0.6268\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7700 - loss: 0.5637 - val_accuracy: 0.7472 - val_loss: 0.6191\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7700 - loss: 0.5637 - val_accuracy: 0.7472 - val_loss: 0.6191\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.5579 - val_accuracy: 0.7501 - val_loss: 0.6137\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.5579 - val_accuracy: 0.7501 - val_loss: 0.6137\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7782 - loss: 0.5451 - val_accuracy: 0.7524 - val_loss: 0.6095\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7782 - loss: 0.5451 - val_accuracy: 0.7524 - val_loss: 0.6095\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.5351 - val_accuracy: 0.7493 - val_loss: 0.6148\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.5351 - val_accuracy: 0.7493 - val_loss: 0.6148\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7858 - loss: 0.5259 - val_accuracy: 0.7496 - val_loss: 0.6112\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7858 - loss: 0.5259 - val_accuracy: 0.7496 - val_loss: 0.6112\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.5149 - val_accuracy: 0.7517 - val_loss: 0.6082\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.5149 - val_accuracy: 0.7517 - val_loss: 0.6082\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5101 - val_accuracy: 0.7439 - val_loss: 0.6168\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5101 - val_accuracy: 0.7439 - val_loss: 0.6168\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.5026 - val_accuracy: 0.7517 - val_loss: 0.6248\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7937 - loss: 0.5026 - val_accuracy: 0.7517 - val_loss: 0.6248\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4885 - val_accuracy: 0.7571 - val_loss: 0.6058\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.4885 - val_accuracy: 0.7571 - val_loss: 0.6058\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.4805 - val_accuracy: 0.7536 - val_loss: 0.6242\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8049 - loss: 0.4805 - val_accuracy: 0.7536 - val_loss: 0.6242\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.4657 - val_accuracy: 0.7538 - val_loss: 0.6226\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8130 - loss: 0.4657 - val_accuracy: 0.7538 - val_loss: 0.6226\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8141 - loss: 0.4602 - val_accuracy: 0.7608 - val_loss: 0.6101\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8141 - loss: 0.4602 - val_accuracy: 0.7608 - val_loss: 0.6101\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8183 - loss: 0.4523 - val_accuracy: 0.7601 - val_loss: 0.6160\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8183 - loss: 0.4523 - val_accuracy: 0.7601 - val_loss: 0.6160\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.4398 - val_accuracy: 0.7535 - val_loss: 0.6182\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8252 - loss: 0.4398 - val_accuracy: 0.7535 - val_loss: 0.6182\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.4355 - val_accuracy: 0.7608 - val_loss: 0.6050\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8230 - loss: 0.4355 - val_accuracy: 0.7608 - val_loss: 0.6050\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.4212 - val_accuracy: 0.7637 - val_loss: 0.6150\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8327 - loss: 0.4212 - val_accuracy: 0.7637 - val_loss: 0.6150\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.4186 - val_accuracy: 0.7562 - val_loss: 0.6241\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.4186 - val_accuracy: 0.7562 - val_loss: 0.6241\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.4058 - val_accuracy: 0.7580 - val_loss: 0.6136\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.4058 - val_accuracy: 0.7580 - val_loss: 0.6136\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.4008 - val_accuracy: 0.7606 - val_loss: 0.6495\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.4008 - val_accuracy: 0.7606 - val_loss: 0.6495\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.3927 - val_accuracy: 0.7668 - val_loss: 0.6198\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.3927 - val_accuracy: 0.7668 - val_loss: 0.6198\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.3817 - val_accuracy: 0.7635 - val_loss: 0.6261\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.3817 - val_accuracy: 0.7635 - val_loss: 0.6261\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8505 - loss: 0.3783 - val_accuracy: 0.7626 - val_loss: 0.6418\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8505 - loss: 0.3783 - val_accuracy: 0.7626 - val_loss: 0.6418\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3701 - val_accuracy: 0.7378 - val_loss: 0.6984\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3701 - val_accuracy: 0.7378 - val_loss: 0.6984\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.3601 - val_accuracy: 0.7465 - val_loss: 0.6804\n",
      "Epoch 35/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.3601 - val_accuracy: 0.7465 - val_loss: 0.6804\n",
      "Epoch 35/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.3507 - val_accuracy: 0.7613 - val_loss: 0.6476\n",
      "Epoch 36/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.3507 - val_accuracy: 0.7613 - val_loss: 0.6476\n",
      "Epoch 36/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3427 - val_accuracy: 0.7635 - val_loss: 0.6620\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8654 - loss: 0.3427 - val_accuracy: 0.7635 - val_loss: 0.6620\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "âœ… Train Acc: 0.8654 | Val Acc: 0.7635\n",
      "   Train Loss: 0.3427 | Val Loss: 0.6620\n",
      "   Epochs: 36/50 | Time: 54.3s\n",
      "âœ… Train Acc: 0.8654 | Val Acc: 0.7635\n",
      "   Train Loss: 0.3427 | Val Loss: 0.6620\n",
      "   Epochs: 36/50 | Time: 54.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–„â–„â–„â–…â–…â–†â–†â–…â–†â–†â–†â–†â–†â–†â–…â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–…â–†â–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–…â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–ƒâ–‚â–‚â–ƒâ–†â–…â–ƒâ–„</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>36</td></tr><tr><td>best_val_acc</td><td>0.76353</td></tr><tr><td>epoch/accuracy</td><td>0.8654</td></tr><tr><td>epoch/epoch</td><td>35</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.34275</td></tr><tr><td>epoch/val_accuracy</td><td>0.76353</td></tr><tr><td>epoch/val_loss</td><td>0.66197</td></tr><tr><td>final_train_acc</td><td>0.8654</td></tr><tr><td>final_train_loss</td><td>0.34275</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-0ce372f7</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/4bvhguw3' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/4bvhguw3</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-0ce372f7/wandb/run-20251204_050307-4bvhguw3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ’¾ Progress saved (205/36)\n",
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 206/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | tanh | dropout=0.2 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-54cef38c/wandb/run-20251204_050406-g1up357n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/g1up357n' target=\"_blank\">RNN-BiGRU-sgd-seed42-54cef38c</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/g1up357n' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/g1up357n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6239 - loss: 0.9457 - val_accuracy: 0.7109 - val_loss: 0.7023\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6239 - loss: 0.9457 - val_accuracy: 0.7109 - val_loss: 0.7023\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7045 - loss: 0.7225 - val_accuracy: 0.7160 - val_loss: 0.6878\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7045 - loss: 0.7225 - val_accuracy: 0.7160 - val_loss: 0.6878\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7191 - loss: 0.6749 - val_accuracy: 0.7266 - val_loss: 0.6548\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7191 - loss: 0.6749 - val_accuracy: 0.7266 - val_loss: 0.6548\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7310 - loss: 0.6506 - val_accuracy: 0.7293 - val_loss: 0.6483\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7310 - loss: 0.6506 - val_accuracy: 0.7293 - val_loss: 0.6483\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7355 - loss: 0.6308 - val_accuracy: 0.7379 - val_loss: 0.6340\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7355 - loss: 0.6308 - val_accuracy: 0.7379 - val_loss: 0.6340\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7448 - loss: 0.6138 - val_accuracy: 0.7399 - val_loss: 0.6466\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7448 - loss: 0.6138 - val_accuracy: 0.7399 - val_loss: 0.6466\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7505 - loss: 0.6011 - val_accuracy: 0.7368 - val_loss: 0.6377\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7505 - loss: 0.6011 - val_accuracy: 0.7368 - val_loss: 0.6377\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7575 - loss: 0.5882 - val_accuracy: 0.7465 - val_loss: 0.6167\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7575 - loss: 0.5882 - val_accuracy: 0.7465 - val_loss: 0.6167\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.5800 - val_accuracy: 0.7382 - val_loss: 0.6445\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7600 - loss: 0.5800 - val_accuracy: 0.7382 - val_loss: 0.6445\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7674 - loss: 0.5653 - val_accuracy: 0.7323 - val_loss: 0.6527\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7674 - loss: 0.5653 - val_accuracy: 0.7323 - val_loss: 0.6527\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7719 - loss: 0.5549 - val_accuracy: 0.7457 - val_loss: 0.6182\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7719 - loss: 0.5549 - val_accuracy: 0.7457 - val_loss: 0.6182\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5416 - val_accuracy: 0.7549 - val_loss: 0.6066\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5416 - val_accuracy: 0.7549 - val_loss: 0.6066\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7835 - loss: 0.5289 - val_accuracy: 0.7533 - val_loss: 0.6255\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7835 - loss: 0.5289 - val_accuracy: 0.7533 - val_loss: 0.6255\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7896 - loss: 0.5170 - val_accuracy: 0.7551 - val_loss: 0.6128\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7896 - loss: 0.5170 - val_accuracy: 0.7551 - val_loss: 0.6128\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5069 - val_accuracy: 0.7545 - val_loss: 0.6156\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5069 - val_accuracy: 0.7545 - val_loss: 0.6156\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.4953 - val_accuracy: 0.7558 - val_loss: 0.6175\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7980 - loss: 0.4953 - val_accuracy: 0.7558 - val_loss: 0.6175\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.4878 - val_accuracy: 0.7583 - val_loss: 0.6048\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.4878 - val_accuracy: 0.7583 - val_loss: 0.6048\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8074 - loss: 0.4741 - val_accuracy: 0.7606 - val_loss: 0.6043\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8074 - loss: 0.4741 - val_accuracy: 0.7606 - val_loss: 0.6043\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8137 - loss: 0.4614 - val_accuracy: 0.7626 - val_loss: 0.5973\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8137 - loss: 0.4614 - val_accuracy: 0.7626 - val_loss: 0.5973\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8172 - loss: 0.4557 - val_accuracy: 0.7647 - val_loss: 0.6095\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8172 - loss: 0.4557 - val_accuracy: 0.7647 - val_loss: 0.6095\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8232 - loss: 0.4420 - val_accuracy: 0.7587 - val_loss: 0.6191\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8232 - loss: 0.4420 - val_accuracy: 0.7587 - val_loss: 0.6191\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.4308 - val_accuracy: 0.7665 - val_loss: 0.6115\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.4308 - val_accuracy: 0.7665 - val_loss: 0.6115\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.4235 - val_accuracy: 0.7567 - val_loss: 0.6523\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.4235 - val_accuracy: 0.7567 - val_loss: 0.6523\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.4100 - val_accuracy: 0.7587 - val_loss: 0.6098\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.4100 - val_accuracy: 0.7587 - val_loss: 0.6098\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.4000 - val_accuracy: 0.7626 - val_loss: 0.6098\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8385 - loss: 0.4000 - val_accuracy: 0.7626 - val_loss: 0.6098\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8440 - loss: 0.3909 - val_accuracy: 0.7587 - val_loss: 0.6327\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8440 - loss: 0.3909 - val_accuracy: 0.7587 - val_loss: 0.6327\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8481 - loss: 0.3871 - val_accuracy: 0.7489 - val_loss: 0.6429\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8481 - loss: 0.3871 - val_accuracy: 0.7489 - val_loss: 0.6429\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3716 - val_accuracy: 0.7653 - val_loss: 0.6289\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3716 - val_accuracy: 0.7653 - val_loss: 0.6289\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "âœ… Train Acc: 0.8553 | Val Acc: 0.7653\n",
      "   Train Loss: 0.3716 | Val Loss: 0.6289\n",
      "   Epochs: 28/50 | Time: 45.1s\n",
      "âœ… Train Acc: 0.8553 | Val Acc: 0.7653\n",
      "   Train Loss: 0.3716 | Val Loss: 0.6289\n",
      "   Epochs: 28/50 | Time: 45.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–ƒâ–ƒâ–„â–…â–„â–…â–„â–„â–…â–‡â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–†â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‡â–…â–„â–ƒâ–„â–„â–‚â–„â–…â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–…â–‚â–‚â–ƒâ–„â–ƒ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>28</td></tr><tr><td>best_val_acc</td><td>0.76532</td></tr><tr><td>epoch/accuracy</td><td>0.85527</td></tr><tr><td>epoch/epoch</td><td>27</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.37165</td></tr><tr><td>epoch/val_accuracy</td><td>0.76532</td></tr><tr><td>epoch/val_loss</td><td>0.62895</td></tr><tr><td>final_train_acc</td><td>0.85527</td></tr><tr><td>final_train_loss</td><td>0.37165</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-54cef38c</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/g1up357n' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/g1up357n</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-54cef38c/wandb/run-20251204_050406-g1up357n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 207/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | tanh | dropout=0.2 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-cd7b1338/wandb/run-20251204_050455-x6ma1crm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/x6ma1crm' target=\"_blank\">RNN-BiGRU-sgd-seed42-cd7b1338</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/x6ma1crm' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/x6ma1crm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6309 - loss: 0.9473 - val_accuracy: 0.7063 - val_loss: 0.7302\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6309 - loss: 0.9473 - val_accuracy: 0.7063 - val_loss: 0.7302\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7096 - loss: 0.7105 - val_accuracy: 0.7303 - val_loss: 0.6624\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7096 - loss: 0.7105 - val_accuracy: 0.7303 - val_loss: 0.6624\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7226 - loss: 0.6690 - val_accuracy: 0.7310 - val_loss: 0.6605\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7226 - loss: 0.6690 - val_accuracy: 0.7310 - val_loss: 0.6605\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.6432 - val_accuracy: 0.7360 - val_loss: 0.6421\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7345 - loss: 0.6432 - val_accuracy: 0.7360 - val_loss: 0.6421\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7430 - loss: 0.6203 - val_accuracy: 0.7353 - val_loss: 0.6439\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7430 - loss: 0.6203 - val_accuracy: 0.7353 - val_loss: 0.6439\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7494 - loss: 0.6034 - val_accuracy: 0.7387 - val_loss: 0.6350\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7494 - loss: 0.6034 - val_accuracy: 0.7387 - val_loss: 0.6350\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7590 - loss: 0.5869 - val_accuracy: 0.7381 - val_loss: 0.6321\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7590 - loss: 0.5869 - val_accuracy: 0.7381 - val_loss: 0.6321\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 0.5721 - val_accuracy: 0.7489 - val_loss: 0.6292\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 0.5721 - val_accuracy: 0.7489 - val_loss: 0.6292\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.5568 - val_accuracy: 0.7538 - val_loss: 0.6160\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.5568 - val_accuracy: 0.7538 - val_loss: 0.6160\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7734 - loss: 0.5499 - val_accuracy: 0.7520 - val_loss: 0.6156\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7734 - loss: 0.5499 - val_accuracy: 0.7520 - val_loss: 0.6156\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7816 - loss: 0.5361 - val_accuracy: 0.7592 - val_loss: 0.6062\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7816 - loss: 0.5361 - val_accuracy: 0.7592 - val_loss: 0.6062\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7869 - loss: 0.5192 - val_accuracy: 0.7546 - val_loss: 0.6060\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7869 - loss: 0.5192 - val_accuracy: 0.7546 - val_loss: 0.6060\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7950 - loss: 0.5070 - val_accuracy: 0.7499 - val_loss: 0.6156\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7950 - loss: 0.5070 - val_accuracy: 0.7499 - val_loss: 0.6156\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8005 - loss: 0.4955 - val_accuracy: 0.7614 - val_loss: 0.5989\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8005 - loss: 0.4955 - val_accuracy: 0.7614 - val_loss: 0.5989\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4815 - val_accuracy: 0.7535 - val_loss: 0.6009\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8049 - loss: 0.4815 - val_accuracy: 0.7535 - val_loss: 0.6009\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8118 - loss: 0.4691 - val_accuracy: 0.7525 - val_loss: 0.6071\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8118 - loss: 0.4691 - val_accuracy: 0.7525 - val_loss: 0.6071\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.4553 - val_accuracy: 0.7572 - val_loss: 0.6172\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8166 - loss: 0.4553 - val_accuracy: 0.7572 - val_loss: 0.6172\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.4450 - val_accuracy: 0.7447 - val_loss: 0.6449\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.4450 - val_accuracy: 0.7447 - val_loss: 0.6449\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.4272 - val_accuracy: 0.7558 - val_loss: 0.6316\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.4272 - val_accuracy: 0.7558 - val_loss: 0.6316\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8335 - loss: 0.4173 - val_accuracy: 0.7558 - val_loss: 0.6148\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8335 - loss: 0.4173 - val_accuracy: 0.7558 - val_loss: 0.6148\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "âœ… Train Acc: 0.8335 | Val Acc: 0.7558\n",
      "   Train Loss: 0.4173 | Val Loss: 0.6148\n",
      "   Epochs: 20/50 | Time: 36.1s\n",
      "âœ… Train Acc: 0.8335 | Val Acc: 0.7558\n",
      "   Train Loss: 0.4173 | Val Loss: 0.6148\n",
      "   Epochs: 20/50 | Time: 36.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–„â–…â–…â–…â–…â–†â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–‚â–â–â–â–‚â–ƒâ–ƒâ–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>20</td></tr><tr><td>best_val_acc</td><td>0.75575</td></tr><tr><td>epoch/accuracy</td><td>0.83347</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.4173</td></tr><tr><td>epoch/val_accuracy</td><td>0.75575</td></tr><tr><td>epoch/val_loss</td><td>0.61477</td></tr><tr><td>final_train_acc</td><td>0.83347</td></tr><tr><td>final_train_loss</td><td>0.4173</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-cd7b1338</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/x6ma1crm' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/x6ma1crm</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-cd7b1338/wandb/run-20251204_050455-x6ma1crm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 208/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | tanh | dropout=0.3333 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-bcca71fc/wandb/run-20251204_050535-rz7c6uw2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/rz7c6uw2' target=\"_blank\">RNN-BiGRU-sgd-seed42-bcca71fc</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/rz7c6uw2' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/rz7c6uw2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6012 - loss: 1.0089 - val_accuracy: 0.6917 - val_loss: 0.7644\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6012 - loss: 1.0089 - val_accuracy: 0.6917 - val_loss: 0.7644\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6941 - loss: 0.7487 - val_accuracy: 0.7207 - val_loss: 0.6928\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6941 - loss: 0.7487 - val_accuracy: 0.7207 - val_loss: 0.6928\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7050 - loss: 0.7087 - val_accuracy: 0.6901 - val_loss: 0.7112\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7050 - loss: 0.7087 - val_accuracy: 0.6901 - val_loss: 0.7112\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7145 - loss: 0.6833 - val_accuracy: 0.7266 - val_loss: 0.6620\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7145 - loss: 0.6833 - val_accuracy: 0.7266 - val_loss: 0.6620\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 0.6664 - val_accuracy: 0.7253 - val_loss: 0.6666\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 0.6664 - val_accuracy: 0.7253 - val_loss: 0.6666\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7266 - loss: 0.6523 - val_accuracy: 0.7219 - val_loss: 0.6639\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7266 - loss: 0.6523 - val_accuracy: 0.7219 - val_loss: 0.6639\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7335 - loss: 0.6419 - val_accuracy: 0.7360 - val_loss: 0.6436\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7335 - loss: 0.6419 - val_accuracy: 0.7360 - val_loss: 0.6436\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.6337 - val_accuracy: 0.7323 - val_loss: 0.6372\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.6337 - val_accuracy: 0.7323 - val_loss: 0.6372\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7417 - loss: 0.6234 - val_accuracy: 0.7365 - val_loss: 0.6388\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7417 - loss: 0.6234 - val_accuracy: 0.7365 - val_loss: 0.6388\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7432 - loss: 0.6135 - val_accuracy: 0.7413 - val_loss: 0.6288\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7432 - loss: 0.6135 - val_accuracy: 0.7413 - val_loss: 0.6288\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7470 - loss: 0.6060 - val_accuracy: 0.7429 - val_loss: 0.6347\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7470 - loss: 0.6060 - val_accuracy: 0.7429 - val_loss: 0.6347\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7485 - loss: 0.6010 - val_accuracy: 0.7446 - val_loss: 0.6268\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7485 - loss: 0.6010 - val_accuracy: 0.7446 - val_loss: 0.6268\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7541 - loss: 0.5916 - val_accuracy: 0.7475 - val_loss: 0.6147\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7541 - loss: 0.5916 - val_accuracy: 0.7475 - val_loss: 0.6147\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.5850 - val_accuracy: 0.7447 - val_loss: 0.6268\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7568 - loss: 0.5850 - val_accuracy: 0.7447 - val_loss: 0.6268\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7591 - loss: 0.5779 - val_accuracy: 0.7368 - val_loss: 0.6341\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7591 - loss: 0.5779 - val_accuracy: 0.7368 - val_loss: 0.6341\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7620 - loss: 0.5713 - val_accuracy: 0.7475 - val_loss: 0.6274\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7620 - loss: 0.5713 - val_accuracy: 0.7475 - val_loss: 0.6274\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.5619 - val_accuracy: 0.7488 - val_loss: 0.6217\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.5619 - val_accuracy: 0.7488 - val_loss: 0.6217\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.5589 - val_accuracy: 0.7439 - val_loss: 0.6287\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.5589 - val_accuracy: 0.7439 - val_loss: 0.6287\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.5527 - val_accuracy: 0.7543 - val_loss: 0.6112\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.5527 - val_accuracy: 0.7543 - val_loss: 0.6112\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.5433 - val_accuracy: 0.7524 - val_loss: 0.6105\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.5433 - val_accuracy: 0.7524 - val_loss: 0.6105\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7799 - loss: 0.5369 - val_accuracy: 0.7527 - val_loss: 0.6071\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7799 - loss: 0.5369 - val_accuracy: 0.7527 - val_loss: 0.6071\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.5286 - val_accuracy: 0.7536 - val_loss: 0.6142\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.5286 - val_accuracy: 0.7536 - val_loss: 0.6142\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7816 - loss: 0.5288 - val_accuracy: 0.7548 - val_loss: 0.6102\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7816 - loss: 0.5288 - val_accuracy: 0.7548 - val_loss: 0.6102\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.5169 - val_accuracy: 0.7566 - val_loss: 0.6091\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.5169 - val_accuracy: 0.7566 - val_loss: 0.6091\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.5116 - val_accuracy: 0.7553 - val_loss: 0.6040\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7891 - loss: 0.5116 - val_accuracy: 0.7553 - val_loss: 0.6040\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7938 - loss: 0.5046 - val_accuracy: 0.7569 - val_loss: 0.6073\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7938 - loss: 0.5046 - val_accuracy: 0.7569 - val_loss: 0.6073\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.5051 - val_accuracy: 0.7533 - val_loss: 0.6152\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.5051 - val_accuracy: 0.7533 - val_loss: 0.6152\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7974 - loss: 0.4963 - val_accuracy: 0.7561 - val_loss: 0.6131\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7974 - loss: 0.4963 - val_accuracy: 0.7561 - val_loss: 0.6131\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.4912 - val_accuracy: 0.7580 - val_loss: 0.6156\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7991 - loss: 0.4912 - val_accuracy: 0.7580 - val_loss: 0.6156\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8032 - loss: 0.4829 - val_accuracy: 0.7600 - val_loss: 0.6132\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8032 - loss: 0.4829 - val_accuracy: 0.7600 - val_loss: 0.6132\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4742 - val_accuracy: 0.7655 - val_loss: 0.6083\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8067 - loss: 0.4742 - val_accuracy: 0.7655 - val_loss: 0.6083\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8071 - loss: 0.4699 - val_accuracy: 0.7600 - val_loss: 0.6271\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8071 - loss: 0.4699 - val_accuracy: 0.7600 - val_loss: 0.6271\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8070 - loss: 0.4693 - val_accuracy: 0.7640 - val_loss: 0.6101\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8070 - loss: 0.4693 - val_accuracy: 0.7640 - val_loss: 0.6101\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.4598 - val_accuracy: 0.7554 - val_loss: 0.6120\n",
      "Epoch 35/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8137 - loss: 0.4598 - val_accuracy: 0.7554 - val_loss: 0.6120\n",
      "Epoch 35/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.4592 - val_accuracy: 0.7622 - val_loss: 0.6070\n",
      "Epoch 36/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8124 - loss: 0.4592 - val_accuracy: 0.7622 - val_loss: 0.6070\n",
      "Epoch 36/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8154 - loss: 0.4510 - val_accuracy: 0.7630 - val_loss: 0.6096\n",
      "Epoch 37/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8154 - loss: 0.4510 - val_accuracy: 0.7630 - val_loss: 0.6096\n",
      "Epoch 37/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.4414 - val_accuracy: 0.7621 - val_loss: 0.6214\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8203 - loss: 0.4414 - val_accuracy: 0.7621 - val_loss: 0.6214\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 31.\n",
      "âœ… Train Acc: 0.8203 | Val Acc: 0.7621\n",
      "   Train Loss: 0.4414 | Val Loss: 0.6214\n",
      "   Epochs: 37/50 | Time: 54.6s\n",
      "âœ… Train Acc: 0.8203 | Val Acc: 0.7621\n",
      "   Train Loss: 0.4414 | Val Loss: 0.6214\n",
      "   Epochs: 37/50 | Time: 54.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–…â–†â–„â–„â–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>37</td></tr><tr><td>best_val_acc</td><td>0.76207</td></tr><tr><td>epoch/accuracy</td><td>0.8203</td></tr><tr><td>epoch/epoch</td><td>36</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.44144</td></tr><tr><td>epoch/val_accuracy</td><td>0.76207</td></tr><tr><td>epoch/val_loss</td><td>0.62142</td></tr><tr><td>final_train_acc</td><td>0.8203</td></tr><tr><td>final_train_loss</td><td>0.44144</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-bcca71fc</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/rz7c6uw2' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/rz7c6uw2</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-bcca71fc/wandb/run-20251204_050535-rz7c6uw2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 209/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | tanh | dropout=0.3333 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-2e6d0d88/wandb/run-20251204_050633-icx8nwku</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/icx8nwku' target=\"_blank\">RNN-BiGRU-sgd-seed42-2e6d0d88</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/icx8nwku' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/icx8nwku</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6187 - loss: 0.9644 - val_accuracy: 0.7018 - val_loss: 0.7370\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6187 - loss: 0.9644 - val_accuracy: 0.7018 - val_loss: 0.7370\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6986 - loss: 0.7365 - val_accuracy: 0.7207 - val_loss: 0.6844\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6986 - loss: 0.7365 - val_accuracy: 0.7207 - val_loss: 0.6844\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7128 - loss: 0.6957 - val_accuracy: 0.7272 - val_loss: 0.6628\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7128 - loss: 0.6957 - val_accuracy: 0.7272 - val_loss: 0.6628\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7223 - loss: 0.6727 - val_accuracy: 0.7143 - val_loss: 0.6812\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7223 - loss: 0.6727 - val_accuracy: 0.7143 - val_loss: 0.6812\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7279 - loss: 0.6540 - val_accuracy: 0.7224 - val_loss: 0.6777\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7279 - loss: 0.6540 - val_accuracy: 0.7224 - val_loss: 0.6777\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7313 - loss: 0.6465 - val_accuracy: 0.7347 - val_loss: 0.6405\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7313 - loss: 0.6465 - val_accuracy: 0.7347 - val_loss: 0.6405\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7378 - loss: 0.6307 - val_accuracy: 0.7290 - val_loss: 0.6754\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7378 - loss: 0.6307 - val_accuracy: 0.7290 - val_loss: 0.6754\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.6225 - val_accuracy: 0.7327 - val_loss: 0.6321\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7426 - loss: 0.6225 - val_accuracy: 0.7327 - val_loss: 0.6321\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 0.6154 - val_accuracy: 0.7408 - val_loss: 0.6308\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 0.6154 - val_accuracy: 0.7408 - val_loss: 0.6308\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7484 - loss: 0.6057 - val_accuracy: 0.7412 - val_loss: 0.6306\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7484 - loss: 0.6057 - val_accuracy: 0.7412 - val_loss: 0.6306\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7527 - loss: 0.5963 - val_accuracy: 0.7384 - val_loss: 0.6408\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7527 - loss: 0.5963 - val_accuracy: 0.7384 - val_loss: 0.6408\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7560 - loss: 0.5934 - val_accuracy: 0.7504 - val_loss: 0.6160\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7560 - loss: 0.5934 - val_accuracy: 0.7504 - val_loss: 0.6160\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7618 - loss: 0.5804 - val_accuracy: 0.7452 - val_loss: 0.6219\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7618 - loss: 0.5804 - val_accuracy: 0.7452 - val_loss: 0.6219\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7633 - loss: 0.5727 - val_accuracy: 0.7457 - val_loss: 0.6163\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7633 - loss: 0.5727 - val_accuracy: 0.7457 - val_loss: 0.6163\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.5641 - val_accuracy: 0.7488 - val_loss: 0.6130\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7671 - loss: 0.5641 - val_accuracy: 0.7488 - val_loss: 0.6130\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7726 - loss: 0.5516 - val_accuracy: 0.7455 - val_loss: 0.6227\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7726 - loss: 0.5516 - val_accuracy: 0.7455 - val_loss: 0.6227\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.5520 - val_accuracy: 0.7507 - val_loss: 0.6071\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7749 - loss: 0.5520 - val_accuracy: 0.7507 - val_loss: 0.6071\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7747 - loss: 0.5473 - val_accuracy: 0.7546 - val_loss: 0.6018\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7747 - loss: 0.5473 - val_accuracy: 0.7546 - val_loss: 0.6018\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.5374 - val_accuracy: 0.7559 - val_loss: 0.6086\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7827 - loss: 0.5374 - val_accuracy: 0.7559 - val_loss: 0.6086\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.5321 - val_accuracy: 0.7483 - val_loss: 0.6153\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7825 - loss: 0.5321 - val_accuracy: 0.7483 - val_loss: 0.6153\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.5196 - val_accuracy: 0.7504 - val_loss: 0.6228\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.5196 - val_accuracy: 0.7504 - val_loss: 0.6228\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.5188 - val_accuracy: 0.7459 - val_loss: 0.6189\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7830 - loss: 0.5188 - val_accuracy: 0.7459 - val_loss: 0.6189\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7931 - loss: 0.5071 - val_accuracy: 0.7609 - val_loss: 0.6007\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7931 - loss: 0.5071 - val_accuracy: 0.7609 - val_loss: 0.6007\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7953 - loss: 0.5030 - val_accuracy: 0.7593 - val_loss: 0.6008\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7953 - loss: 0.5030 - val_accuracy: 0.7593 - val_loss: 0.6008\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.4918 - val_accuracy: 0.7561 - val_loss: 0.6046\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.4918 - val_accuracy: 0.7561 - val_loss: 0.6046\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4866 - val_accuracy: 0.7645 - val_loss: 0.6013\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4866 - val_accuracy: 0.7645 - val_loss: 0.6013\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.4779 - val_accuracy: 0.7603 - val_loss: 0.6115\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.4779 - val_accuracy: 0.7603 - val_loss: 0.6115\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4766 - val_accuracy: 0.7592 - val_loss: 0.6180\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4766 - val_accuracy: 0.7592 - val_loss: 0.6180\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8131 - loss: 0.4642 - val_accuracy: 0.7558 - val_loss: 0.6162\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8131 - loss: 0.4642 - val_accuracy: 0.7558 - val_loss: 0.6162\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.4647 - val_accuracy: 0.7527 - val_loss: 0.6131\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8121 - loss: 0.4647 - val_accuracy: 0.7527 - val_loss: 0.6131\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.4577 - val_accuracy: 0.7640 - val_loss: 0.6042\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8171 - loss: 0.4577 - val_accuracy: 0.7640 - val_loss: 0.6042\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8216 - loss: 0.4476 - val_accuracy: 0.7598 - val_loss: 0.6110\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8216 - loss: 0.4476 - val_accuracy: 0.7598 - val_loss: 0.6110\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "âœ… Train Acc: 0.8216 | Val Acc: 0.7598\n",
      "   Train Loss: 0.4476 | Val Loss: 0.6110\n",
      "   Epochs: 32/50 | Time: 49.3s\n",
      "âœ… Train Acc: 0.8216 | Val Acc: 0.7598\n",
      "   Train Loss: 0.4476 | Val Loss: 0.6110\n",
      "   Epochs: 32/50 | Time: 49.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–„â–‚â–ƒâ–…â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–†â–†â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–…â–„â–…â–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>32</td></tr><tr><td>best_val_acc</td><td>0.75981</td></tr><tr><td>epoch/accuracy</td><td>0.8216</td></tr><tr><td>epoch/epoch</td><td>31</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.4476</td></tr><tr><td>epoch/val_accuracy</td><td>0.75981</td></tr><tr><td>epoch/val_loss</td><td>0.61103</td></tr><tr><td>final_train_acc</td><td>0.8216</td></tr><tr><td>final_train_loss</td><td>0.4476</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-2e6d0d88</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/icx8nwku' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/icx8nwku</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-2e6d0d88/wandb/run-20251204_050633-icx8nwku/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 210/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | tanh | dropout=0.3333 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-e74af0e6/wandb/run-20251204_050726-ql1o96oz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ql1o96oz' target=\"_blank\">RNN-BiGRU-sgd-seed42-e74af0e6</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ql1o96oz' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ql1o96oz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6205 - loss: 0.9782 - val_accuracy: 0.7157 - val_loss: 0.7061\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6205 - loss: 0.9782 - val_accuracy: 0.7157 - val_loss: 0.7061\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7004 - loss: 0.7378 - val_accuracy: 0.7232 - val_loss: 0.6770\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7004 - loss: 0.7378 - val_accuracy: 0.7232 - val_loss: 0.6770\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7131 - loss: 0.6958 - val_accuracy: 0.7282 - val_loss: 0.6601\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7131 - loss: 0.6958 - val_accuracy: 0.7282 - val_loss: 0.6601\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7208 - loss: 0.6685 - val_accuracy: 0.7368 - val_loss: 0.6522\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7208 - loss: 0.6685 - val_accuracy: 0.7368 - val_loss: 0.6522\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7292 - loss: 0.6537 - val_accuracy: 0.7353 - val_loss: 0.6471\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7292 - loss: 0.6537 - val_accuracy: 0.7353 - val_loss: 0.6471\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7374 - loss: 0.6396 - val_accuracy: 0.7358 - val_loss: 0.6480\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7374 - loss: 0.6396 - val_accuracy: 0.7358 - val_loss: 0.6480\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7424 - loss: 0.6255 - val_accuracy: 0.7404 - val_loss: 0.6283\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7424 - loss: 0.6255 - val_accuracy: 0.7404 - val_loss: 0.6283\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7468 - loss: 0.6170 - val_accuracy: 0.7429 - val_loss: 0.6292\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7468 - loss: 0.6170 - val_accuracy: 0.7429 - val_loss: 0.6292\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 0.6114 - val_accuracy: 0.7429 - val_loss: 0.6248\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 0.6114 - val_accuracy: 0.7429 - val_loss: 0.6248\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7515 - loss: 0.5989 - val_accuracy: 0.7449 - val_loss: 0.6249\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7515 - loss: 0.5989 - val_accuracy: 0.7449 - val_loss: 0.6249\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.5893 - val_accuracy: 0.7431 - val_loss: 0.6250\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.5893 - val_accuracy: 0.7431 - val_loss: 0.6250\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7626 - loss: 0.5829 - val_accuracy: 0.7439 - val_loss: 0.6184\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7626 - loss: 0.5829 - val_accuracy: 0.7439 - val_loss: 0.6184\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7617 - loss: 0.5773 - val_accuracy: 0.7522 - val_loss: 0.6177\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7617 - loss: 0.5773 - val_accuracy: 0.7522 - val_loss: 0.6177\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7657 - loss: 0.5662 - val_accuracy: 0.7498 - val_loss: 0.6152\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7657 - loss: 0.5662 - val_accuracy: 0.7498 - val_loss: 0.6152\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 0.5554 - val_accuracy: 0.7558 - val_loss: 0.6095\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 0.5554 - val_accuracy: 0.7558 - val_loss: 0.6095\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7761 - loss: 0.5481 - val_accuracy: 0.7394 - val_loss: 0.6369\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7761 - loss: 0.5481 - val_accuracy: 0.7394 - val_loss: 0.6369\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7805 - loss: 0.5391 - val_accuracy: 0.7522 - val_loss: 0.6114\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7805 - loss: 0.5391 - val_accuracy: 0.7522 - val_loss: 0.6114\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7828 - loss: 0.5345 - val_accuracy: 0.7571 - val_loss: 0.6202\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7828 - loss: 0.5345 - val_accuracy: 0.7571 - val_loss: 0.6202\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 0.5239 - val_accuracy: 0.7572 - val_loss: 0.6061\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7861 - loss: 0.5239 - val_accuracy: 0.7572 - val_loss: 0.6061\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.5154 - val_accuracy: 0.7538 - val_loss: 0.6193\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.5154 - val_accuracy: 0.7538 - val_loss: 0.6193\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.5134 - val_accuracy: 0.7577 - val_loss: 0.6096\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7912 - loss: 0.5134 - val_accuracy: 0.7577 - val_loss: 0.6096\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.5023 - val_accuracy: 0.7541 - val_loss: 0.6172\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7942 - loss: 0.5023 - val_accuracy: 0.7541 - val_loss: 0.6172\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7975 - loss: 0.4974 - val_accuracy: 0.7553 - val_loss: 0.6067\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7975 - loss: 0.4974 - val_accuracy: 0.7553 - val_loss: 0.6067\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.4897 - val_accuracy: 0.7324 - val_loss: 0.6550\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.4897 - val_accuracy: 0.7324 - val_loss: 0.6550\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8056 - loss: 0.4801 - val_accuracy: 0.7532 - val_loss: 0.6197\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8056 - loss: 0.4801 - val_accuracy: 0.7532 - val_loss: 0.6197\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.4739 - val_accuracy: 0.7498 - val_loss: 0.6271\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8085 - loss: 0.4739 - val_accuracy: 0.7498 - val_loss: 0.6271\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8136 - loss: 0.4638 - val_accuracy: 0.7595 - val_loss: 0.6055\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8136 - loss: 0.4638 - val_accuracy: 0.7595 - val_loss: 0.6055\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.4579 - val_accuracy: 0.7590 - val_loss: 0.6177\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8128 - loss: 0.4579 - val_accuracy: 0.7590 - val_loss: 0.6177\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.4497 - val_accuracy: 0.7608 - val_loss: 0.6154\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8200 - loss: 0.4497 - val_accuracy: 0.7608 - val_loss: 0.6154\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.4420 - val_accuracy: 0.7577 - val_loss: 0.6078\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.4420 - val_accuracy: 0.7577 - val_loss: 0.6078\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8263 - loss: 0.4345 - val_accuracy: 0.7614 - val_loss: 0.6162\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8263 - loss: 0.4345 - val_accuracy: 0.7614 - val_loss: 0.6162\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.4288 - val_accuracy: 0.7519 - val_loss: 0.6199\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8269 - loss: 0.4288 - val_accuracy: 0.7519 - val_loss: 0.6199\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.4204 - val_accuracy: 0.7554 - val_loss: 0.6248\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8335 - loss: 0.4204 - val_accuracy: 0.7554 - val_loss: 0.6248\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.4117 - val_accuracy: 0.7652 - val_loss: 0.6039\n",
      "Epoch 35/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.4117 - val_accuracy: 0.7652 - val_loss: 0.6039\n",
      "Epoch 35/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.4016 - val_accuracy: 0.7626 - val_loss: 0.6102\n",
      "Epoch 36/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.4016 - val_accuracy: 0.7626 - val_loss: 0.6102\n",
      "Epoch 36/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8447 - loss: 0.3935 - val_accuracy: 0.7652 - val_loss: 0.6153\n",
      "Epoch 37/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8447 - loss: 0.3935 - val_accuracy: 0.7652 - val_loss: 0.6153\n",
      "Epoch 37/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.3923 - val_accuracy: 0.7619 - val_loss: 0.6156\n",
      "Epoch 38/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.3923 - val_accuracy: 0.7619 - val_loss: 0.6156\n",
      "Epoch 38/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8482 - loss: 0.3812 - val_accuracy: 0.7540 - val_loss: 0.6393\n",
      "Epoch 39/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8482 - loss: 0.3812 - val_accuracy: 0.7540 - val_loss: 0.6393\n",
      "Epoch 39/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.3754 - val_accuracy: 0.7658 - val_loss: 0.6326\n",
      "Epoch 40/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.3754 - val_accuracy: 0.7658 - val_loss: 0.6326\n",
      "Epoch 40/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3652 - val_accuracy: 0.7608 - val_loss: 0.6332\n",
      "Epoch 41/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3652 - val_accuracy: 0.7608 - val_loss: 0.6332\n",
      "Epoch 41/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3583 - val_accuracy: 0.7632 - val_loss: 0.6364\n",
      "Epoch 42/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3583 - val_accuracy: 0.7632 - val_loss: 0.6364\n",
      "Epoch 42/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8662 - loss: 0.3433 - val_accuracy: 0.7501 - val_loss: 0.6772\n",
      "Epoch 43/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8662 - loss: 0.3433 - val_accuracy: 0.7501 - val_loss: 0.6772\n",
      "Epoch 43/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.3437 - val_accuracy: 0.7549 - val_loss: 0.6701\n",
      "Epoch 44/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.3437 - val_accuracy: 0.7549 - val_loss: 0.6701\n",
      "Epoch 44/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3365 - val_accuracy: 0.7658 - val_loss: 0.6637\n",
      "Epoch 45/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3365 - val_accuracy: 0.7658 - val_loss: 0.6637\n",
      "Epoch 45/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3334 - val_accuracy: 0.7677 - val_loss: 0.6689\n",
      "Epoch 46/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3334 - val_accuracy: 0.7677 - val_loss: 0.6689\n",
      "Epoch 46/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8737 - loss: 0.3275 - val_accuracy: 0.7677 - val_loss: 0.6415\n",
      "Epoch 47/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8737 - loss: 0.3275 - val_accuracy: 0.7677 - val_loss: 0.6415\n",
      "Epoch 47/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8790 - loss: 0.3161 - val_accuracy: 0.7626 - val_loss: 0.6486\n",
      "Epoch 48/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8790 - loss: 0.3161 - val_accuracy: 0.7626 - val_loss: 0.6486\n",
      "Epoch 48/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.3129 - val_accuracy: 0.7677 - val_loss: 0.6728\n",
      "Epoch 49/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.3129 - val_accuracy: 0.7677 - val_loss: 0.6728\n",
      "Epoch 49/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8821 - loss: 0.3031 - val_accuracy: 0.7686 - val_loss: 0.6502\n",
      "Epoch 50/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8821 - loss: 0.3031 - val_accuracy: 0.7686 - val_loss: 0.6502\n",
      "Epoch 50/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.2984 - val_accuracy: 0.7679 - val_loss: 0.6571\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.2984 - val_accuracy: 0.7679 - val_loss: 0.6571\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "âœ… Train Acc: 0.8847 | Val Acc: 0.7679\n",
      "   Train Loss: 0.2984 | Val Loss: 0.6571\n",
      "   Epochs: 50/50 | Time: 73.4s\n",
      "   ğŸŒŸ NEW BEST MODEL! Val Acc: 0.7679\n",
      "âœ… Train Acc: 0.8847 | Val Acc: 0.7679\n",
      "   Train Loss: 0.2984 | Val Loss: 0.6571\n",
      "   Epochs: 50/50 | Time: 73.4s\n",
      "   ğŸŒŸ NEW BEST MODEL! Val Acc: 0.7679\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–‚â–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–†â–†â–ƒâ–†â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–†â–†â–ˆâ–ˆâ–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–†â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–†â–…â–…â–„â–„â–„</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>50</td></tr><tr><td>best_val_acc</td><td>0.76791</td></tr><tr><td>epoch/accuracy</td><td>0.88468</td></tr><tr><td>epoch/epoch</td><td>49</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.29843</td></tr><tr><td>epoch/val_accuracy</td><td>0.76791</td></tr><tr><td>epoch/val_loss</td><td>0.65713</td></tr><tr><td>final_train_acc</td><td>0.88468</td></tr><tr><td>final_train_loss</td><td>0.29843</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-e74af0e6</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ql1o96oz' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ql1o96oz</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-e74af0e6/wandb/run-20251204_050726-ql1o96oz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ’¾ Progress saved (210/36)\n",
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 211/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | selu | dropout=0.2 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-f5cde9fe/wandb/run-20251204_050844-jjpmxi1n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jjpmxi1n' target=\"_blank\">RNN-BiGRU-sgd-seed42-f5cde9fe</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jjpmxi1n' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jjpmxi1n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6329 - loss: 0.9279 - val_accuracy: 0.7042 - val_loss: 0.7058\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6329 - loss: 0.9279 - val_accuracy: 0.7042 - val_loss: 0.7058\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7079 - loss: 0.7040 - val_accuracy: 0.7264 - val_loss: 0.6771\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7079 - loss: 0.7040 - val_accuracy: 0.7264 - val_loss: 0.6771\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7228 - loss: 0.6657 - val_accuracy: 0.7233 - val_loss: 0.6644\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7228 - loss: 0.6657 - val_accuracy: 0.7233 - val_loss: 0.6644\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7274 - loss: 0.6515 - val_accuracy: 0.7274 - val_loss: 0.6517\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7274 - loss: 0.6515 - val_accuracy: 0.7274 - val_loss: 0.6517\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.6309 - val_accuracy: 0.7303 - val_loss: 0.6528\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7382 - loss: 0.6309 - val_accuracy: 0.7303 - val_loss: 0.6528\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.6196 - val_accuracy: 0.7428 - val_loss: 0.6249\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.6196 - val_accuracy: 0.7428 - val_loss: 0.6249\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7484 - loss: 0.6050 - val_accuracy: 0.7339 - val_loss: 0.6441\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7484 - loss: 0.6050 - val_accuracy: 0.7339 - val_loss: 0.6441\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7513 - loss: 0.5987 - val_accuracy: 0.7323 - val_loss: 0.6514\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7513 - loss: 0.5987 - val_accuracy: 0.7323 - val_loss: 0.6514\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7590 - loss: 0.5830 - val_accuracy: 0.7415 - val_loss: 0.6244\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7590 - loss: 0.5830 - val_accuracy: 0.7415 - val_loss: 0.6244\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.5724 - val_accuracy: 0.7527 - val_loss: 0.6067\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.5724 - val_accuracy: 0.7527 - val_loss: 0.6067\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.5591 - val_accuracy: 0.7444 - val_loss: 0.6170\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.5591 - val_accuracy: 0.7444 - val_loss: 0.6170\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7708 - loss: 0.5520 - val_accuracy: 0.7353 - val_loss: 0.6474\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7708 - loss: 0.5520 - val_accuracy: 0.7353 - val_loss: 0.6474\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.5436 - val_accuracy: 0.7540 - val_loss: 0.6013\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.5436 - val_accuracy: 0.7540 - val_loss: 0.6013\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.5320 - val_accuracy: 0.7549 - val_loss: 0.6110\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.5320 - val_accuracy: 0.7549 - val_loss: 0.6110\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7856 - loss: 0.5225 - val_accuracy: 0.7530 - val_loss: 0.6141\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7856 - loss: 0.5225 - val_accuracy: 0.7530 - val_loss: 0.6141\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7889 - loss: 0.5116 - val_accuracy: 0.7514 - val_loss: 0.6131\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7889 - loss: 0.5116 - val_accuracy: 0.7514 - val_loss: 0.6131\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.5062 - val_accuracy: 0.7548 - val_loss: 0.6066\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7918 - loss: 0.5062 - val_accuracy: 0.7548 - val_loss: 0.6066\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.4921 - val_accuracy: 0.7548 - val_loss: 0.6161\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7966 - loss: 0.4921 - val_accuracy: 0.7548 - val_loss: 0.6161\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.4871 - val_accuracy: 0.7618 - val_loss: 0.6046\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8000 - loss: 0.4871 - val_accuracy: 0.7618 - val_loss: 0.6046\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4755 - val_accuracy: 0.7587 - val_loss: 0.6106\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8048 - loss: 0.4755 - val_accuracy: 0.7587 - val_loss: 0.6106\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.4684 - val_accuracy: 0.7551 - val_loss: 0.6201\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.4684 - val_accuracy: 0.7551 - val_loss: 0.6201\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.4625 - val_accuracy: 0.7480 - val_loss: 0.6246\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8117 - loss: 0.4625 - val_accuracy: 0.7480 - val_loss: 0.6246\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8175 - loss: 0.4548 - val_accuracy: 0.7551 - val_loss: 0.6166\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8175 - loss: 0.4548 - val_accuracy: 0.7551 - val_loss: 0.6166\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.4390 - val_accuracy: 0.7630 - val_loss: 0.6119\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8229 - loss: 0.4390 - val_accuracy: 0.7630 - val_loss: 0.6119\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.4326 - val_accuracy: 0.7668 - val_loss: 0.6163\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8246 - loss: 0.4326 - val_accuracy: 0.7668 - val_loss: 0.6163\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.4206 - val_accuracy: 0.7632 - val_loss: 0.6103\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8306 - loss: 0.4206 - val_accuracy: 0.7632 - val_loss: 0.6103\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8307 - loss: 0.4165 - val_accuracy: 0.7621 - val_loss: 0.6347\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8307 - loss: 0.4165 - val_accuracy: 0.7621 - val_loss: 0.6347\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.4146 - val_accuracy: 0.7627 - val_loss: 0.6391\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8289 - loss: 0.4146 - val_accuracy: 0.7627 - val_loss: 0.6391\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3984 - val_accuracy: 0.7618 - val_loss: 0.6257\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8377 - loss: 0.3984 - val_accuracy: 0.7618 - val_loss: 0.6257\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.3912 - val_accuracy: 0.7583 - val_loss: 0.6321\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.3912 - val_accuracy: 0.7583 - val_loss: 0.6321\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8466 - loss: 0.3824 - val_accuracy: 0.7590 - val_loss: 0.6523\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8466 - loss: 0.3824 - val_accuracy: 0.7590 - val_loss: 0.6523\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "âœ… Train Acc: 0.8466 | Val Acc: 0.7590\n",
      "   Train Loss: 0.3824 | Val Loss: 0.6523\n",
      "   Epochs: 31/50 | Time: 47.2s\n",
      "âœ… Train Acc: 0.8466 | Val Acc: 0.7590\n",
      "   Train Loss: 0.3824 | Val Loss: 0.6523\n",
      "   Epochs: 31/50 | Time: 47.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–ƒâ–„â–„â–…â–„â–„â–…â–†â–…â–„â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–†â–…â–„â–„â–ƒâ–„â–„â–ƒâ–â–‚â–„â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–„</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>31</td></tr><tr><td>best_val_acc</td><td>0.759</td></tr><tr><td>epoch/accuracy</td><td>0.8466</td></tr><tr><td>epoch/epoch</td><td>30</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.38242</td></tr><tr><td>epoch/val_accuracy</td><td>0.759</td></tr><tr><td>epoch/val_loss</td><td>0.65231</td></tr><tr><td>final_train_acc</td><td>0.8466</td></tr><tr><td>final_train_loss</td><td>0.38242</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-f5cde9fe</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jjpmxi1n' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/jjpmxi1n</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-f5cde9fe/wandb/run-20251204_050844-jjpmxi1n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 212/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | selu | dropout=0.2 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-4a17e42a/wandb/run-20251204_050936-2lg86fkh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/2lg86fkh' target=\"_blank\">RNN-BiGRU-sgd-seed42-4a17e42a</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/2lg86fkh' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/2lg86fkh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6310 - loss: 0.9483 - val_accuracy: 0.7078 - val_loss: 0.7198\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6310 - loss: 0.9483 - val_accuracy: 0.7078 - val_loss: 0.7198\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7127 - loss: 0.7001 - val_accuracy: 0.7253 - val_loss: 0.6666\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7127 - loss: 0.7001 - val_accuracy: 0.7253 - val_loss: 0.6666\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7219 - loss: 0.6628 - val_accuracy: 0.7321 - val_loss: 0.6499\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7219 - loss: 0.6628 - val_accuracy: 0.7321 - val_loss: 0.6499\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7344 - loss: 0.6419 - val_accuracy: 0.7344 - val_loss: 0.6375\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7344 - loss: 0.6419 - val_accuracy: 0.7344 - val_loss: 0.6375\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7442 - loss: 0.6212 - val_accuracy: 0.7382 - val_loss: 0.6360\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7442 - loss: 0.6212 - val_accuracy: 0.7382 - val_loss: 0.6360\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7434 - loss: 0.6122 - val_accuracy: 0.7339 - val_loss: 0.6471\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7434 - loss: 0.6122 - val_accuracy: 0.7339 - val_loss: 0.6471\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7523 - loss: 0.5966 - val_accuracy: 0.7441 - val_loss: 0.6259\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7523 - loss: 0.5966 - val_accuracy: 0.7441 - val_loss: 0.6259\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7563 - loss: 0.5866 - val_accuracy: 0.7459 - val_loss: 0.6295\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7563 - loss: 0.5866 - val_accuracy: 0.7459 - val_loss: 0.6295\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7638 - loss: 0.5717 - val_accuracy: 0.7410 - val_loss: 0.6422\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7638 - loss: 0.5717 - val_accuracy: 0.7410 - val_loss: 0.6422\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7682 - loss: 0.5581 - val_accuracy: 0.7464 - val_loss: 0.6131\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7682 - loss: 0.5581 - val_accuracy: 0.7464 - val_loss: 0.6131\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7760 - loss: 0.5492 - val_accuracy: 0.7546 - val_loss: 0.6156\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7760 - loss: 0.5492 - val_accuracy: 0.7546 - val_loss: 0.6156\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7776 - loss: 0.5401 - val_accuracy: 0.7595 - val_loss: 0.6017\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7776 - loss: 0.5401 - val_accuracy: 0.7595 - val_loss: 0.6017\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7844 - loss: 0.5238 - val_accuracy: 0.7556 - val_loss: 0.6100\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7844 - loss: 0.5238 - val_accuracy: 0.7556 - val_loss: 0.6100\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.5180 - val_accuracy: 0.7579 - val_loss: 0.6131\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.5180 - val_accuracy: 0.7579 - val_loss: 0.6131\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.5067 - val_accuracy: 0.7540 - val_loss: 0.6042\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7927 - loss: 0.5067 - val_accuracy: 0.7540 - val_loss: 0.6042\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.4934 - val_accuracy: 0.7566 - val_loss: 0.6160\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7998 - loss: 0.4934 - val_accuracy: 0.7566 - val_loss: 0.6160\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.4831 - val_accuracy: 0.7538 - val_loss: 0.6137\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8029 - loss: 0.4831 - val_accuracy: 0.7538 - val_loss: 0.6137\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.4749 - val_accuracy: 0.7575 - val_loss: 0.6032\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8041 - loss: 0.4749 - val_accuracy: 0.7575 - val_loss: 0.6032\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 12.\n",
      "âœ… Train Acc: 0.8041 | Val Acc: 0.7575\n",
      "   Train Loss: 0.4749 | Val Loss: 0.6032\n",
      "   Epochs: 18/50 | Time: 31.4s\n",
      "âœ… Train Acc: 0.8041 | Val Acc: 0.7575\n",
      "   Train Loss: 0.4749 | Val Loss: 0.6032\n",
      "   Epochs: 18/50 | Time: 31.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–„â–…â–…â–…â–†â–†â–…â–†â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–…â–„â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–‚â–â–â–‚â–â–‚â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>18</td></tr><tr><td>best_val_acc</td><td>0.75754</td></tr><tr><td>epoch/accuracy</td><td>0.80405</td></tr><tr><td>epoch/epoch</td><td>17</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.47494</td></tr><tr><td>epoch/val_accuracy</td><td>0.75754</td></tr><tr><td>epoch/val_loss</td><td>0.60324</td></tr><tr><td>final_train_acc</td><td>0.80405</td></tr><tr><td>final_train_loss</td><td>0.47494</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-4a17e42a</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/2lg86fkh' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/2lg86fkh</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-4a17e42a/wandb/run-20251204_050936-2lg86fkh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 213/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | selu | dropout=0.2 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-f060e4d3/wandb/run-20251204_051011-zf1vokqi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/zf1vokqi' target=\"_blank\">RNN-BiGRU-sgd-seed42-f060e4d3</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/zf1vokqi' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/zf1vokqi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6404 - loss: 0.9530 - val_accuracy: 0.7122 - val_loss: 0.6898\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6404 - loss: 0.9530 - val_accuracy: 0.7122 - val_loss: 0.6898\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7104 - loss: 0.6948 - val_accuracy: 0.7253 - val_loss: 0.6679\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7104 - loss: 0.6948 - val_accuracy: 0.7253 - val_loss: 0.6679\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7263 - loss: 0.6520 - val_accuracy: 0.7365 - val_loss: 0.6424\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7263 - loss: 0.6520 - val_accuracy: 0.7365 - val_loss: 0.6424\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.6294 - val_accuracy: 0.7394 - val_loss: 0.6294\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.6294 - val_accuracy: 0.7394 - val_loss: 0.6294\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7441 - loss: 0.6112 - val_accuracy: 0.7360 - val_loss: 0.6394\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7441 - loss: 0.6112 - val_accuracy: 0.7360 - val_loss: 0.6394\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7511 - loss: 0.5969 - val_accuracy: 0.7434 - val_loss: 0.6231\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7511 - loss: 0.5969 - val_accuracy: 0.7434 - val_loss: 0.6231\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7551 - loss: 0.5867 - val_accuracy: 0.7502 - val_loss: 0.6175\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7551 - loss: 0.5867 - val_accuracy: 0.7502 - val_loss: 0.6175\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7632 - loss: 0.5723 - val_accuracy: 0.7360 - val_loss: 0.6273\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7632 - loss: 0.5723 - val_accuracy: 0.7360 - val_loss: 0.6273\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7726 - loss: 0.5563 - val_accuracy: 0.7532 - val_loss: 0.6142\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7726 - loss: 0.5563 - val_accuracy: 0.7532 - val_loss: 0.6142\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7762 - loss: 0.5458 - val_accuracy: 0.7481 - val_loss: 0.6238\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7762 - loss: 0.5458 - val_accuracy: 0.7481 - val_loss: 0.6238\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7820 - loss: 0.5335 - val_accuracy: 0.7434 - val_loss: 0.6235\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7820 - loss: 0.5335 - val_accuracy: 0.7434 - val_loss: 0.6235\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7878 - loss: 0.5198 - val_accuracy: 0.7468 - val_loss: 0.6185\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7878 - loss: 0.5198 - val_accuracy: 0.7468 - val_loss: 0.6185\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.5124 - val_accuracy: 0.7540 - val_loss: 0.6156\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.5124 - val_accuracy: 0.7540 - val_loss: 0.6156\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.5004 - val_accuracy: 0.7454 - val_loss: 0.6275\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.5004 - val_accuracy: 0.7454 - val_loss: 0.6275\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.4852 - val_accuracy: 0.7465 - val_loss: 0.6297\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8025 - loss: 0.4852 - val_accuracy: 0.7465 - val_loss: 0.6297\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.4734 - val_accuracy: 0.7572 - val_loss: 0.6186\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8079 - loss: 0.4734 - val_accuracy: 0.7572 - val_loss: 0.6186\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.4610 - val_accuracy: 0.7569 - val_loss: 0.6189\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.4610 - val_accuracy: 0.7569 - val_loss: 0.6189\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.4478 - val_accuracy: 0.7525 - val_loss: 0.6251\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8190 - loss: 0.4478 - val_accuracy: 0.7525 - val_loss: 0.6251\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.4385 - val_accuracy: 0.7588 - val_loss: 0.6273\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8246 - loss: 0.4385 - val_accuracy: 0.7588 - val_loss: 0.6273\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.4265 - val_accuracy: 0.7436 - val_loss: 0.6523\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.4265 - val_accuracy: 0.7436 - val_loss: 0.6523\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.4136 - val_accuracy: 0.7507 - val_loss: 0.6383\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8321 - loss: 0.4136 - val_accuracy: 0.7507 - val_loss: 0.6383\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8391 - loss: 0.4003 - val_accuracy: 0.7546 - val_loss: 0.6451\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8391 - loss: 0.4003 - val_accuracy: 0.7546 - val_loss: 0.6451\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8420 - loss: 0.3910 - val_accuracy: 0.7577 - val_loss: 0.6527\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8420 - loss: 0.3910 - val_accuracy: 0.7577 - val_loss: 0.6527\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.3800 - val_accuracy: 0.7600 - val_loss: 0.6433\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8451 - loss: 0.3800 - val_accuracy: 0.7600 - val_loss: 0.6433\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3699 - val_accuracy: 0.7452 - val_loss: 0.6720\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3699 - val_accuracy: 0.7452 - val_loss: 0.6720\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.3565 - val_accuracy: 0.7493 - val_loss: 0.6708\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8586 - loss: 0.3565 - val_accuracy: 0.7493 - val_loss: 0.6708\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3473 - val_accuracy: 0.7506 - val_loss: 0.7117\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3473 - val_accuracy: 0.7506 - val_loss: 0.7117\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8663 - loss: 0.3326 - val_accuracy: 0.7485 - val_loss: 0.7491\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8663 - loss: 0.3326 - val_accuracy: 0.7485 - val_loss: 0.7491\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8705 - loss: 0.3249 - val_accuracy: 0.7512 - val_loss: 0.6943\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8705 - loss: 0.3249 - val_accuracy: 0.7512 - val_loss: 0.6943\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.3090 - val_accuracy: 0.7608 - val_loss: 0.6960\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.3090 - val_accuracy: 0.7608 - val_loss: 0.6960\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 0.3018 - val_accuracy: 0.7554 - val_loss: 0.6982\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8836 - loss: 0.3018 - val_accuracy: 0.7554 - val_loss: 0.6982\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.2923 - val_accuracy: 0.7603 - val_loss: 0.7021\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.2923 - val_accuracy: 0.7603 - val_loss: 0.7021\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2832 - val_accuracy: 0.7384 - val_loss: 0.7519\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.2832 - val_accuracy: 0.7384 - val_loss: 0.7519\n",
      "Epoch 34/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.2729 - val_accuracy: 0.7439 - val_loss: 0.7913\n",
      "Epoch 35/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.2729 - val_accuracy: 0.7439 - val_loss: 0.7913\n",
      "Epoch 35/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8986 - loss: 0.2655 - val_accuracy: 0.7613 - val_loss: 0.7480\n",
      "Epoch 36/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8986 - loss: 0.2655 - val_accuracy: 0.7613 - val_loss: 0.7480\n",
      "Epoch 36/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.2540 - val_accuracy: 0.7504 - val_loss: 0.7950\n",
      "Epoch 37/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.2540 - val_accuracy: 0.7504 - val_loss: 0.7950\n",
      "Epoch 37/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2485 - val_accuracy: 0.7506 - val_loss: 0.7916\n",
      "Epoch 38/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2485 - val_accuracy: 0.7506 - val_loss: 0.7916\n",
      "Epoch 38/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2379 - val_accuracy: 0.7642 - val_loss: 0.7891\n",
      "Epoch 39/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2379 - val_accuracy: 0.7642 - val_loss: 0.7891\n",
      "Epoch 39/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2262 - val_accuracy: 0.7540 - val_loss: 0.8272\n",
      "Epoch 40/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2262 - val_accuracy: 0.7540 - val_loss: 0.8272\n",
      "Epoch 40/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2171 - val_accuracy: 0.7582 - val_loss: 0.8023\n",
      "Epoch 41/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2171 - val_accuracy: 0.7582 - val_loss: 0.8023\n",
      "Epoch 41/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.2143 - val_accuracy: 0.7489 - val_loss: 0.8199\n",
      "Epoch 42/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9194 - loss: 0.2143 - val_accuracy: 0.7489 - val_loss: 0.8199\n",
      "Epoch 42/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.2033 - val_accuracy: 0.7686 - val_loss: 0.7973\n",
      "Epoch 43/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.2033 - val_accuracy: 0.7686 - val_loss: 0.7973\n",
      "Epoch 43/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.1977 - val_accuracy: 0.7546 - val_loss: 0.8645\n",
      "Epoch 44/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.1977 - val_accuracy: 0.7546 - val_loss: 0.8645\n",
      "Epoch 44/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9284 - loss: 0.1905 - val_accuracy: 0.7686 - val_loss: 0.8277\n",
      "Epoch 45/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9284 - loss: 0.1905 - val_accuracy: 0.7686 - val_loss: 0.8277\n",
      "Epoch 45/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1818 - val_accuracy: 0.7658 - val_loss: 0.8414\n",
      "Epoch 46/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9317 - loss: 0.1818 - val_accuracy: 0.7658 - val_loss: 0.8414\n",
      "Epoch 46/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9321 - loss: 0.1778 - val_accuracy: 0.7645 - val_loss: 0.8560\n",
      "Epoch 47/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9321 - loss: 0.1778 - val_accuracy: 0.7645 - val_loss: 0.8560\n",
      "Epoch 47/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.1736 - val_accuracy: 0.7533 - val_loss: 0.8972\n",
      "Epoch 48/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.1736 - val_accuracy: 0.7533 - val_loss: 0.8972\n",
      "Epoch 48/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.1594 - val_accuracy: 0.7640 - val_loss: 0.8796\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9397 - loss: 0.1594 - val_accuracy: 0.7640 - val_loss: 0.8796\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 42.\n",
      "âœ… Train Acc: 0.9397 | Val Acc: 0.7640\n",
      "   Train Loss: 0.1594 | Val Loss: 0.8796\n",
      "   Epochs: 48/50 | Time: 70.6s\n",
      "âœ… Train Acc: 0.9397 | Val Acc: 0.7640\n",
      "   Train Loss: 0.1594 | Val Loss: 0.8796\n",
      "   Epochs: 48/50 | Time: 70.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–ƒâ–„â–„â–„â–†â–„â–†â–…â–…â–†â–…â–…â–‡â–‡â–‡â–…â–†â–†â–‡â–…â–†â–†â–†â–†â–†â–‡â–„â–…â–‡â–†â–‡â–†â–‡â–†â–†â–ˆâ–ˆâ–‡â–‡</td></tr><tr><td>epoch/val_loss</td><td>â–ƒâ–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–„â–…â–ƒâ–ƒâ–ƒâ–…â–†â–…â–†â–†â–‡â–†â–†â–ˆâ–‡â–‡â–‡â–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>48</td></tr><tr><td>best_val_acc</td><td>0.76402</td></tr><tr><td>epoch/accuracy</td><td>0.93975</td></tr><tr><td>epoch/epoch</td><td>47</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.15939</td></tr><tr><td>epoch/val_accuracy</td><td>0.76402</td></tr><tr><td>epoch/val_loss</td><td>0.87964</td></tr><tr><td>final_train_acc</td><td>0.93975</td></tr><tr><td>final_train_loss</td><td>0.15939</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-f060e4d3</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/zf1vokqi' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/zf1vokqi</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-f060e4d3/wandb/run-20251204_051011-zf1vokqi/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 214/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | selu | dropout=0.3333 | units=64\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-07725554/wandb/run-20251204_051126-ua18jji6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ua18jji6' target=\"_blank\">RNN-BiGRU-sgd-seed42-07725554</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ua18jji6' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ua18jji6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6248 - loss: 0.9570 - val_accuracy: 0.6969 - val_loss: 0.7400\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6248 - loss: 0.9570 - val_accuracy: 0.6969 - val_loss: 0.7400\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6992 - loss: 0.7254 - val_accuracy: 0.7138 - val_loss: 0.6867\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6992 - loss: 0.7254 - val_accuracy: 0.7138 - val_loss: 0.6867\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.6908 - val_accuracy: 0.7267 - val_loss: 0.6597\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7147 - loss: 0.6908 - val_accuracy: 0.7267 - val_loss: 0.6597\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 0.6721 - val_accuracy: 0.7277 - val_loss: 0.6508\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7220 - loss: 0.6721 - val_accuracy: 0.7277 - val_loss: 0.6508\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7227 - loss: 0.6635 - val_accuracy: 0.7253 - val_loss: 0.6511\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7227 - loss: 0.6635 - val_accuracy: 0.7253 - val_loss: 0.6511\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7331 - loss: 0.6474 - val_accuracy: 0.7254 - val_loss: 0.6605\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7331 - loss: 0.6474 - val_accuracy: 0.7254 - val_loss: 0.6605\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7368 - loss: 0.6372 - val_accuracy: 0.7394 - val_loss: 0.6364\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7368 - loss: 0.6372 - val_accuracy: 0.7394 - val_loss: 0.6364\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.6282 - val_accuracy: 0.7230 - val_loss: 0.6571\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.6282 - val_accuracy: 0.7230 - val_loss: 0.6571\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.6199 - val_accuracy: 0.7368 - val_loss: 0.6326\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.6199 - val_accuracy: 0.7368 - val_loss: 0.6326\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7467 - loss: 0.6094 - val_accuracy: 0.7352 - val_loss: 0.6293\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7467 - loss: 0.6094 - val_accuracy: 0.7352 - val_loss: 0.6293\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7467 - loss: 0.6035 - val_accuracy: 0.7282 - val_loss: 0.6423\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7467 - loss: 0.6035 - val_accuracy: 0.7282 - val_loss: 0.6423\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7506 - loss: 0.6015 - val_accuracy: 0.7324 - val_loss: 0.6384\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7506 - loss: 0.6015 - val_accuracy: 0.7324 - val_loss: 0.6384\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7522 - loss: 0.5929 - val_accuracy: 0.7389 - val_loss: 0.6233\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7522 - loss: 0.5929 - val_accuracy: 0.7389 - val_loss: 0.6233\n",
      "Epoch 13: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "âœ… Train Acc: 0.7522 | Val Acc: 0.7389\n",
      "   Train Loss: 0.5929 | Val Loss: 0.6233\n",
      "   Epochs: 13/50 | Time: 24.5s\n",
      "âœ… Train Acc: 0.7522 | Val Acc: 0.7389\n",
      "   Train Loss: 0.5929 | Val Loss: 0.6233\n",
      "   Epochs: 13/50 | Time: 24.5s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–†â–†â–‡â–‡â–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–†â–†â–†â–†â–ˆâ–…â–ˆâ–‡â–†â–‡â–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>13</td></tr><tr><td>best_val_acc</td><td>0.7389</td></tr><tr><td>epoch/accuracy</td><td>0.75223</td></tr><tr><td>epoch/epoch</td><td>12</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.59288</td></tr><tr><td>epoch/val_accuracy</td><td>0.7389</td></tr><tr><td>epoch/val_loss</td><td>0.6233</td></tr><tr><td>final_train_acc</td><td>0.75223</td></tr><tr><td>final_train_loss</td><td>0.59288</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-07725554</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ua18jji6' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/ua18jji6</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-07725554/wandb/run-20251204_051126-ua18jji6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 215/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | selu | dropout=0.3333 | units=128\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-50299570/wandb/run-20251204_051154-6vjjlkjp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/6vjjlkjp' target=\"_blank\">RNN-BiGRU-sgd-seed42-50299570</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/6vjjlkjp' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/6vjjlkjp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6174 - loss: 0.9885 - val_accuracy: 0.6964 - val_loss: 0.7327\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6174 - loss: 0.9885 - val_accuracy: 0.6964 - val_loss: 0.7327\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6970 - loss: 0.7297 - val_accuracy: 0.7233 - val_loss: 0.6723\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6970 - loss: 0.7297 - val_accuracy: 0.7233 - val_loss: 0.6723\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7110 - loss: 0.6903 - val_accuracy: 0.7258 - val_loss: 0.6608\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7110 - loss: 0.6903 - val_accuracy: 0.7258 - val_loss: 0.6608\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7225 - loss: 0.6647 - val_accuracy: 0.7300 - val_loss: 0.6513\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7225 - loss: 0.6647 - val_accuracy: 0.7300 - val_loss: 0.6513\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7252 - loss: 0.6546 - val_accuracy: 0.7211 - val_loss: 0.6758\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7252 - loss: 0.6546 - val_accuracy: 0.7211 - val_loss: 0.6758\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7287 - loss: 0.6473 - val_accuracy: 0.7402 - val_loss: 0.6307\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7287 - loss: 0.6473 - val_accuracy: 0.7402 - val_loss: 0.6307\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7347 - loss: 0.6298 - val_accuracy: 0.7395 - val_loss: 0.6420\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7347 - loss: 0.6298 - val_accuracy: 0.7395 - val_loss: 0.6420\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7404 - loss: 0.6237 - val_accuracy: 0.7434 - val_loss: 0.6313\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7404 - loss: 0.6237 - val_accuracy: 0.7434 - val_loss: 0.6313\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.6146 - val_accuracy: 0.7426 - val_loss: 0.6190\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 0.6146 - val_accuracy: 0.7426 - val_loss: 0.6190\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.6020 - val_accuracy: 0.7404 - val_loss: 0.6188\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.6020 - val_accuracy: 0.7404 - val_loss: 0.6188\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7503 - loss: 0.5960 - val_accuracy: 0.7459 - val_loss: 0.6298\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7503 - loss: 0.5960 - val_accuracy: 0.7459 - val_loss: 0.6298\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.5865 - val_accuracy: 0.7476 - val_loss: 0.6208\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7562 - loss: 0.5865 - val_accuracy: 0.7476 - val_loss: 0.6208\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7593 - loss: 0.5809 - val_accuracy: 0.7489 - val_loss: 0.6204\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7593 - loss: 0.5809 - val_accuracy: 0.7489 - val_loss: 0.6204\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7597 - loss: 0.5771 - val_accuracy: 0.7532 - val_loss: 0.6132\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7597 - loss: 0.5771 - val_accuracy: 0.7532 - val_loss: 0.6132\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.5651 - val_accuracy: 0.7528 - val_loss: 0.6048\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7672 - loss: 0.5651 - val_accuracy: 0.7528 - val_loss: 0.6048\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7635 - loss: 0.5595 - val_accuracy: 0.7488 - val_loss: 0.6199\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7635 - loss: 0.5595 - val_accuracy: 0.7488 - val_loss: 0.6199\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.5493 - val_accuracy: 0.7580 - val_loss: 0.6063\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.5493 - val_accuracy: 0.7580 - val_loss: 0.6063\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.5448 - val_accuracy: 0.7538 - val_loss: 0.6086\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7741 - loss: 0.5448 - val_accuracy: 0.7538 - val_loss: 0.6086\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.5399 - val_accuracy: 0.7566 - val_loss: 0.6035\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.5399 - val_accuracy: 0.7566 - val_loss: 0.6035\n",
      "Epoch 20/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7802 - loss: 0.5299 - val_accuracy: 0.7426 - val_loss: 0.6376\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7802 - loss: 0.5299 - val_accuracy: 0.7426 - val_loss: 0.6376\n",
      "Epoch 21/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7863 - loss: 0.5228 - val_accuracy: 0.7512 - val_loss: 0.6128\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7863 - loss: 0.5228 - val_accuracy: 0.7512 - val_loss: 0.6128\n",
      "Epoch 22/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7883 - loss: 0.5150 - val_accuracy: 0.7472 - val_loss: 0.6219\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7883 - loss: 0.5150 - val_accuracy: 0.7472 - val_loss: 0.6219\n",
      "Epoch 23/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.5085 - val_accuracy: 0.7585 - val_loss: 0.6055\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7915 - loss: 0.5085 - val_accuracy: 0.7585 - val_loss: 0.6055\n",
      "Epoch 24/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.5016 - val_accuracy: 0.7611 - val_loss: 0.5989\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.5016 - val_accuracy: 0.7611 - val_loss: 0.5989\n",
      "Epoch 25/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.4967 - val_accuracy: 0.7571 - val_loss: 0.5975\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7936 - loss: 0.4967 - val_accuracy: 0.7571 - val_loss: 0.5975\n",
      "Epoch 26/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7983 - loss: 0.4895 - val_accuracy: 0.7579 - val_loss: 0.6188\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7983 - loss: 0.4895 - val_accuracy: 0.7579 - val_loss: 0.6188\n",
      "Epoch 27/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.4846 - val_accuracy: 0.7669 - val_loss: 0.6030\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.4846 - val_accuracy: 0.7669 - val_loss: 0.6030\n",
      "Epoch 28/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.4740 - val_accuracy: 0.7616 - val_loss: 0.6183\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.4740 - val_accuracy: 0.7616 - val_loss: 0.6183\n",
      "Epoch 29/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.4657 - val_accuracy: 0.7648 - val_loss: 0.5994\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8064 - loss: 0.4657 - val_accuracy: 0.7648 - val_loss: 0.5994\n",
      "Epoch 30/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.4630 - val_accuracy: 0.7626 - val_loss: 0.6063\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8069 - loss: 0.4630 - val_accuracy: 0.7626 - val_loss: 0.6063\n",
      "Epoch 31/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.4543 - val_accuracy: 0.7639 - val_loss: 0.6032\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8127 - loss: 0.4543 - val_accuracy: 0.7639 - val_loss: 0.6032\n",
      "Epoch 32/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8126 - loss: 0.4507 - val_accuracy: 0.7658 - val_loss: 0.6052\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8126 - loss: 0.4507 - val_accuracy: 0.7658 - val_loss: 0.6052\n",
      "Epoch 33/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 0.4418 - val_accuracy: 0.7630 - val_loss: 0.6075\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8189 - loss: 0.4418 - val_accuracy: 0.7630 - val_loss: 0.6075\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "âœ… Train Acc: 0.8189 | Val Acc: 0.7630\n",
      "   Train Loss: 0.4418 | Val Loss: 0.6075\n",
      "   Epochs: 33/50 | Time: 49.8s\n",
      "âœ… Train Acc: 0.8189 | Val Acc: 0.7630\n",
      "   Train Loss: 0.4418 | Val Loss: 0.6075\n",
      "   Epochs: 33/50 | Time: 49.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–…â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–„â–„â–„â–ƒâ–…â–…â–†â–†â–…â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–…â–„â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–‚â–â–ƒâ–‚â–‚â–â–â–â–‚â–â–‚â–â–â–â–â–‚</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>33</td></tr><tr><td>best_val_acc</td><td>0.76305</td></tr><tr><td>epoch/accuracy</td><td>0.81888</td></tr><tr><td>epoch/epoch</td><td>32</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.4418</td></tr><tr><td>epoch/val_accuracy</td><td>0.76305</td></tr><tr><td>epoch/val_loss</td><td>0.60745</td></tr><tr><td>final_train_acc</td><td>0.81888</td></tr><tr><td>final_train_loss</td><td>0.4418</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-50299570</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/6vjjlkjp' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/6vjjlkjp</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-50299570/wandb/run-20251204_051154-6vjjlkjp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ğŸ’¾ Progress saved (215/36)\n",
      "\n",
      "======================================================================\n",
      "ğŸ”„ Progress: 216/36 configurations\n",
      "Config: BiGRU | sgd | lr=0.001 | mom=0.95 | selu | dropout=0.3333 | units=256\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>progress/RNN-BiGRU-sgd-seed42-c701e39c/wandb/run-20251204_051248-2vti964l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/2vti964l' target=\"_blank\">RNN-BiGRU-sgd-seed42-c701e39c</a></strong> to <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/2vti964l' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/2vti964l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.6290 - loss: 0.9850 - val_accuracy: 0.7160 - val_loss: 0.6943\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.6290 - loss: 0.9850 - val_accuracy: 0.7160 - val_loss: 0.6943\n",
      "Epoch 2/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.7197 - val_accuracy: 0.7173 - val_loss: 0.6861\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.7197 - val_accuracy: 0.7173 - val_loss: 0.6861\n",
      "Epoch 3/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7174 - loss: 0.6812 - val_accuracy: 0.7290 - val_loss: 0.6629\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7174 - loss: 0.6812 - val_accuracy: 0.7290 - val_loss: 0.6629\n",
      "Epoch 4/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7248 - loss: 0.6599 - val_accuracy: 0.7326 - val_loss: 0.6493\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7248 - loss: 0.6599 - val_accuracy: 0.7326 - val_loss: 0.6493\n",
      "Epoch 5/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7315 - loss: 0.6435 - val_accuracy: 0.7160 - val_loss: 0.6918\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7315 - loss: 0.6435 - val_accuracy: 0.7160 - val_loss: 0.6918\n",
      "Epoch 6/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7346 - loss: 0.6329 - val_accuracy: 0.7365 - val_loss: 0.6361\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7346 - loss: 0.6329 - val_accuracy: 0.7365 - val_loss: 0.6361\n",
      "Epoch 7/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7425 - loss: 0.6191 - val_accuracy: 0.7441 - val_loss: 0.6262\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7425 - loss: 0.6191 - val_accuracy: 0.7441 - val_loss: 0.6262\n",
      "Epoch 8/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7421 - loss: 0.6126 - val_accuracy: 0.7439 - val_loss: 0.6313\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7421 - loss: 0.6126 - val_accuracy: 0.7439 - val_loss: 0.6313\n",
      "Epoch 9/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.6018 - val_accuracy: 0.7423 - val_loss: 0.6220\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7475 - loss: 0.6018 - val_accuracy: 0.7423 - val_loss: 0.6220\n",
      "Epoch 10/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7521 - loss: 0.5933 - val_accuracy: 0.7370 - val_loss: 0.6252\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7521 - loss: 0.5933 - val_accuracy: 0.7370 - val_loss: 0.6252\n",
      "Epoch 11/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.5853 - val_accuracy: 0.7222 - val_loss: 0.6712\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.5853 - val_accuracy: 0.7222 - val_loss: 0.6712\n",
      "Epoch 12/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7608 - loss: 0.5793 - val_accuracy: 0.7533 - val_loss: 0.6099\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7608 - loss: 0.5793 - val_accuracy: 0.7533 - val_loss: 0.6099\n",
      "Epoch 13/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7656 - loss: 0.5661 - val_accuracy: 0.7585 - val_loss: 0.6110\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7656 - loss: 0.5661 - val_accuracy: 0.7585 - val_loss: 0.6110\n",
      "Epoch 14/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7685 - loss: 0.5591 - val_accuracy: 0.7488 - val_loss: 0.6131\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7685 - loss: 0.5591 - val_accuracy: 0.7488 - val_loss: 0.6131\n",
      "Epoch 15/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.5547 - val_accuracy: 0.7533 - val_loss: 0.6129\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.5547 - val_accuracy: 0.7533 - val_loss: 0.6129\n",
      "Epoch 16/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 0.5465 - val_accuracy: 0.7502 - val_loss: 0.6073\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 0.5465 - val_accuracy: 0.7502 - val_loss: 0.6073\n",
      "Epoch 17/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5342 - val_accuracy: 0.7564 - val_loss: 0.6045\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7791 - loss: 0.5342 - val_accuracy: 0.7564 - val_loss: 0.6045\n",
      "Epoch 18/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7782 - loss: 0.5294 - val_accuracy: 0.7571 - val_loss: 0.6017\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7782 - loss: 0.5294 - val_accuracy: 0.7571 - val_loss: 0.6017\n",
      "Epoch 19/50\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.5199 - val_accuracy: 0.7580 - val_loss: 0.6066\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m386/386\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.5199 - val_accuracy: 0.7580 - val_loss: 0.6066\n",
      "Epoch 19: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "âœ… Train Acc: 0.7849 | Val Acc: 0.7580\n",
      "   Train Loss: 0.5199 | Val Loss: 0.6066\n",
      "   Epochs: 19/50 | Time: 33.8s\n",
      "âœ… Train Acc: 0.7849 | Val Acc: 0.7580\n",
      "   Train Loss: 0.5199 | Val Loss: 0.6066\n",
      "   Epochs: 19/50 | Time: 33.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>â–â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/learning_rate</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>epoch/loss</td><td>â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–</td></tr><tr><td>epoch/val_accuracy</td><td>â–â–â–ƒâ–„â–â–„â–†â–†â–…â–„â–‚â–‡â–ˆâ–†â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/val_loss</td><td>â–ˆâ–‡â–†â–…â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–†â–‚â–‚â–‚â–‚â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>19</td></tr><tr><td>best_val_acc</td><td>0.75802</td></tr><tr><td>epoch/accuracy</td><td>0.78489</td></tr><tr><td>epoch/epoch</td><td>18</td></tr><tr><td>epoch/learning_rate</td><td>0.001</td></tr><tr><td>epoch/loss</td><td>0.51993</td></tr><tr><td>epoch/val_accuracy</td><td>0.75802</td></tr><tr><td>epoch/val_loss</td><td>0.60662</td></tr><tr><td>final_train_acc</td><td>0.78489</td></tr><tr><td>final_train_loss</td><td>0.51993</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RNN-BiGRU-sgd-seed42-c701e39c</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/2vti964l' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN/runs/2vti964l</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/Assignment4-RNN</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>progress/RNN-BiGRU-sgd-seed42-c701e39c/wandb/run-20251204_051248-2vti964l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HYPERPARAMETER TUNING COMPLETE!\n",
      "\n",
      "ğŸ† BEST CONFIGURATION (Val Acc: 0.7679):\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Results saved with 216 configurations tested\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# HYPERPARAMETER SEARCH - PART 1: LSTM\n",
    "# 3 optimizers Ã— 3 activations Ã— 2 dropouts Ã— 3 units = 54 configs\n",
    "# Estimated time: ~20-30 minutes\n",
    "# ====================================================================\n",
    "import uuid\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ” PART 1/4: LSTM HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define hyperparameter grid for LSTM\n",
    "rnn_types = ['LSTM']                             # Only LSTM\n",
    "optimizers = ['adam', 'adamw', 'sgd']            # All optimizers\n",
    "activations = ['relu', 'tanh', 'selu']           # All activations from course\n",
    "dropouts = [0.2, 0.3333]                         # Two dropout rates\n",
    "batch_norms = [True]                             # Always use batch normalization\n",
    "rnn_units_list = [64, 128, 256]                  # Test different unit sizes\n",
    "learning_rates = [1e-3]                          # Standard learning rate\n",
    "momentums = [0.95]                               # Momentum for SGD only (not Adam/AdamW)\n",
    "\n",
    "# Training configuration\n",
    "TUNING_EPOCHS = 50  # Epochs per config (with early stopping if no improvement)\n",
    "EARLY_STOP_PATIENCE = 6  # Stop if val_loss doesn't improve for 6 epochs\n",
    "\n",
    "# Results storage for LSTM\n",
    "results_lstm = []\n",
    "best_val_acc_lstm = 0\n",
    "best_config_lstm = None\n",
    "\n",
    "total_configs = len(rnn_types) * len(optimizers) * len(activations) * len(dropouts) * len(batch_norms) * len(rnn_units_list) * len(learning_rates) * len(momentums)\n",
    "print(f\"\\nğŸ“Š Testing {total_configs} LSTM configurations...\")\n",
    "print(f\"â±ï¸  Estimated time: ~{total_configs * 2} minutes (assuming ~2 min per config)\\n\")\n",
    "print(f\"â° Note: Each config runs max {TUNING_EPOCHS} epochs with early stopping (patience={EARLY_STOP_PATIENCE})\\n\")\n",
    "\n",
    "config_num = 0\n",
    "\n",
    "for rnn_type in rnn_types:\n",
    "    for optimizer in optimizers:\n",
    "        for activation in activations:\n",
    "            for dropout in dropouts:\n",
    "                for batch_norm in batch_norms:\n",
    "                    for rnn_units in rnn_units_list:\n",
    "                        for lr in learning_rates:\n",
    "                            for momentum in momentums:\n",
    "                                config_num += 1\n",
    "                                \n",
    "                                print(f\"\\n{'='*70}\")\n",
    "                                print(f\"ğŸ”„ Progress: {config_num}/{total_configs} configurations\")\n",
    "                                print(f\"Config: {rnn_type} | {optimizer} | lr={lr} | mom={momentum} | {activation} | dropout={dropout} | units={rnn_units}\")\n",
    "                                print(f\"{'='*70}\")\n",
    "                                \n",
    "                                # Generate unique run ID\n",
    "                                RUN_ID = uuid.uuid4().hex[:8]\n",
    "                                RUN_NAME = f\"RNN-CHUNKED-{rnn_type}-{optimizer}-seed{SEED}-{RUN_ID}\"\n",
    "                                BASE_DIR = os.path.join(\"progress\", RUN_NAME)\n",
    "                                os.makedirs(BASE_DIR, exist_ok=True)\n",
    "                                \n",
    "                                # Initialize W&B run\n",
    "                                run = wandb.init(\n",
    "                                    project=WANDB_PROJECT,\n",
    "                                    entity=WANDB_ENTITY,\n",
    "                                    name=RUN_NAME,\n",
    "                                    dir=BASE_DIR,\n",
    "                                    config={\n",
    "                                        \"architecture\": \"TITLE_CHUNKS\",\n",
    "                                        \"input_shape\": f\"({MAX_CHUNKS_TOTAL}, {EMBED_DIM})\",\n",
    "                                        \"rnn_type\": rnn_type,\n",
    "                                        \"optimizer\": optimizer,\n",
    "                                        \"learning_rate\": lr,\n",
    "                                        \"momentum\": momentum if optimizer == 'sgd' else None,\n",
    "                                        \"activation\": activation,\n",
    "                                        \"dropout\": dropout,\n",
    "                                        \"batch_norm\": batch_norm,\n",
    "                                        \"rnn_units\": rnn_units,\n",
    "                                        \"max_epochs\": TUNING_EPOCHS,\n",
    "                                        \"early_stop_patience\": EARLY_STOP_PATIENCE,\n",
    "                                        \"early_stop_monitor\": \"val_loss\",\n",
    "                                        \"batch_size\": BATCH,\n",
    "                                        \"seed\": SEED,\n",
    "                                        \"run_id\": RUN_ID,\n",
    "                                        \"config_number\": config_num,\n",
    "                                        \"total_configs\": total_configs,\n",
    "                                        \"class_weights\": \"balanced\",\n",
    "                                    },\n",
    "                                )\n",
    "                                \n",
    "                                # Build model\n",
    "                                model = build_rnn_model(\n",
    "                                    rnn_type=rnn_type,\n",
    "                                    rnn_units=rnn_units,\n",
    "                                    activation=activation,\n",
    "                                    dropout=dropout,\n",
    "                                    use_batch_norm=batch_norm\n",
    "                                )\n",
    "                                \n",
    "                                # Compile model with specific learning rate and momentum\n",
    "                                if optimizer == 'adam':\n",
    "                                    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "                                elif optimizer == 'adamw':\n",
    "                                    opt = tf.keras.optimizers.AdamW(learning_rate=lr)\n",
    "                                elif optimizer == 'sgd':\n",
    "                                    opt = tf.keras.optimizers.SGD(learning_rate=lr, momentum=momentum)\n",
    "                                else:\n",
    "                                    opt = optimizer  # Fallback\n",
    "                                \n",
    "                                model.compile(\n",
    "                                    optimizer=opt,\n",
    "                                    loss='sparse_categorical_crossentropy',\n",
    "                                    metrics=['accuracy']\n",
    "                                )\n",
    "                                \n",
    "                                # Early stopping callback - MONITORS val_loss (mode='min')\n",
    "                                early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor='val_loss',\n",
    "                                    patience=EARLY_STOP_PATIENCE,\n",
    "                                    mode='min',\n",
    "                                    restore_best_weights=True,\n",
    "                                    verbose=1\n",
    "                                )\n",
    "                                \n",
    "                                # W&B callbacks\n",
    "                                wandb_callback = WandbMetricsLogger(log_freq=\"epoch\")\n",
    "                                best_metrics_cb = BestMetricsCallback()\n",
    "                                \n",
    "                                # Train model with class weights\n",
    "                                start_time = time.time()\n",
    "                                history = model.fit(\n",
    "                                    train_ds_chunked,\n",
    "                                    validation_data=val_ds_chunked,\n",
    "                                    epochs=TUNING_EPOCHS,\n",
    "                                    class_weight=class_weights,\n",
    "                                    callbacks=[early_stop, wandb_callback, best_metrics_cb],\n",
    "                                    verbose=1\n",
    "                                )\n",
    "                                train_time = time.time() - start_time\n",
    "                                \n",
    "                                # Get final metrics\n",
    "                                train_acc = history.history['accuracy'][-1]\n",
    "                                val_acc = history.history['val_accuracy'][-1]\n",
    "                                train_loss = history.history['loss'][-1]\n",
    "                                val_loss = history.history['val_loss'][-1]\n",
    "                                epochs_trained = len(history.history['accuracy'])\n",
    "                                \n",
    "                                # Get predictions for confusion matrix\n",
    "                                y_val_pred = model.predict(val_ds_chunked, verbose=0)\n",
    "                                y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n",
    "                                \n",
    "                                # Confusion matrix\n",
    "                                cm = confusion_matrix(y_val_indexed, y_val_pred_labels)\n",
    "                                \n",
    "                                # Store results\n",
    "                                results_lstm.append({\n",
    "                                    'rnn_type': rnn_type,\n",
    "                                    'optimizer': optimizer,\n",
    "                                    'learning_rate': lr,\n",
    "                                    'momentum': momentum if optimizer == 'sgd' else None,\n",
    "                                    'activation': activation,\n",
    "                                    'dropout': dropout,\n",
    "                                    'batch_norm': batch_norm,\n",
    "                                    'rnn_units': rnn_units,\n",
    "                                    'train_acc': train_acc,\n",
    "                                    'val_acc': val_acc,\n",
    "                                    'train_loss': train_loss,\n",
    "                                    'val_loss': val_loss,\n",
    "                                    'epochs': epochs_trained,\n",
    "                                    'time_sec': train_time,\n",
    "                                    'confusion_matrix': cm\n",
    "                                })\n",
    "                                \n",
    "                                # Print results\n",
    "                                print(f\"âœ… Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "                                print(f\"   Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "                                print(f\"   Epochs: {epochs_trained}/{TUNING_EPOCHS} | Time: {train_time:.1f}s\")\n",
    "                                \n",
    "                                # Track best model\n",
    "                                if val_acc > best_val_acc_lstm:\n",
    "                                    best_val_acc_lstm = val_acc\n",
    "                                    best_config_lstm = {\n",
    "                                        'rnn_type': rnn_type,\n",
    "                                        'optimizer': optimizer,\n",
    "                                        'learning_rate': lr,\n",
    "                                        'momentum': momentum if optimizer == 'sgd' else None,\n",
    "                                        'activation': activation,\n",
    "                                        'dropout': dropout,\n",
    "                                        'batch_norm': batch_norm,\n",
    "                                        'rnn_units': rnn_units\n",
    "                                    }\n",
    "                                    print(f\"   ğŸŒŸ NEW BEST MODEL! Val Acc: {val_acc:.4f}\")\n",
    "                                \n",
    "                                # Log final metrics to W&B\n",
    "                                wandb.run.summary[\"best_val_acc\"] = val_acc\n",
    "                                wandb.run.summary[\"best_epoch\"] = epochs_trained\n",
    "                                wandb.run.summary[\"final_train_acc\"] = train_acc\n",
    "                                wandb.run.summary[\"final_train_loss\"] = train_loss\n",
    "                                wandb.run.summary[\"final_val_loss\"] = val_loss\n",
    "                                wandb.run.summary[\"training_time_sec\"] = train_time\n",
    "                                \n",
    "                                # Finish W&B run\n",
    "                                wandb.finish()\n",
    "                                \n",
    "                                # Clear session to free memory\n",
    "                                tf.keras.backend.clear_session()\n",
    "                                \n",
    "                                # Aggressive memory cleanup to prevent crashes\n",
    "                                import gc\n",
    "                                gc.collect()\n",
    "                                \n",
    "                                # Also clear GPU memory if using GPU\n",
    "                                try:\n",
    "                                    import torch\n",
    "                                    if torch.cuda.is_available():\n",
    "                                        torch.cuda.empty_cache()\n",
    "                                except:\n",
    "                                    pass\n",
    "                                \n",
    "                                # Save progress every 10 configs\n",
    "                                if config_num % 10 == 0:\n",
    "                                    temp_df = pd.DataFrame(results_lstm)\n",
    "                                    temp_df.drop(columns=['confusion_matrix']).to_csv('rnn_chunked_LSTM_partial.csv', index=False)\n",
    "                                    print(f\"   ğŸ’¾ Progress saved ({config_num}/{total_configs})\")\n",
    "\n",
    "# Create results DataFrame for LSTM\n",
    "results_lstm_df = pd.DataFrame(results_lstm)\n",
    "\n",
    "# Save final results\n",
    "results_lstm_csv = results_lstm_df.drop(columns=['confusion_matrix'])\n",
    "results_lstm_csv.to_csv('rnn_chunked_LSTM_FULL.csv', index=False)\n",
    "\n",
    "print(\"\\nâœ… LSTM HYPERPARAMETER TUNING COMPLETE!\")\n",
    "print(f\"\\nğŸ† BEST LSTM CONFIGURATION (Val Acc: {best_val_acc_lstm:.4f}):\")\n",
    "for key, value in best_config_lstm.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“Š Results saved to 'rnn_chunked_LSTM_FULL.csv'\")\n",
    "print(f\"   Total LSTM configurations tested: {len(results_lstm)}\")\n",
    "print(f\"   Best validation accuracy: {results_lstm_csv['val_acc'].max():.4f}\")\n",
    "print(f\"   Mean validation accuracy: {results_lstm_csv['val_acc'].mean():.4f}\")\n",
    "print(f\"   Std validation accuracy: {results_lstm_csv['val_acc'].std():.4f}\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af02a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# HYPERPARAMETER SEARCH - PART 2: GRU\n",
    "# 3 optimizers Ã— 3 activations Ã— 2 dropouts Ã— 3 units = 54 configs\n",
    "# Estimated time: ~20-30 minutes\n",
    "# ====================================================================\n",
    "import uuid\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ” PART 2/4: GRU HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define hyperparameter grid for GRU\n",
    "rnn_types = ['GRU']                              # Only GRU\n",
    "optimizers = ['adam', 'adamw', 'sgd']            # All optimizers\n",
    "activations = ['relu', 'tanh', 'selu']           # All activations from course\n",
    "dropouts = [0.2, 0.3333]                         # Two dropout rates\n",
    "batch_norms = [True]                             # Always use batch normalization\n",
    "rnn_units_list = [64, 128, 256]                  # Test different unit sizes\n",
    "learning_rates = [1e-3]                          # Standard learning rate\n",
    "momentums = [0.95]                               # Momentum for SGD only (not Adam/AdamW)\n",
    "\n",
    "# Training configuration\n",
    "TUNING_EPOCHS = 50  # Epochs per config (with early stopping if no improvement)\n",
    "EARLY_STOP_PATIENCE = 6  # Stop if val_loss doesn't improve for 6 epochs\n",
    "\n",
    "# Results storage for GRU\n",
    "results_gru = []\n",
    "best_val_acc_gru = 0\n",
    "best_config_gru = None\n",
    "\n",
    "total_configs = len(rnn_types) * len(optimizers) * len(activations) * len(dropouts) * len(batch_norms) * len(rnn_units_list) * len(learning_rates) * len(momentums)\n",
    "print(f\"\\nğŸ“Š Testing {total_configs} GRU configurations...\")\n",
    "print(f\"â±ï¸  Estimated time: ~{total_configs * 2} minutes (assuming ~2 min per config)\\n\")\n",
    "print(f\"â° Note: Each config runs max {TUNING_EPOCHS} epochs with early stopping (patience={EARLY_STOP_PATIENCE})\\n\")\n",
    "\n",
    "config_num = 0\n",
    "\n",
    "for rnn_type in rnn_types:\n",
    "    for optimizer in optimizers:\n",
    "        for activation in activations:\n",
    "            for dropout in dropouts:\n",
    "                for batch_norm in batch_norms:\n",
    "                    for rnn_units in rnn_units_list:\n",
    "                        for lr in learning_rates:\n",
    "                            for momentum in momentums:\n",
    "                                config_num += 1\n",
    "                                \n",
    "                                print(f\"\\n{'='*70}\")\n",
    "                                print(f\"ğŸ”„ Progress: {config_num}/{total_configs} configurations\")\n",
    "                                print(f\"Config: {rnn_type} | {optimizer} | lr={lr} | mom={momentum} | {activation} | dropout={dropout} | units={rnn_units}\")\n",
    "                                print(f\"{'='*70}\")\n",
    "                                \n",
    "                                # Generate unique run ID\n",
    "                                RUN_ID = uuid.uuid4().hex[:8]\n",
    "                                RUN_NAME = f\"RNN-CHUNKED-{rnn_type}-{optimizer}-seed{SEED}-{RUN_ID}\"\n",
    "                                BASE_DIR = os.path.join(\"progress\", RUN_NAME)\n",
    "                                os.makedirs(BASE_DIR, exist_ok=True)\n",
    "                                \n",
    "                                # Initialize W&B run\n",
    "                                run = wandb.init(\n",
    "                                    project=WANDB_PROJECT,\n",
    "                                    entity=WANDB_ENTITY,\n",
    "                                    name=RUN_NAME,\n",
    "                                    dir=BASE_DIR,\n",
    "                                    config={\n",
    "                                        \"architecture\": \"TITLE_CHUNKS\",\n",
    "                                        \"input_shape\": f\"({MAX_CHUNKS_TOTAL}, {EMBED_DIM})\",\n",
    "                                        \"rnn_type\": rnn_type,\n",
    "                                        \"optimizer\": optimizer,\n",
    "                                        \"learning_rate\": lr,\n",
    "                                        \"momentum\": momentum if optimizer == 'sgd' else None,\n",
    "                                        \"activation\": activation,\n",
    "                                        \"dropout\": dropout,\n",
    "                                        \"batch_norm\": batch_norm,\n",
    "                                        \"rnn_units\": rnn_units,\n",
    "                                        \"max_epochs\": TUNING_EPOCHS,\n",
    "                                        \"early_stop_patience\": EARLY_STOP_PATIENCE,\n",
    "                                        \"early_stop_monitor\": \"val_loss\",\n",
    "                                        \"batch_size\": BATCH,\n",
    "                                        \"seed\": SEED,\n",
    "                                        \"run_id\": RUN_ID,\n",
    "                                        \"config_number\": config_num,\n",
    "                                        \"total_configs\": total_configs,\n",
    "                                        \"class_weights\": \"balanced\",\n",
    "                                    },\n",
    "                                )\n",
    "                                \n",
    "                                # Build model\n",
    "                                model = build_rnn_model(\n",
    "                                    rnn_type=rnn_type,\n",
    "                                    rnn_units=rnn_units,\n",
    "                                    activation=activation,\n",
    "                                    dropout=dropout,\n",
    "                                    use_batch_norm=batch_norm\n",
    "                                )\n",
    "                                \n",
    "                                # Compile model with specific learning rate and momentum\n",
    "                                if optimizer == 'adam':\n",
    "                                    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "                                elif optimizer == 'adamw':\n",
    "                                    opt = tf.keras.optimizers.AdamW(learning_rate=lr)\n",
    "                                elif optimizer == 'sgd':\n",
    "                                    opt = tf.keras.optimizers.SGD(learning_rate=lr, momentum=momentum)\n",
    "                                else:\n",
    "                                    opt = optimizer  # Fallback\n",
    "                                \n",
    "                                model.compile(\n",
    "                                    optimizer=opt,\n",
    "                                    loss='sparse_categorical_crossentropy',\n",
    "                                    metrics=['accuracy']\n",
    "                                )\n",
    "                                \n",
    "                                # Early stopping callback - MONITORS val_loss (mode='min')\n",
    "                                early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor='val_loss',\n",
    "                                    patience=EARLY_STOP_PATIENCE,\n",
    "                                    mode='min',\n",
    "                                    restore_best_weights=True,\n",
    "                                    verbose=1\n",
    "                                )\n",
    "                                \n",
    "                                # W&B callbacks\n",
    "                                wandb_callback = WandbMetricsLogger(log_freq=\"epoch\")\n",
    "                                best_metrics_cb = BestMetricsCallback()\n",
    "                                \n",
    "                                # Train model with class weights\n",
    "                                start_time = time.time()\n",
    "                                history = model.fit(\n",
    "                                    train_ds_chunked,\n",
    "                                    validation_data=val_ds_chunked,\n",
    "                                    epochs=TUNING_EPOCHS,\n",
    "                                    class_weight=class_weights,\n",
    "                                    callbacks=[early_stop, wandb_callback, best_metrics_cb],\n",
    "                                    verbose=1\n",
    "                                )\n",
    "                                train_time = time.time() - start_time\n",
    "                                \n",
    "                                # Get final metrics\n",
    "                                train_acc = history.history['accuracy'][-1]\n",
    "                                val_acc = history.history['val_accuracy'][-1]\n",
    "                                train_loss = history.history['loss'][-1]\n",
    "                                val_loss = history.history['val_loss'][-1]\n",
    "                                epochs_trained = len(history.history['accuracy'])\n",
    "                                \n",
    "                                # Get predictions for confusion matrix\n",
    "                                y_val_pred = model.predict(val_ds_chunked, verbose=0)\n",
    "                                y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n",
    "                                \n",
    "                                # Confusion matrix\n",
    "                                cm = confusion_matrix(y_val_indexed, y_val_pred_labels)\n",
    "                                \n",
    "                                # Store results\n",
    "                                results_gru.append({\n",
    "                                    'rnn_type': rnn_type,\n",
    "                                    'optimizer': optimizer,\n",
    "                                    'learning_rate': lr,\n",
    "                                    'momentum': momentum if optimizer == 'sgd' else None,\n",
    "                                    'activation': activation,\n",
    "                                    'dropout': dropout,\n",
    "                                    'batch_norm': batch_norm,\n",
    "                                    'rnn_units': rnn_units,\n",
    "                                    'train_acc': train_acc,\n",
    "                                    'val_acc': val_acc,\n",
    "                                    'train_loss': train_loss,\n",
    "                                    'val_loss': val_loss,\n",
    "                                    'epochs': epochs_trained,\n",
    "                                    'time_sec': train_time,\n",
    "                                    'confusion_matrix': cm\n",
    "                                })\n",
    "                                \n",
    "                                # Print results\n",
    "                                print(f\"âœ… Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "                                print(f\"   Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "                                print(f\"   Epochs: {epochs_trained}/{TUNING_EPOCHS} | Time: {train_time:.1f}s\")\n",
    "                                \n",
    "                                # Track best model\n",
    "                                if val_acc > best_val_acc_gru:\n",
    "                                    best_val_acc_gru = val_acc\n",
    "                                    best_config_gru = {\n",
    "                                        'rnn_type': rnn_type,\n",
    "                                        'optimizer': optimizer,\n",
    "                                        'learning_rate': lr,\n",
    "                                        'momentum': momentum if optimizer == 'sgd' else None,\n",
    "                                        'activation': activation,\n",
    "                                        'dropout': dropout,\n",
    "                                        'batch_norm': batch_norm,\n",
    "                                        'rnn_units': rnn_units\n",
    "                                    }\n",
    "                                    print(f\"   ğŸŒŸ NEW BEST MODEL! Val Acc: {val_acc:.4f}\")\n",
    "                                \n",
    "                                # Log final metrics to W&B\n",
    "                                wandb.run.summary[\"best_val_acc\"] = val_acc\n",
    "                                wandb.run.summary[\"best_epoch\"] = epochs_trained\n",
    "                                wandb.run.summary[\"final_train_acc\"] = train_acc\n",
    "                                wandb.run.summary[\"final_train_loss\"] = train_loss\n",
    "                                wandb.run.summary[\"final_val_loss\"] = val_loss\n",
    "                                wandb.run.summary[\"training_time_sec\"] = train_time\n",
    "                                \n",
    "                                # Finish W&B run\n",
    "                                wandb.finish()\n",
    "                                \n",
    "                                # Clear session to free memory\n",
    "                                tf.keras.backend.clear_session()\n",
    "                                \n",
    "                                # Aggressive memory cleanup to prevent crashes\n",
    "                                import gc\n",
    "                                gc.collect()\n",
    "                                \n",
    "                                # Also clear GPU memory if using GPU\n",
    "                                try:\n",
    "                                    import torch\n",
    "                                    if torch.cuda.is_available():\n",
    "                                        torch.cuda.empty_cache()\n",
    "                                except:\n",
    "                                    pass\n",
    "                                \n",
    "                                # Save progress every 10 configs\n",
    "                                if config_num % 10 == 0:\n",
    "                                    temp_df = pd.DataFrame(results_gru)\n",
    "                                    temp_df.drop(columns=['confusion_matrix']).to_csv('rnn_chunked_GRU_partial.csv', index=False)\n",
    "                                    print(f\"   ğŸ’¾ Progress saved ({config_num}/{total_configs})\")\n",
    "\n",
    "# Create results DataFrame for GRU\n",
    "results_gru_df = pd.DataFrame(results_gru)\n",
    "\n",
    "# Save final results\n",
    "results_gru_csv = results_gru_df.drop(columns=['confusion_matrix'])\n",
    "results_gru_csv.to_csv('rnn_chunked_GRU_FULL.csv', index=False)\n",
    "\n",
    "print(\"\\nâœ… GRU HYPERPARAMETER TUNING COMPLETE!\")\n",
    "print(f\"\\nğŸ† BEST GRU CONFIGURATION (Val Acc: {best_val_acc_gru:.4f}):\")\n",
    "for key, value in best_config_gru.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“Š Results saved to 'rnn_chunked_GRU_FULL.csv'\")\n",
    "print(f\"   Total GRU configurations tested: {len(results_gru)}\")\n",
    "print(f\"   Best validation accuracy: {results_gru_csv['val_acc'].max():.4f}\")\n",
    "print(f\"   Mean validation accuracy: {results_gru_csv['val_acc'].mean():.4f}\")\n",
    "print(f\"   Std validation accuracy: {results_gru_csv['val_acc'].std():.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07049e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# HYPERPARAMETER SEARCH - PART 3: BiLSTM\n",
    "# 3 optimizers Ã— 3 activations Ã— 2 dropouts Ã— 3 units = 54 configs\n",
    "# Estimated time: ~20-30 minutes\n",
    "# ====================================================================\n",
    "import uuid\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ” PART 3/4: BiLSTM HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define hyperparameter grid for BiLSTM\n",
    "rnn_types = ['BiLSTM']                           # Only BiLSTM\n",
    "optimizers = ['adam', 'adamw', 'sgd']            # All optimizers\n",
    "activations = ['relu', 'tanh', 'selu']           # All activations from course\n",
    "dropouts = [0.2, 0.3333]                         # Two dropout rates\n",
    "batch_norms = [True]                             # Always use batch normalization\n",
    "rnn_units_list = [64, 128, 256]                  # Test different unit sizes\n",
    "learning_rates = [1e-3]                          # Standard learning rate\n",
    "momentums = [0.95]                               # Momentum for SGD only (not Adam/AdamW)\n",
    "\n",
    "# Training configuration\n",
    "TUNING_EPOCHS = 50  # Epochs per config (with early stopping if no improvement)\n",
    "EARLY_STOP_PATIENCE = 6  # Stop if val_loss doesn't improve for 6 epochs\n",
    "\n",
    "# Results storage for BiLSTM\n",
    "results_bilstm = []\n",
    "best_val_acc_bilstm = 0\n",
    "best_config_bilstm = None\n",
    "\n",
    "total_configs = len(rnn_types) * len(optimizers) * len(activations) * len(dropouts) * len(batch_norms) * len(rnn_units_list) * len(learning_rates) * len(momentums)\n",
    "print(f\"\\nğŸ“Š Testing {total_configs} BiLSTM configurations...\")\n",
    "print(f\"â±ï¸  Estimated time: ~{total_configs * 2} minutes (assuming ~2 min per config)\\n\")\n",
    "print(f\"â° Note: Each config runs max {TUNING_EPOCHS} epochs with early stopping (patience={EARLY_STOP_PATIENCE})\\n\")\n",
    "\n",
    "config_num = 0\n",
    "\n",
    "for rnn_type in rnn_types:\n",
    "    for optimizer in optimizers:\n",
    "        for activation in activations:\n",
    "            for dropout in dropouts:\n",
    "                for batch_norm in batch_norms:\n",
    "                    for rnn_units in rnn_units_list:\n",
    "                        for lr in learning_rates:\n",
    "                            for momentum in momentums:\n",
    "                                config_num += 1\n",
    "                                \n",
    "                                print(f\"\\n{'='*70}\")\n",
    "                                print(f\"ğŸ”„ Progress: {config_num}/{total_configs} configurations\")\n",
    "                                print(f\"Config: {rnn_type} | {optimizer} | lr={lr} | mom={momentum} | {activation} | dropout={dropout} | units={rnn_units}\")\n",
    "                                print(f\"{'='*70}\")\n",
    "                                \n",
    "                                # Generate unique run ID\n",
    "                                RUN_ID = uuid.uuid4().hex[:8]\n",
    "                                RUN_NAME = f\"RNN-CHUNKED-{rnn_type}-{optimizer}-seed{SEED}-{RUN_ID}\"\n",
    "                                BASE_DIR = os.path.join(\"progress\", RUN_NAME)\n",
    "                                os.makedirs(BASE_DIR, exist_ok=True)\n",
    "                                \n",
    "                                # Initialize W&B run\n",
    "                                run = wandb.init(\n",
    "                                    project=WANDB_PROJECT,\n",
    "                                    entity=WANDB_ENTITY,\n",
    "                                    name=RUN_NAME,\n",
    "                                    dir=BASE_DIR,\n",
    "                                    config={\n",
    "                                        \"architecture\": \"TITLE_CHUNKS\",\n",
    "                                        \"input_shape\": f\"({MAX_CHUNKS_TOTAL}, {EMBED_DIM})\",\n",
    "                                        \"rnn_type\": rnn_type,\n",
    "                                        \"optimizer\": optimizer,\n",
    "                                        \"learning_rate\": lr,\n",
    "                                        \"momentum\": momentum if optimizer == 'sgd' else None,\n",
    "                                        \"activation\": activation,\n",
    "                                        \"dropout\": dropout,\n",
    "                                        \"batch_norm\": batch_norm,\n",
    "                                        \"rnn_units\": rnn_units,\n",
    "                                        \"max_epochs\": TUNING_EPOCHS,\n",
    "                                        \"early_stop_patience\": EARLY_STOP_PATIENCE,\n",
    "                                        \"early_stop_monitor\": \"val_loss\",\n",
    "                                        \"batch_size\": BATCH,\n",
    "                                        \"seed\": SEED,\n",
    "                                        \"run_id\": RUN_ID,\n",
    "                                        \"config_number\": config_num,\n",
    "                                        \"total_configs\": total_configs,\n",
    "                                        \"class_weights\": \"balanced\",\n",
    "                                    },\n",
    "                                )\n",
    "                                \n",
    "                                # Build model\n",
    "                                model = build_rnn_model(\n",
    "                                    rnn_type=rnn_type,\n",
    "                                    rnn_units=rnn_units,\n",
    "                                    activation=activation,\n",
    "                                    dropout=dropout,\n",
    "                                    use_batch_norm=batch_norm\n",
    "                                )\n",
    "                                \n",
    "                                # Compile model with specific learning rate and momentum\n",
    "                                if optimizer == 'adam':\n",
    "                                    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "                                elif optimizer == 'adamw':\n",
    "                                    opt = tf.keras.optimizers.AdamW(learning_rate=lr)\n",
    "                                elif optimizer == 'sgd':\n",
    "                                    opt = tf.keras.optimizers.SGD(learning_rate=lr, momentum=momentum)\n",
    "                                else:\n",
    "                                    opt = optimizer  # Fallback\n",
    "                                \n",
    "                                model.compile(\n",
    "                                    optimizer=opt,\n",
    "                                    loss='sparse_categorical_crossentropy',\n",
    "                                    metrics=['accuracy']\n",
    "                                )\n",
    "                                \n",
    "                                # Early stopping callback - MONITORS val_loss (mode='min')\n",
    "                                early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor='val_loss',\n",
    "                                    patience=EARLY_STOP_PATIENCE,\n",
    "                                    mode='min',\n",
    "                                    restore_best_weights=True,\n",
    "                                    verbose=1\n",
    "                                )\n",
    "                                \n",
    "                                # W&B callbacks\n",
    "                                wandb_callback = WandbMetricsLogger(log_freq=\"epoch\")\n",
    "                                best_metrics_cb = BestMetricsCallback()\n",
    "                                \n",
    "                                # Train model with class weights\n",
    "                                start_time = time.time()\n",
    "                                history = model.fit(\n",
    "                                    train_ds_chunked,\n",
    "                                    validation_data=val_ds_chunked,\n",
    "                                    epochs=TUNING_EPOCHS,\n",
    "                                    class_weight=class_weights,\n",
    "                                    callbacks=[early_stop, wandb_callback, best_metrics_cb],\n",
    "                                    verbose=1\n",
    "                                )\n",
    "                                train_time = time.time() - start_time\n",
    "                                \n",
    "                                # Get final metrics\n",
    "                                train_acc = history.history['accuracy'][-1]\n",
    "                                val_acc = history.history['val_accuracy'][-1]\n",
    "                                train_loss = history.history['loss'][-1]\n",
    "                                val_loss = history.history['val_loss'][-1]\n",
    "                                epochs_trained = len(history.history['accuracy'])\n",
    "                                \n",
    "                                # Get predictions for confusion matrix\n",
    "                                y_val_pred = model.predict(val_ds_chunked, verbose=0)\n",
    "                                y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n",
    "                                \n",
    "                                # Confusion matrix\n",
    "                                cm = confusion_matrix(y_val_indexed, y_val_pred_labels)\n",
    "                                \n",
    "                                # Store results\n",
    "                                results_bilstm.append({\n",
    "                                    'rnn_type': rnn_type,\n",
    "                                    'optimizer': optimizer,\n",
    "                                    'learning_rate': lr,\n",
    "                                    'momentum': momentum if optimizer == 'sgd' else None,\n",
    "                                    'activation': activation,\n",
    "                                    'dropout': dropout,\n",
    "                                    'batch_norm': batch_norm,\n",
    "                                    'rnn_units': rnn_units,\n",
    "                                    'train_acc': train_acc,\n",
    "                                    'val_acc': val_acc,\n",
    "                                    'train_loss': train_loss,\n",
    "                                    'val_loss': val_loss,\n",
    "                                    'epochs': epochs_trained,\n",
    "                                    'time_sec': train_time,\n",
    "                                    'confusion_matrix': cm\n",
    "                                })\n",
    "                                \n",
    "                                # Print results\n",
    "                                print(f\"âœ… Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "                                print(f\"   Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "                                print(f\"   Epochs: {epochs_trained}/{TUNING_EPOCHS} | Time: {train_time:.1f}s\")\n",
    "                                \n",
    "                                # Track best model\n",
    "                                if val_acc > best_val_acc_bilstm:\n",
    "                                    best_val_acc_bilstm = val_acc\n",
    "                                    best_config_bilstm = {\n",
    "                                        'rnn_type': rnn_type,\n",
    "                                        'optimizer': optimizer,\n",
    "                                        'learning_rate': lr,\n",
    "                                        'momentum': momentum if optimizer == 'sgd' else None,\n",
    "                                        'activation': activation,\n",
    "                                        'dropout': dropout,\n",
    "                                        'batch_norm': batch_norm,\n",
    "                                        'rnn_units': rnn_units\n",
    "                                    }\n",
    "                                    print(f\"   ğŸŒŸ NEW BEST MODEL! Val Acc: {val_acc:.4f}\")\n",
    "                                \n",
    "                                # Log final metrics to W&B\n",
    "                                wandb.run.summary[\"best_val_acc\"] = val_acc\n",
    "                                wandb.run.summary[\"best_epoch\"] = epochs_trained\n",
    "                                wandb.run.summary[\"final_train_acc\"] = train_acc\n",
    "                                wandb.run.summary[\"final_train_loss\"] = train_loss\n",
    "                                wandb.run.summary[\"final_val_loss\"] = val_loss\n",
    "                                wandb.run.summary[\"training_time_sec\"] = train_time\n",
    "                                \n",
    "                                # Finish W&B run\n",
    "                                wandb.finish()\n",
    "                                \n",
    "                                # Clear session to free memory\n",
    "                                tf.keras.backend.clear_session()\n",
    "                                \n",
    "                                # Aggressive memory cleanup to prevent crashes\n",
    "                                import gc\n",
    "                                gc.collect()\n",
    "                                \n",
    "                                # Also clear GPU memory if using GPU\n",
    "                                try:\n",
    "                                    import torch\n",
    "                                    if torch.cuda.is_available():\n",
    "                                        torch.cuda.empty_cache()\n",
    "                                except:\n",
    "                                    pass\n",
    "                                \n",
    "                                # Save progress every 10 configs\n",
    "                                if config_num % 10 == 0:\n",
    "                                    temp_df = pd.DataFrame(results_bilstm)\n",
    "                                    temp_df.drop(columns=['confusion_matrix']).to_csv('rnn_chunked_BiLSTM_partial.csv', index=False)\n",
    "                                    print(f\"   ğŸ’¾ Progress saved ({config_num}/{total_configs})\")\n",
    "\n",
    "# Create results DataFrame for BiLSTM\n",
    "results_bilstm_df = pd.DataFrame(results_bilstm)\n",
    "\n",
    "# Save final results\n",
    "results_bilstm_csv = results_bilstm_df.drop(columns=['confusion_matrix'])\n",
    "results_bilstm_csv.to_csv('rnn_chunked_BiLSTM_FULL.csv', index=False)\n",
    "\n",
    "print(\"\\nâœ… BiLSTM HYPERPARAMETER TUNING COMPLETE!\")\n",
    "print(f\"\\nğŸ† BEST BiLSTM CONFIGURATION (Val Acc: {best_val_acc_bilstm:.4f}):\")\n",
    "for key, value in best_config_bilstm.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“Š Results saved to 'rnn_chunked_BiLSTM_FULL.csv'\")\n",
    "print(f\"   Total BiLSTM configurations tested: {len(results_bilstm)}\")\n",
    "print(f\"   Best validation accuracy: {results_bilstm_csv['val_acc'].max():.4f}\")\n",
    "print(f\"   Mean validation accuracy: {results_bilstm_csv['val_acc'].mean():.4f}\")\n",
    "print(f\"   Std validation accuracy: {results_bilstm_csv['val_acc'].std():.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88148c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# HYPERPARAMETER SEARCH - PART 4: BiGRU\n",
    "# 3 optimizers Ã— 3 activations Ã— 2 dropouts Ã— 3 units = 54 configs\n",
    "# Estimated time: ~20-30 minutes\n",
    "# ====================================================================\n",
    "import uuid\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ” PART 4/4: BiGRU HYPERPARAMETER TUNING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define hyperparameter grid for BiGRU\n",
    "rnn_types = ['BiGRU']                            # Only BiGRU\n",
    "optimizers = ['adam', 'adamw', 'sgd']            # All optimizers\n",
    "activations = ['relu', 'tanh', 'selu']           # All activations from course\n",
    "dropouts = [0.2, 0.3333]                         # Two dropout rates\n",
    "batch_norms = [True]                             # Always use batch normalization\n",
    "rnn_units_list = [64, 128, 256]                  # Test different unit sizes\n",
    "learning_rates = [1e-3]                          # Standard learning rate\n",
    "momentums = [0.95]                               # Momentum for SGD only (not Adam/AdamW)\n",
    "\n",
    "# Training configuration\n",
    "TUNING_EPOCHS = 50  # Epochs per config (with early stopping if no improvement)\n",
    "EARLY_STOP_PATIENCE = 6  # Stop if val_loss doesn't improve for 6 epochs\n",
    "\n",
    "# Results storage for BiGRU\n",
    "results_bigru = []\n",
    "best_val_acc_bigru = 0\n",
    "best_config_bigru = None\n",
    "\n",
    "total_configs = len(rnn_types) * len(optimizers) * len(activations) * len(dropouts) * len(batch_norms) * len(rnn_units_list) * len(learning_rates) * len(momentums)\n",
    "print(f\"\\nğŸ“Š Testing {total_configs} BiGRU configurations...\")\n",
    "print(f\"â±ï¸  Estimated time: ~{total_configs * 2} minutes (assuming ~2 min per config)\\n\")\n",
    "print(f\"â° Note: Each config runs max {TUNING_EPOCHS} epochs with early stopping (patience={EARLY_STOP_PATIENCE})\\n\")\n",
    "\n",
    "config_num = 0\n",
    "\n",
    "for rnn_type in rnn_types:\n",
    "    for optimizer in optimizers:\n",
    "        for activation in activations:\n",
    "            for dropout in dropouts:\n",
    "                for batch_norm in batch_norms:\n",
    "                    for rnn_units in rnn_units_list:\n",
    "                        for lr in learning_rates:\n",
    "                            for momentum in momentums:\n",
    "                                config_num += 1\n",
    "                                \n",
    "                                print(f\"\\n{'='*70}\")\n",
    "                                print(f\"ğŸ”„ Progress: {config_num}/{total_configs} configurations\")\n",
    "                                print(f\"Config: {rnn_type} | {optimizer} | lr={lr} | mom={momentum} | {activation} | dropout={dropout} | units={rnn_units}\")\n",
    "                                print(f\"{'='*70}\")\n",
    "                                \n",
    "                                # Generate unique run ID\n",
    "                                RUN_ID = uuid.uuid4().hex[:8]\n",
    "                                RUN_NAME = f\"RNN-CHUNKED-{rnn_type}-{optimizer}-seed{SEED}-{RUN_ID}\"\n",
    "                                BASE_DIR = os.path.join(\"progress\", RUN_NAME)\n",
    "                                os.makedirs(BASE_DIR, exist_ok=True)\n",
    "                                \n",
    "                                # Initialize W&B run\n",
    "                                run = wandb.init(\n",
    "                                    project=WANDB_PROJECT,\n",
    "                                    entity=WANDB_ENTITY,\n",
    "                                    name=RUN_NAME,\n",
    "                                    dir=BASE_DIR,\n",
    "                                    config={\n",
    "                                        \"architecture\": \"TITLE_CHUNKS\",\n",
    "                                        \"input_shape\": f\"({MAX_CHUNKS_TOTAL}, {EMBED_DIM})\",\n",
    "                                        \"rnn_type\": rnn_type,\n",
    "                                        \"optimizer\": optimizer,\n",
    "                                        \"learning_rate\": lr,\n",
    "                                        \"momentum\": momentum if optimizer == 'sgd' else None,\n",
    "                                        \"activation\": activation,\n",
    "                                        \"dropout\": dropout,\n",
    "                                        \"batch_norm\": batch_norm,\n",
    "                                        \"rnn_units\": rnn_units,\n",
    "                                        \"max_epochs\": TUNING_EPOCHS,\n",
    "                                        \"early_stop_patience\": EARLY_STOP_PATIENCE,\n",
    "                                        \"early_stop_monitor\": \"val_loss\",\n",
    "                                        \"batch_size\": BATCH,\n",
    "                                        \"seed\": SEED,\n",
    "                                        \"run_id\": RUN_ID,\n",
    "                                        \"config_number\": config_num,\n",
    "                                        \"total_configs\": total_configs,\n",
    "                                        \"class_weights\": \"balanced\",\n",
    "                                    },\n",
    "                                )\n",
    "                                \n",
    "                                # Build model\n",
    "                                model = build_rnn_model(\n",
    "                                    rnn_type=rnn_type,\n",
    "                                    rnn_units=rnn_units,\n",
    "                                    activation=activation,\n",
    "                                    dropout=dropout,\n",
    "                                    use_batch_norm=batch_norm\n",
    "                                )\n",
    "                                \n",
    "                                # Compile model with specific learning rate and momentum\n",
    "                                if optimizer == 'adam':\n",
    "                                    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "                                elif optimizer == 'adamw':\n",
    "                                    opt = tf.keras.optimizers.AdamW(learning_rate=lr)\n",
    "                                elif optimizer == 'sgd':\n",
    "                                    opt = tf.keras.optimizers.SGD(learning_rate=lr, momentum=momentum)\n",
    "                                else:\n",
    "                                    opt = optimizer  # Fallback\n",
    "                                \n",
    "                                model.compile(\n",
    "                                    optimizer=opt,\n",
    "                                    loss='sparse_categorical_crossentropy',\n",
    "                                    metrics=['accuracy']\n",
    "                                )\n",
    "                                \n",
    "                                # Early stopping callback - MONITORS val_loss (mode='min')\n",
    "                                early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor='val_loss',\n",
    "                                    patience=EARLY_STOP_PATIENCE,\n",
    "                                    mode='min',\n",
    "                                    restore_best_weights=True,\n",
    "                                    verbose=1\n",
    "                                )\n",
    "                                \n",
    "                                # W&B callbacks\n",
    "                                wandb_callback = WandbMetricsLogger(log_freq=\"epoch\")\n",
    "                                best_metrics_cb = BestMetricsCallback()\n",
    "                                \n",
    "                                # Train model with class weights\n",
    "                                start_time = time.time()\n",
    "                                history = model.fit(\n",
    "                                    train_ds_chunked,\n",
    "                                    validation_data=val_ds_chunked,\n",
    "                                    epochs=TUNING_EPOCHS,\n",
    "                                    class_weight=class_weights,\n",
    "                                    callbacks=[early_stop, wandb_callback, best_metrics_cb],\n",
    "                                    verbose=1\n",
    "                                )\n",
    "                                train_time = time.time() - start_time\n",
    "                                \n",
    "                                # Get final metrics\n",
    "                                train_acc = history.history['accuracy'][-1]\n",
    "                                val_acc = history.history['val_accuracy'][-1]\n",
    "                                train_loss = history.history['loss'][-1]\n",
    "                                val_loss = history.history['val_loss'][-1]\n",
    "                                epochs_trained = len(history.history['accuracy'])\n",
    "                                \n",
    "                                # Get predictions for confusion matrix\n",
    "                                y_val_pred = model.predict(val_ds_chunked, verbose=0)\n",
    "                                y_val_pred_labels = np.argmax(y_val_pred, axis=1)\n",
    "                                \n",
    "                                # Confusion matrix\n",
    "                                cm = confusion_matrix(y_val_indexed, y_val_pred_labels)\n",
    "                                \n",
    "                                # Store results\n",
    "                                results_bigru.append({\n",
    "                                    'rnn_type': rnn_type,\n",
    "                                    'optimizer': optimizer,\n",
    "                                    'learning_rate': lr,\n",
    "                                    'momentum': momentum if optimizer == 'sgd' else None,\n",
    "                                    'activation': activation,\n",
    "                                    'dropout': dropout,\n",
    "                                    'batch_norm': batch_norm,\n",
    "                                    'rnn_units': rnn_units,\n",
    "                                    'train_acc': train_acc,\n",
    "                                    'val_acc': val_acc,\n",
    "                                    'train_loss': train_loss,\n",
    "                                    'val_loss': val_loss,\n",
    "                                    'epochs': epochs_trained,\n",
    "                                    'time_sec': train_time,\n",
    "                                    'confusion_matrix': cm\n",
    "                                })\n",
    "                                \n",
    "                                # Print results\n",
    "                                print(f\"âœ… Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "                                print(f\"   Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "                                print(f\"   Epochs: {epochs_trained}/{TUNING_EPOCHS} | Time: {train_time:.1f}s\")\n",
    "                                \n",
    "                                # Track best model\n",
    "                                if val_acc > best_val_acc_bigru:\n",
    "                                    best_val_acc_bigru = val_acc\n",
    "                                    best_config_bigru = {\n",
    "                                        'rnn_type': rnn_type,\n",
    "                                        'optimizer': optimizer,\n",
    "                                        'learning_rate': lr,\n",
    "                                        'momentum': momentum if optimizer == 'sgd' else None,\n",
    "                                        'activation': activation,\n",
    "                                        'dropout': dropout,\n",
    "                                        'batch_norm': batch_norm,\n",
    "                                        'rnn_units': rnn_units\n",
    "                                    }\n",
    "                                    print(f\"   ğŸŒŸ NEW BEST MODEL! Val Acc: {val_acc:.4f}\")\n",
    "                                \n",
    "                                # Log final metrics to W&B\n",
    "                                wandb.run.summary[\"best_val_acc\"] = val_acc\n",
    "                                wandb.run.summary[\"best_epoch\"] = epochs_trained\n",
    "                                wandb.run.summary[\"final_train_acc\"] = train_acc\n",
    "                                wandb.run.summary[\"final_train_loss\"] = train_loss\n",
    "                                wandb.run.summary[\"final_val_loss\"] = val_loss\n",
    "                                wandb.run.summary[\"training_time_sec\"] = train_time\n",
    "                                \n",
    "                                # Finish W&B run\n",
    "                                wandb.finish()\n",
    "                                \n",
    "                                # Clear session to free memory\n",
    "                                tf.keras.backend.clear_session()\n",
    "                                \n",
    "                                # Aggressive memory cleanup to prevent crashes\n",
    "                                import gc\n",
    "                                gc.collect()\n",
    "                                \n",
    "                                # Also clear GPU memory if using GPU\n",
    "                                try:\n",
    "                                    import torch\n",
    "                                    if torch.cuda.is_available():\n",
    "                                        torch.cuda.empty_cache()\n",
    "                                except:\n",
    "                                    pass\n",
    "                                \n",
    "                                # Save progress every 10 configs\n",
    "                                if config_num % 10 == 0:\n",
    "                                    temp_df = pd.DataFrame(results_bigru)\n",
    "                                    temp_df.drop(columns=['confusion_matrix']).to_csv('rnn_chunked_BiGRU_partial.csv', index=False)\n",
    "                                    print(f\"   ğŸ’¾ Progress saved ({config_num}/{total_configs})\")\n",
    "\n",
    "# Create results DataFrame for BiGRU\n",
    "results_bigru_df = pd.DataFrame(results_bigru)\n",
    "\n",
    "# Save final results\n",
    "results_bigru_csv = results_bigru_df.drop(columns=['confusion_matrix'])\n",
    "results_bigru_csv.to_csv('rnn_chunked_BiGRU_FULL.csv', index=False)\n",
    "\n",
    "print(\"\\nâœ… BiGRU HYPERPARAMETER TUNING COMPLETE!\")\n",
    "print(f\"\\nğŸ† BEST BiGRU CONFIGURATION (Val Acc: {best_val_acc_bigru:.4f}):\")\n",
    "for key, value in best_config_bigru.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“Š Results saved to 'rnn_chunked_BiGRU_FULL.csv'\")\n",
    "print(f\"   Total BiGRU configurations tested: {len(results_bigru)}\")\n",
    "print(f\"   Best validation accuracy: {results_bigru_csv['val_acc'].max():.4f}\")\n",
    "print(f\"   Mean validation accuracy: {results_bigru_csv['val_acc'].mean():.4f}\")\n",
    "print(f\"   Std validation accuracy: {results_bigru_csv['val_acc'].std():.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610c441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# COMBINE ALL RESULTS FROM ALL 4 RNN TYPES\n",
    "# ====================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š COMBINING RESULTS FROM ALL RNN TYPES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Combine all results into one DataFrame\n",
    "all_results = []\n",
    "\n",
    "# Add LSTM results if exists\n",
    "if 'results_lstm' in globals() and len(results_lstm) > 0:\n",
    "    all_results.extend(results_lstm)\n",
    "    print(f\"âœ… Added {len(results_lstm)} LSTM results\")\n",
    "\n",
    "# Add GRU results if exists\n",
    "if 'results_gru' in globals() and len(results_gru) > 0:\n",
    "    all_results.extend(results_gru)\n",
    "    print(f\"âœ… Added {len(results_gru)} GRU results\")\n",
    "\n",
    "# Add BiLSTM results if exists\n",
    "if 'results_bilstm' in globals() and len(results_bilstm) > 0:\n",
    "    all_results.extend(results_bilstm)\n",
    "    print(f\"âœ… Added {len(results_bilstm)} BiLSTM results\")\n",
    "\n",
    "# Add BiGRU results if exists\n",
    "if 'results_bigru' in globals() and len(results_bigru) > 0:\n",
    "    all_results.extend(results_bigru)\n",
    "    print(f\"âœ… Added {len(results_bigru)} BiGRU results\")\n",
    "\n",
    "# Create combined DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# Save combined results\n",
    "results_csv = results_df.drop(columns=['confusion_matrix'])\n",
    "results_csv.to_csv('rnn_chunked_hyperparameter_results_ALL.csv', index=False)\n",
    "\n",
    "print(f\"\\nğŸ“Š Combined Results Summary:\")\n",
    "print(f\"   Total configurations: {len(results_df)}\")\n",
    "print(f\"   Best validation accuracy: {results_csv['val_acc'].max():.4f}\")\n",
    "print(f\"   Mean validation accuracy: {results_csv['val_acc'].mean():.4f}\")\n",
    "print(f\"   Std validation accuracy: {results_csv['val_acc'].std():.4f}\")\n",
    "\n",
    "# Find overall best configuration\n",
    "best_idx = results_df['val_acc'].idxmax()\n",
    "best_result = results_df.iloc[best_idx]\n",
    "best_config = {\n",
    "    'rnn_type': best_result['rnn_type'],\n",
    "    'optimizer': best_result['optimizer'],\n",
    "    'learning_rate': best_result['learning_rate'],\n",
    "    'momentum': best_result['momentum'],\n",
    "    'activation': best_result['activation'],\n",
    "    'dropout': best_result['dropout'],\n",
    "    'batch_norm': best_result['batch_norm'],\n",
    "    'rnn_units': best_result['rnn_units']\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ† OVERALL BEST CONFIGURATION (Val Acc: {best_result['val_acc']:.4f}):\")\n",
    "for key, value in best_config.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ Results by RNN Type:\")\n",
    "rnn_summary = results_csv.groupby('rnn_type')['val_acc'].agg(['count', 'mean', 'std', 'max']).sort_values('max', ascending=False)\n",
    "print(rnn_summary)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"âœ… All results saved to 'rnn_chunked_hyperparameter_results_ALL.csv'\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155dbdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“ˆ TOP 10 CONFIGURATIONS BY VALIDATION ACCURACY\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'results_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mğŸ“ˆ TOP 10 CONFIGURATIONS BY VALIDATION ACCURACY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m top_10 = \u001b[43mresults_df\u001b[49m.nlargest(\u001b[32m10\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m'\u001b[39m)[[\u001b[33m'\u001b[39m\u001b[33mrnn_type\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33moptimizer\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmomentum\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mactivation\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      7\u001b[39m                                                \u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrnn_units\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m                                                \u001b[33m'\u001b[39m\u001b[33mval_acc\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtrain_acc\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(top_10.to_string(index=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'results_df' is not defined"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# ANALYZE RESULTS - Top 10 Configurations\n",
    "# NOTE: Run the \"COMBINE ALL RESULTS\" cell first!\n",
    "# ====================================================================\n",
    "\n",
    "if 'results_df' not in globals():\n",
    "    print(\"âš ï¸  ERROR: results_df not found!\")\n",
    "    print(\"   Please run the 'COMBINE ALL RESULTS' cell first.\")\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(\"ğŸ“ˆ TOP 10 CONFIGURATIONS BY VALIDATION ACCURACY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    top_10 = results_df.nlargest(10, 'val_acc')[['rnn_type', 'optimizer', 'learning_rate', 'momentum', 'activation', \n",
    "                                                   'dropout', 'rnn_units',\n",
    "                                                   'val_acc', 'train_acc', 'epochs']]\n",
    "    print(top_10.to_string(index=False))\n",
    "    \n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)    print(bottom_10.to_string(index=False))\n",
    "\n",
    "    print(\"ğŸ“‰ BOTTOM 10 CONFIGURATIONS BY VALIDATION ACCURACY\")                                                       'val_acc', 'train_acc', 'epochs']]\n",
    "\n",
    "    print(\"=\"*70)                                                       'dropout', 'rnn_units',\n",
    "\n",
    "        bottom_10 = results_df.nsmallest(10, 'val_acc')[['rnn_type', 'optimizer', 'learning_rate', 'momentum', 'activation', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# VISUALIZE BEST MODEL'S CONFUSION MATRIX\n",
    "# NOTE: Run the \"COMBINE ALL RESULTS\" cell first!\n",
    "# ====================================================================\n",
    "\n",
    "if 'results_df' not in globals():\n",
    "    print(\"âš ï¸  ERROR: results_df not found!\")\n",
    "    print(\"   Please run the 'COMBINE ALL RESULTS' cell first.\")\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(\"ğŸ¯ CONFUSION MATRIX - BEST MODEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    best_idx = results_df['val_acc'].idxmax()\n",
    "    best_result = results_df.iloc[best_idx]\n",
    "    best_cm = best_result['confusion_matrix']\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(best_cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(f'Confusion Matrix - Best Model\\n{best_result[\"rnn_type\"]} | Val Acc: {best_result[\"val_acc\"]:.4f}')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    classes = ['1 star', '2 stars', '3 stars', '4 stars', '5 stars']\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    # Add text annotations\n",
    "    thresh = best_cm.max() / 2.\n",
    "    for i in range(best_cm.shape[0]):\n",
    "        for j in range(best_cm.shape[1]):\n",
    "            plt.text(j, i, format(best_cm[i, j], 'd'),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if best_cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed metrics\n",
    "    print(f\"\\nğŸ“Š Best Configuration Details:\")\n",
    "    print(f\"   RNN Type: {best_result['rnn_type']}\")\n",
    "    print(f\"   Optimizer: {best_result['optimizer']}\")\n",
    "    print(f\"   Learning Rate: {best_result['learning_rate']}\")\n",
    "    print(f\"   Momentum: {best_result['momentum']}\")\n",
    "    print(f\"   Activation: {best_result['activation']}\")\n",
    "    print(f\"   Dropout: {best_result['dropout']}\")\n",
    "    print(f\"   RNN Units: {best_result['rnn_units']}\")\n",
    "    print(f\"   Val Accuracy: {best_result['val_acc']:.4f}\")\n",
    "    print(f\"   Train Accuracy: {best_result['train_acc']:.4f}\")\n",
    "    print(f\"   Training Time: {best_result['time_sec']:.1f}s\")\n",
    "\n",
    "print(f\"   Learning Rate: {best_result['learning_rate']}\")print(f\"   Training Time: {best_result['time_sec']:.1f}s\")\n",
    "\n",
    "print(f\"   Momentum: {best_result['momentum']}\")print(f\"   Train Accuracy: {best_result['train_acc']:.4f}\")\n",
    "\n",
    "print(f\"   Activation: {best_result['activation']}\")print(f\"   Val Accuracy: {best_result['val_acc']:.4f}\")\n",
    "\n",
    "print(f\"   Dropout: {best_result['dropout']}\")print(f\"   RNN Units: {best_result['rnn_units']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# HYPERPARAMETER IMPACT ANALYSIS\n",
    "# NOTE: Run the \"COMBINE ALL RESULTS\" cell first!\n",
    "# ====================================================================\n",
    "\n",
    "if 'results_df' not in globals():\n",
    "    print(\"âš ï¸  ERROR: results_df not found!\")\n",
    "    print(\"   Please run the 'COMBINE ALL RESULTS' cell first.\")\n",
    "else:\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nğŸ“Š Average Validation Accuracy by Optimizer:\")\n",
    "    opt_impact = results_df.groupby('optimizer')['val_acc'].agg(['mean', 'std', 'max']).sort_values('mean', ascending=False)\n",
    "    print(opt_impact)\n",
    "    \n",
    "    print(\"\\nğŸ“Š Average Validation Accuracy by Activation:\")\n",
    "    act_impact = results_df.groupby('activation')['val_acc'].agg(['mean', 'std', 'max']).sort_values('mean', ascending=False)\n",
    "    print(act_impact)\n",
    "    \n",
    "    print(\"\\nğŸ“Š Average Validation Accuracy by Dropout:\")\n",
    "    drop_impact = results_df.groupby('dropout')['val_acc'].agg(['mean', 'std', 'max']).sort_values('mean', ascending=False)\n",
    "    print(drop_impact)\n",
    "    \n",
    "    print(\"\\nğŸ“Š Average Validation Accuracy by Learning Rate:\")\n",
    "    lr_impact = results_df.groupby('learning_rate')['val_acc'].agg(['mean', 'std', 'max']).sort_values('mean', ascending=False)\n",
    "    print(lr_impact)\n",
    "    \n",
    "    print(\"\\nğŸ“Š Average Validation Accuracy by Momentum (SGD only):\")\n",
    "    sgd_results = results_df[results_df['optimizer'] == 'sgd']\n",
    "    if len(sgd_results) > 0:\n",
    "        momentum_impact = sgd_results.groupby('momentum')['val_acc'].agg(['mean', 'std', 'max']).sort_values('mean', ascending=False)\n",
    "        print(momentum_impact)\n",
    "    else:\n",
    "        print(\"   No SGD results available yet\")\n",
    "\n",
    "    \n",
    "print(units_impact)\n",
    "\n",
    "    print(\"\\nğŸ“Š Average Validation Accuracy by RNN Units:\")\n",
    "print(\"\\nğŸ“Š Average Validation Accuracy by Momentum (SGD & RMSprop only):\")units_impact = results_df.groupby('rnn_units')['val_acc'].agg(['mean', 'std', 'max']).sort_values('mean', ascending=False)\n",
    "\n",
    "    units_impact = results_df.groupby('rnn_units')['val_acc'].agg(['mean', 'std', 'max']).sort_values('mean', ascending=False)\n",
    "momentum_impact = results_df[results_df['optimizer'] != 'adam'].groupby('momentum')['val_acc'].agg(['mean', 'std', 'max']).sort_values('mean', ascending=False)print(\"\\nğŸ“Š Average Validation Accuracy by RNN Units:\")\n",
    "\n",
    "    print(units_impact)\n",
    "print(momentum_impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfe15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# SAVE COMBINED RESULTS TO CSV (LEGACY FORMAT)\n",
    "# NOTE: Run the \"COMBINE ALL RESULTS\" cell first!\n",
    "# This cell is optional - results are already saved in individual CSVs\n",
    "# ====================================================================\n",
    "\n",
    "if 'results_df' not in globals():\n",
    "    print(\"âš ï¸  ERROR: results_df not found!\")\n",
    "    print(\"   Please run the 'COMBINE ALL RESULTS' cell first.\")\n",
    "else:\n",
    "\n",
    "    # Save hyperparameter tuning results to CSV (legacy filename)    print(\"   - rnn_chunked_hyperparameter_results_ALL.csv (combined)\")\n",
    "\n",
    "    results_csv = results_df.drop(columns=['confusion_matrix'])  # Drop confusion matrix for CSV export    print(\"   - rnn_chunked_BiGRU_FULL.csv\")\n",
    "\n",
    "    results_csv.to_csv('rnn_hyperparameter_results.csv', index=False)    print(\"   - rnn_chunked_BiLSTM_FULL.csv\")\n",
    "\n",
    "        print(\"   - rnn_chunked_GRU_FULL.csv\")\n",
    "\n",
    "    print(\"âœ… Results saved to 'rnn_hyperparameter_results.csv' (legacy format)\")    print(\"   - rnn_chunked_LSTM_FULL.csv\")\n",
    "\n",
    "    print(f\"   Total configurations tested: {len(results_csv)}\")    print(\"\\nğŸ’¡ Note: Individual RNN type results are already saved as:\")\n",
    "\n",
    "    print(f\"   Best validation accuracy: {results_csv['val_acc'].max():.4f}\")    print(f\"   Std validation accuracy: {results_csv['val_acc'].std():.4f}\")\n",
    "\n",
    "    print(f\"   Worst validation accuracy: {results_csv['val_acc'].min():.4f}\")    print(f\"   Mean validation accuracy: {results_csv['val_acc'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f801858",
   "metadata": {},
   "source": [
    "### 3.2 Train Final Model with Best Hyperparameters\n",
    "\n",
    "Now we'll train the final model using the best hyperparameters found during tuning, with:\n",
    "- More epochs\n",
    "- Early stopping\n",
    "- Model checkpointing\n",
    "- Weights & Biases logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa6d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final model with best hyperparameters\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ—ï¸  BUILDING FINAL MODEL WITH BEST HYPERPARAMETERS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "final_model = build_rnn_model(\n",
    "    rnn_type=best_config['rnn_type'],\n",
    "    rnn_units=best_config['rnn_units'],\n",
    "    activation=best_config['activation'],\n",
    "    dropout=best_config['dropout'],\n",
    "    use_batch_norm=best_config['batch_norm']\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "optimizer_instance = None\n",
    "if best_config['optimizer'] == 'adam':\n",
    "    optimizer_instance = tf.keras.optimizers.Adam(learning_rate=best_config['learning_rate'])\n",
    "elif best_config['optimizer'] == 'rmsprop':\n",
    "    optimizer_instance = tf.keras.optimizers.RMSprop(\n",
    "        learning_rate=best_config['learning_rate'],\n",
    "        momentum=best_config['momentum']\n",
    "    )\n",
    "elif best_config['optimizer'] == 'sgd':\n",
    "    optimizer_instance = tf.keras.optimizers.SGD(\n",
    "        learning_rate=best_config['learning_rate'],\n",
    "        momentum=best_config['momentum']\n",
    "    )\n",
    "\n",
    "final_model.compile(\n",
    "    optimizer=optimizer_instance,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Final Model Architecture:\")\n",
    "print(f\"   RNN Type: {best_config['rnn_type']}\")\n",
    "print(f\"   RNN Units: {best_config['rnn_units']}\")\n",
    "print(f\"   Optimizer: {best_config['optimizer']}\")\n",
    "print(f\"   Learning Rate: {best_config['learning_rate']}\")\n",
    "print(f\"   Momentum: {best_config['momentum']}\")\n",
    "print(f\"   Activation: {best_config['activation']}\")\n",
    "print(f\"   Dropout: {best_config['dropout']}\")\n",
    "print(f\"   Batch Norm: {best_config['batch_norm']}\")\n",
    "\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a4102",
   "metadata": {},
   "source": [
    "## Performance documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd692f",
   "metadata": {},
   "source": [
    "### 3.1 TrainningCurves (loss/accuracy/AUC)\n",
    "\n",
    "Vi plotter den **sidst trÃ¦nede models** historik (her: ViT). Du kan let skifte til `history_cnn` eller kombinere i Ã©t plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7c7529d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(hist, title=\"Training curves\"):\n",
    "    hist = hist.history\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(hist.get(\"loss\",[]), label=\"loss\")\n",
    "    plt.plot(hist.get(\"val_loss\",[]), label=\"val_loss\")\n",
    "    plt.title(title + \" â€” loss\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.legend(); plt.show()\n",
    "\n",
    "    if \"accuracy\" in hist or \"acc\" in hist:\n",
    "        acc_key = \"accuracy\" if \"accuracy\" in hist else \"acc\"\n",
    "        val_acc_key = \"val_accuracy\" if \"val_accuracy\" in hist else \"val_acc\"\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(hist.get(acc_key,[]), label=acc_key)\n",
    "        plt.plot(hist.get(val_acc_key,[]), label=val_acc_key)\n",
    "        plt.title(title + \" â€” accuracy\")\n",
    "        plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.legend(); plt.show()\n",
    "\n",
    "    if \"auc\" in hist:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.plot(hist.get(\"auc\",[]), label=\"auc\")\n",
    "        plt.plot(hist.get(\"val_auc\",[]), label=\"val_auc\")\n",
    "        plt.title(title + \" â€” AUC\")\n",
    "        plt.xlabel(\"Epoch\"); plt.ylabel(\"AUC\"); plt.legend(); plt.show()\n",
    "\n",
    "# Plot for CNN (head + finetune)\n",
    "plot_history(history_cnn, \"CNN (frozen backbone)\")\n",
    "plot_history(history_cnn_ft, \"CNN (finetuned)\")\n",
    "\n",
    "\n",
    "# create directory for plots in save_dir\n",
    "os.makedirs(os.path.join(save_dir, \"plots\"), exist_ok=True)\n",
    "\n",
    "# after creating all plots, save them to save_dir\n",
    "for i in plt.get_fignums():\n",
    "    fig = plt.figure(i)\n",
    "    fig.savefig(os.path.join(save_dir, f\"plots/training_curve_{i}_{WANDB_ID}.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57dbeb",
   "metadata": {},
   "source": [
    "## 4.1) Prepare final re-fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ded2023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing final refit\n"
     ]
    }
   ],
   "source": [
    "print('preparing final refit')\n",
    "\n",
    "# Train* DataSet (val + train)\n",
    "#train_star = train_ds.concatenate(val_ds).shuffle(\n",
    "#    buffer_size=2048, seed=SEED, reshuffle_each_iteration=True\n",
    "#)\n",
    "\t\n",
    "train_star = train_ds.concatenate(val_ds)\n",
    "\n",
    "# update W&B for refit\n",
    "final_callbacks = [\n",
    "    WandbMetricsLogger(log_freq=\"epoch\"),\n",
    "    WandbModelCheckpoint(\n",
    "        filepath=os.path.join(save_dir, \"final_refit.weights.h5\"),\n",
    "        monitor=\"auc\",    # ingen val-data, sÃ¥ brug trÃ¦nings-AUC\n",
    "        mode=\"max\",\n",
    "        save_weights_only=True,\n",
    "        save_best_only=True,\n",
    "        save_freq=\"epoch\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "wandb.log({\"phase\": \"final_refit\"})\n",
    "\n",
    "final_model = finetune_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6e571",
   "metadata": {},
   "source": [
    "## 4.2) Final re-fit on train* (train+val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c71f7507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINAL REFIT]\n",
      "Epoch 1/14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 08:48:28.423852: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 579806208 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 170ms/step - accuracy: 0.9462 - auc: 0.9877 - loss: 0.1397\n",
      "Epoch 2/14\n",
      "\u001b[1m328/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m12s\u001b[0m 154ms/step - accuracy: 0.9559 - auc: 0.9909 - loss: 0.1193"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 08:50:28.959985: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 67109120 bytes after encountering the first element of size 67109120 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 161ms/step - accuracy: 0.9516 - auc: 0.9897 - loss: 0.1272\n",
      "Epoch 3/14\n",
      "\u001b[1m328/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m13s\u001b[0m 159ms/step - accuracy: 0.9544 - auc: 0.9918 - loss: 0.1144"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 08:51:36.741933: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 67109120 bytes after encountering the first element of size 67109120 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 169ms/step - accuracy: 0.9552 - auc: 0.9915 - loss: 0.1156\n",
      "Epoch 4/14\n",
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 176ms/step - accuracy: 0.9615 - auc: 0.9928 - loss: 0.1039\n",
      "Epoch 5/14\n",
      "\u001b[1m328/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m13s\u001b[0m 167ms/step - accuracy: 0.9562 - auc: 0.9914 - loss: 0.1149"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 08:54:00.636021: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 67109120 bytes after encountering the first element of size 67109120 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 172ms/step - accuracy: 0.9615 - auc: 0.9931 - loss: 0.1024\n",
      "Epoch 6/14\n",
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 172ms/step - accuracy: 0.9647 - auc: 0.9941 - loss: 0.0945\n",
      "Epoch 7/14\n",
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 174ms/step - accuracy: 0.9690 - auc: 0.9949 - loss: 0.0857\n",
      "Epoch 8/14\n",
      "\u001b[1m328/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m13s\u001b[0m 168ms/step - accuracy: 0.9673 - auc: 0.9952 - loss: 0.0849"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 08:57:33.512399: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 67109120 bytes after encountering the first element of size 67109120 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 174ms/step - accuracy: 0.9706 - auc: 0.9957 - loss: 0.0800\n",
      "Epoch 9/14\n",
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 173ms/step - accuracy: 0.9704 - auc: 0.9957 - loss: 0.0792\n",
      "Epoch 10/14\n",
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 175ms/step - accuracy: 0.9721 - auc: 0.9962 - loss: 0.0743\n",
      "Epoch 11/14\n",
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 175ms/step - accuracy: 0.9744 - auc: 0.9968 - loss: 0.0678\n",
      "Epoch 12/14\n",
      "\u001b[1m328/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - accuracy: 0.9732 - auc: 0.9960 - loss: 0.0771"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 09:02:19.121442: W tensorflow/core/kernels/data/prefetch_autotuner.cc:55] Prefetch autotuner tried to allocate 67109120 bytes after encountering the first element of size 67109120 bytes.This already causes the autotune ram budget to be exceeded. To stay within the ram budget, either increase the ram budget or reduce element size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 172ms/step - accuracy: 0.9766 - auc: 0.9972 - loss: 0.0648\n",
      "Epoch 13/14\n",
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 176ms/step - accuracy: 0.9765 - auc: 0.9971 - loss: 0.0637\n",
      "Epoch 14/14\n",
      "\u001b[1m410/410\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 178ms/step - accuracy: 0.9776 - auc: 0.9974 - loss: 0.0609\n"
     ]
    }
   ],
   "source": [
    "print('[FINAL REFIT]')\n",
    "\n",
    "# Reuse best model weights and ReFit on train*\n",
    "history_final = final_model.fit(\n",
    "\ttrain_star,\n",
    "\tepochs=best_ft_epoch,\n",
    "\tverbose=1,\n",
    "\tcallbacks=final_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ba4d226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ preprocess (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ preprocess (\u001b[38;5;33mLambda\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ backbone (\u001b[38;5;33mFunctional\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚    \u001b[38;5;34m23,587,712\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚         \u001b[38;5;34m2,049\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,431,941</span> (158.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,431,941\u001b[0m (158.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,921,089</span> (34.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,921,089\u001b[0m (34.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,668,672</span> (55.96 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,668,672\u001b[0m (55.96 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,842,180</span> (68.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m17,842,180\u001b[0m (68.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6ca5a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final refitted model\n",
    "final_model.save(os.path.join(save_dir, f\"model_final_refit_{WANDB_ID}.keras\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f7217",
   "metadata": {},
   "source": [
    "## 4.3) Log to W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5aad150a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINAL REFIT] Done âœ…\n",
      "[FINAL REFIT] âœ… Model saved: ModelWeights/resnet50_seed42_xxvh4y17\n",
      "[FINAL REFIT] ğŸª„ W&B artifact: resnet50_seed42_xxvh4y17_final_refit\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>cnn_val_acc_ft</td><td>â–</td></tr><tr><td>cnn_val_acc_tl</td><td>â–</td></tr><tr><td>cnn_val_auc_ft</td><td>â–</td></tr><tr><td>cnn_val_auc_tl</td><td>â–</td></tr><tr><td>cnn_val_loss_ft</td><td>â–</td></tr><tr><td>cnn_val_loss_tl</td><td>â–</td></tr><tr><td>epoch/accuracy</td><td>â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>epoch/auc</td><td>â–â–‚â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>epoch/epoch</td><td>â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒ</td></tr><tr><td>epoch/learning_rate</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚</td></tr><tr><td>+10</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>cnn_val_acc_ft</td><td>0.93038</td></tr><tr><td>cnn_val_acc_tl</td><td>0.87774</td></tr><tr><td>cnn_val_auc_ft</td><td>0.9789</td></tr><tr><td>cnn_val_auc_tl</td><td>0.94951</td></tr><tr><td>cnn_val_loss_ft</td><td>0.18694</td></tr><tr><td>cnn_val_loss_tl</td><td>0.29012</td></tr><tr><td>epoch/accuracy</td><td>0.97765</td></tr><tr><td>epoch/auc</td><td>0.9974</td></tr><tr><td>epoch/epoch</td><td>13</td></tr><tr><td>epoch/learning_rate</td><td>1e-05</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resnet50-seed42-1762120763</strong> at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/pcam-tf-example/runs/xxvh4y17' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/pcam-tf-example/runs/xxvh4y17</a><br> View project at: <a href='https://wandb.ai/guldmand-university-of-southern-denmark/pcam-tf-example' target=\"_blank\">https://wandb.ai/guldmand-university-of-southern-denmark/pcam-tf-example</a><br>Synced 4 W&B file(s), 0 media file(s), 53 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251102_225815-xxvh4y17/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# W&B Artifact\n",
    "artifact = wandb.Artifact(\n",
    "    name=f\"{MODEL_NAME}_seed{SEED}_{WANDB_ID}_final_refit\",\n",
    "    type=\"model\",\n",
    "    metadata={\n",
    "        \"model_name\": MODEL_NAME,\n",
    "        \"img_size\": IMG_SIZE,\n",
    "        \"seed\": SEED,\n",
    "        \"finetune_lr\": LR * 0.1,\n",
    "        \"refit_epochs_total\": int(best_ft_epoch),\n",
    "        \"phase\": \"final_refit\",\n",
    "        \"source_run_id\": WANDB_ID,\n",
    "    },\n",
    ")\n",
    "\n",
    "artifact.add_file(os.path.join(save_dir, f\"model_final_refit_{WANDB_ID}.keras\"))\n",
    "\n",
    "artifact.add_file(save_dir + \"/final_refit.weights.h5\")\n",
    "wandb.log_artifact(artifact)\n",
    "\n",
    "# W&B Metrics ğŸ“Š for final refit\n",
    "final_metrics = {\n",
    "    \"final_refit_best_epoch\": np.argmax(history_final.history[\"auc\"]) + 1,\n",
    "    \"final_refit_last_epoch\": len(history_final.history[\"loss\"]),\n",
    "    \"final_refit_best_auc\": float(np.max(history_final.history[\"auc\"])),\n",
    "    \"final_refit_last_auc\": float(history_final.history[\"auc\"][-1]),\n",
    "    \"final_refit_best_loss\": float(np.min(history_final.history[\"loss\"])),\n",
    "    \"final_refit_last_loss\": float(history_final.history[\"loss\"][-1]),\n",
    "}\n",
    "\n",
    "wandb.log(final_metrics)\n",
    "\n",
    "print(f\"[FINAL REFIT] Done âœ…\")\n",
    "print(f\"[FINAL REFIT] âœ… Model saved: {save_dir}\")\n",
    "print(f\"[FINAL REFIT] ğŸª„ W&B artifact: {artifact.name}\")\n",
    "\n",
    "#finish wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c93bde",
   "metadata": {},
   "source": [
    "### 5) Export CSV with probabilities (on test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d46a117c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/26\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 105ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 09:09:24.943735: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{} for conv (f32[38,64,56,56]{3,2,1,0}, u8[0]{0}) custom-call(f32[38,64,56,56]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-11-03 09:09:25.521833: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{} for conv (f32[38,128,28,28]{3,2,1,0}, u8[0]{0}) custom-call(f32[38,128,28,28]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-11-03 09:09:26.106486: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{} for conv (f32[38,256,14,14]{3,2,1,0}, u8[0]{0}) custom-call(f32[38,256,14,14]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n",
      "2025-11-03 09:09:26.716270: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:546] Omitted potentially buggy algorithm eng14{} for conv (f32[38,512,7,7]{3,2,1,0}, u8[0]{0}) custom-call(f32[38,512,7,7]{3,2,1,0}, f32[512,512,3,3]{3,2,1,0}, f32[512]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 347ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate submission csv using test_ds\n",
    "y_test_hat = final_model.predict(test_ds, verbose=1)\n",
    "ytest_hat = pd.DataFrame({\n",
    "    'Id': list(range(len(y_test_hat))),\n",
    "    'Predicted': y_test_hat.reshape(-1,),\n",
    "})\n",
    "\n",
    "# create directory for csv export inside save_dir\n",
    "os.makedirs(os.path.join(save_dir, \"csv\"), exist_ok=True)\n",
    "ytest_hat.to_csv(f'{save_dir}/csv/ytest_hat_{WANDB_ID}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c070ecb",
   "metadata": {},
   "source": [
    "### 6) Find optimal accuracy threshold based on validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcdcfa76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[THR] Finder optimal threshold pÃ¥ val_ds (baseret pÃ¥ accuracy)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 09:09:33.022463: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[THR] Bedste threshold = 0.564 med val-accuracy = 0.9985\n",
      "[THR] W&B log skipped: You must call wandb.init() before wandb.log()\n"
     ]
    }
   ],
   "source": [
    "# === A) Find optimal threshold pÃ¥ val_ds (max accuracy) ===\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"[THR] Finder optimal threshold pÃ¥ val_ds (baseret pÃ¥ accuracy)\")\n",
    "\n",
    "# 1) Hent y_true og p_hat fra val_ds\n",
    "y_val_true = []\n",
    "for _, y in val_ds:\n",
    "    y_val_true.append(y.numpy())\n",
    "y_val_true = np.concatenate(y_val_true).astype(int)\n",
    "\n",
    "# Keras .predict giver sandsynligheder (antager sigmoid i sidste lag)\n",
    "y_val_prob = final_model.predict(val_ds, verbose=0).reshape(-1)\n",
    "\n",
    "# 2) Grid-scan thresholds i [0.0, 1.0]\n",
    "thr_grid = np.linspace(0.0, 1.0, 1001)  # oplÃ¸sning 0.001\n",
    "accs = []\n",
    "\n",
    "for thr in thr_grid:\n",
    "    y_val_pred = (y_val_prob >= thr).astype(int)\n",
    "    accs.append(accuracy_score(y_val_true, y_val_pred))\n",
    "\n",
    "accs = np.array(accs)\n",
    "best_idx = int(np.argmax(accs))\n",
    "best_thr = float(thr_grid[best_idx])\n",
    "best_acc = float(accs[best_idx])\n",
    "\n",
    "print(f\"[THR] Bedste threshold = {best_thr:.3f} med val-accuracy = {best_acc:.4f}\")\n",
    "\n",
    "# (valgfrit) log til W&B\n",
    "try:\n",
    "    wandb.log({\"threshold/best\": best_thr, \"threshold/val_accuracy\": best_acc})\n",
    "except Exception as e:\n",
    "    print(\"[THR] W&B log skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4736dfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate best threshold plot based on Cross validation k-fold 10, with 0.8 train and 0.2 val splits\n",
    "\n",
    "# setup new datasplit from original train data\n",
    "X_tr_final, X_val_final, y_tr_final, y_val_final = train_test_split(\n",
    "\tXtrain, ytrain, test_size=0.2, random_state=42, stratify=ytrain\n",
    ")\n",
    "\n",
    "# use cross validation to find best threshold with 10 folds\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# for each fold find best threshold\n",
    "best_thresholds = []\n",
    "for train_index, val_index in kf.split(X_tr_final):\n",
    "\tX_tr_fold, X_val_fold = X_tr_final[train_index], X_tr_final[val_index]\n",
    "\ty_tr_fold, y_val_fold = y_tr_final[train_index], y_tr_final[val_index]\n",
    "\n",
    "\t# create datasets\n",
    "\ttrain_ds_fold = make_train_ds(X_tr_fold, y_tr_fold)\n",
    "\tval_ds_fold = make_eval_ds(X_val_fold, y_val_fold)\n",
    "\n",
    "\t# predict on val_ds_fold\n",
    "\ty_val_prob_fold = final_model.predict(val_ds_fold, verbose=0).reshape(-1)\n",
    "\n",
    "\t# get true labels\n",
    "\ty_val_true_fold = []\n",
    "\tfor _, y in val_ds_fold:\n",
    "\t\ty_val_true_fold.append(y.numpy())\n",
    "\ty_val_true_fold = np.concatenate(y_val_true_fold).astype(int)\n",
    "\n",
    "\t# grid scan thresholds\n",
    "\tthr_grid = np.linspace(0.0, 1.0, 1001)\n",
    "\taccs = []\n",
    "\n",
    "\tfor thr in thr_grid:\n",
    "\t\ty_val_pred_fold = (y_val_prob_fold >= thr).astype(int)\n",
    "\t\taccs.append(accuracy_score(y_val_true_fold, y_val_pred_fold))\n",
    "\n",
    "\taccs = np.array(accs)\n",
    "\tbest_idx = int(np.argmax(accs))\n",
    "\tbest_thr = float(thr_grid[best_idx])\n",
    "\tbest_thresholds.append(best_thr)\n",
    "\n",
    "mean_best_thr = np.mean(best_thresholds)\n",
    "std_best_thr = np.std(best_thresholds)\n",
    "\n",
    "print(f\"[THR CV] Mean best threshold from CV = {mean_best_thr:.3f} Â± {std_best_thr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99544d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step\n",
      "[SUBMIT] Skrev 0/1-label CSV til:\n",
      "ModelWeights/resnet50_seed42_xxvh4y17/csv/submission_threshold_0.564_xxvh4y17.csv\n",
      "[SUBMIT] W&B artifact skip: You must call wandb.init() before wandb.log_artifact()\n"
     ]
    }
   ],
   "source": [
    "# === B) GenerÃ©r 0/1 Kaggle-CSV fra test_ds ved brug af best_thr ===\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "assert \"best_thr\" in globals(), \"KÃ¸r fÃ¸rst threshold-cellen (A), sÃ¥ 'best_thr' findes.\"\n",
    "\n",
    "# 1) Hent P(y=1) pÃ¥ test\n",
    "y_test_prob = final_model.predict(test_ds, verbose=1).reshape(-1)\n",
    "\n",
    "# 2) Threshold til 0/1\n",
    "y_test_label = (y_test_prob >= best_thr).astype(int)\n",
    "\n",
    "# 3) Gem CSV\n",
    "os.makedirs(os.path.join(save_dir, \"csv\"), exist_ok=True)\n",
    "csv_path = os.path.join(save_dir, \"csv\", f\"submission_threshold_{best_thr:.3f}_{WANDB_ID}.csv\")\n",
    "pd.DataFrame({\"Id\": np.arange(len(y_test_label)), \"Predicted\": y_test_label}).to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"[SUBMIT] Skrev 0/1-label CSV til:\\n{csv_path}\")\n",
    "\n",
    "# (valgfrit) log filen som W&B-artifact\n",
    "try:\n",
    "    art = wandb.Artifact(\n",
    "        name=f\"{MODEL_NAME}_seed{SEED}_{WANDB_ID}_submission_thr\",\n",
    "        type=\"submission\",\n",
    "        metadata={\"threshold\": best_thr, \"source_run_id\": WANDB_ID}\n",
    "    )\n",
    "    art.add_file(csv_path)\n",
    "    wandb.log_artifact(art)\n",
    "except Exception as e:\n",
    "    print(\"[SUBMIT] W&B artifact skip:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
